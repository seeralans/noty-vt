#+TITLE: On stochastic differential equations with piecewise smooth drift and noise amplitudes.
#+OPTIONS: num:t
#+SLUG: pwsde
#+INCLUDE: "_macros.org"
#+bibliography: ../bib/references.bib
#+cite_export: csl ../csl/chicago-author-date.csl
#+LATEX_HEADER: \usepackage{amsmath,amsthm,amssymb}
#+LATEX_HEADER: \usepackage[nameinlink,noabbrev]{cleveref}

#+LATEX_HEADER: \newtheorem{theorem}{Theorem}[section]
#+LATEX_HEADER: \newtheorem{lemma}[theorem]{Lemma}
#+LATEX_HEADER: \newtheorem{proposition}[theorem]{Proposition}
#+LATEX_HEADER: \newtheorem{corollary}[theorem]{Corollary}
#+LATEX_HEADER: \theoremstyle{definition}\newtheorem{definition}[theorem]{Definition}
#+LATEX_HEADER: \theoremstyle{remark}\newtheorem*{remark}{Remark}
#+LATEX_HEADER: \crefname{lemma}{lemma}{lemmas}
#+LATEX_HEADER: \Crefname{lemma}{Lemma}{Lemmas}
#+LATEX_HEADER: \input{customcommands.tex}
#+LATEX_HEADER: \newcommand{\cunt}{\mathbb{R}}

#+PROPERTY: header-args :eval no

* Introduction
Consider the the autonomous general piecewise stochastic differential equation
#+name: eq-general-psde
\begin{equation}
\mathrm{d}x_t = a(x_t, \lambda_t) \mathrm{d}t + \sqrt{\epsilon} b(x_t, \lambda_t) \mathrm{d}W_t,
\end{equation}
where $x_t \in \mathbb{R}^d$, $\lambda_t \in [-1, 1]$, and $a(\cdot) \in \mathbb{R}^d$ is 
$b(\cdot) \in \mathbb{R}^d$, and $\mathrm{d}W_t$ is a Wiener increment. Of course without the non-smoothness, equations of the form [[eq-general-psde]] are obtained when one perturbs a system with weak noise see for example [cite:freidlinwentzel2012book]. Such equations are also manifest the sde description corresponding to the quadratic approximation of the tilted (non-linear) generator obtained via large deviation principle on a chemical master equation for large system size.


Let the discontinuity $\sigma: \mathbb{R}^d \mapsto \mathbb{R}$ be a scalar function used to define the discontinuity surface
#+name: eq-disc-surf
\begin{equation}
\mathcal{D} = {\left\{ x \in \mathbb{R}^d \,|\, \sigma(x) = 0 \right\}},
\end{equation}
notice that $\lambda_{t} = \mathrm{sign}(\sigma(x_{t}))$ is now stochastic. The dynamics of $x_t$ together with $\lambda_t$ is a stochastic slow-fast system. Recall that
for deterministic system, the fast dynamics of the switching variable is given via $\dot{\lambda} = \epsilon^{-1}\nabla \sigma \cdot \dot{x}^{{\scriptsize\mathsf{T}}}$, this comes from regularising the sign function into something of the form
#+name: eq-lam-reg
\begin{equation}
\lambda^{(\epsilon^{\beta})}(x) = 
\left\{
\begin{array}
\sigma \sigma (x) / \epsilon^{\beta} & |\sigma(x)| < \epsilon^{\beta},\\
\mathrm{sign}(\sigma(x)) & |\sigma(x)| \geq \epsilon^{\beta},
\end{array}
\right.
\quad 0 < \epsilon, \beta 
\end{equation}
and then taking the derivative with respect to time. Note that this regularisation is obviously not unique, any choose of $\beta > 0$, would work as we are interested in only the singular limit as it pertains to resolving the sliding mode.

For stochastic system one must employ Ito's lemma which yeilds
#+name: eq-lam-slow-ito
\begin{equation}
\mathrm{d}\lambda_t = \frac{1}{\epsilon} \left[
\nabla \sigma \cdot
\mathrm{d}x_t
+  
\frac{1}{2}
\mathrm{d}x_t
\nabla^2 \sigma
\mathrm{d}x_t^{\scriptsize{\mathsf{T}}} \right],
\end{equation}
clearly for non planar discontinuity surfaces the additional Ito correction will yeild additional drift terms, while for planar discontinuity surfaces we obtain a simple projection onto the normal. For this introduction let us assume we have a planar discontinuity surface with $\sigma(x) = n \cdot x$ where $n \in \mathbb{R}^{d}$ is a constant vector, which gives us 
#+name: eq-lam-slow
\begin{equation}
\mathrm{d}\lambda_t = 
\frac{1}{\epsilon}
n \cdot
a(x_t, \lambda_t) \mathrm{d}t +
\frac{1}{\sqrt{\epsilon}}
n\cdot b(x_t, \lambda_t) 
\mathrm{d}W_t,
\end{equation}
Suppose we wish to analyse the fast subsystem, let us consider the rescaling time with $t = \epsilon^{\alpha} \tau$, where $\epsilon, \alpha > 0$. Rescaling [[eq-lam-slow]] we obtain 
#+name: eq-lam-fast
\begin{equation}
\mathrm{d}\lambda_{\tau} = 
\epsilon^{\alpha - 1}
a^{(n)}(x_{\tau}, \lambda_{\tau}) \mathrm{d}\tau +
\epsilon^{\frac{\alpha - 1}{2}}
b^{(n)}(x_\tau, \lambda_{\tau}) 
\mathrm{d}W_{\tau},
\end{equation}
where $\mathrm{d}W_{\tau}$ is a Weiner increment with zero mean and second moment
$\mathbb{E}[\mathrm{d}W_{\tau}^2] = \mathrm{d}\tau$. Notice that $\alpha = 1$ puts both the drift and noise terms on equal footing. Notice that there is no time scale that is  faster than $t$ such that we can suppress the noise faster than the drift as $\epsilon$. That is for all $\alpha > 0$ (fast $\tau$)
$$
\frac{\epsilon^{-\frac{1}{2}}|b^{(n)(x_{\tau}, \lambda_{\tau})}|}{|a^{(n)(x_{\tau}, \lambda_{\tau})}|} \not \to 0, 
\quad \text{as} \quad \epsilon \to 0.
$$
This follows from the fact that the dynamics of $\lambda_{\tau}$ exist in an $\epsilon$ layer around the discontinuity surface and because the noise amplitude in [[eq-general-psde]] is $\mathcal{O}(\sqrt{\epsilon})$. In the microtubule example the lattice size $N$ affixes indpendently the size of the layer with $\epsilon = 1/N$ which corresponds to one lattice site, as well as the Gaussian noise amplitude which is $O(1/\sqrt{N})$. The slow subsystem under the fast time scale is given by 
#+name: eq-general-psde-fast
\begin{equation}
\mathrm{d}x_{\tau} = \epsilon^{\alpha} a(x_{\tau}, \lambda_{\tau}) \mathrm{d}{\tau} + \epsilon^{\alpha + \frac{1}{2}} b(x_{\tau}, \lambda_{\tau}) \mathrm{d}W_{\tau},
\end{equation}
which shows that variable is static under the fast time and also maintains the correct scaling between the drift and noise terms 
$$
\frac{\epsilon^{\frac{1}{2}}|b^{(n)(x_{\tau}, \lambda_{\tau})}|}{|a^{(n)(x_{\tau}, \lambda_{\tau})}|} \to 0, 
\quad \text{as} \quad \epsilon \to 0.
$$
While analysing the fast subsystem and the multiple timescales problem is in itself an interesting endeavour, our goal is only to analyse the fast dynamics only as far as it pertains to resolving the slow dynamics at the discontinuity sets.

** Derivation of Fokker-Planck for the fast switching variable
Let $x_t$  be a stochastic process in $\mathbb{R}^d$, and governed by the SDE
#+name: eq-sde-al
\begin{equation}
\mathrm{d} x_t = \hat{a}(t, x_t, \lambda_t) \mathrm{d} t + \sqrt{\epsilon} \hat{b}(t, x_t, \lambda_t) \mathrm{d} W_t^\alpha, \quad \alpha \in [0, 1]
\end{equation}
where 
#+name: eq-ahat-def
\begin{equation}
\hat{a}(t, x_t, \lambda_t) =
\frac{1}{2}{\left(1 + \lambda_t \right)} a^{+}(t, x_t)
+ \frac{1}{2}{\left(1 - \lambda_t \right)} a^{-}(t, x_t)
\end{equation}
is a convex combination of the vector fields on either side of the discontinuity surface, similarly
#+name: eq-bhat-def
\begin{equation}
\hat{b}(t, x_t, \lambda_t) =
\frac{1}{2}{\left(1 + \lambda_t \right)} b^{+}(t, x_t)
+ \frac{1}{2}{\left(1 - \lambda_t \right)} b^{-}(t, x_t)
\end{equation}
is a convex combination of the noise amplitude on either side of the
discontinuity surface, $\rmd W_t$ is a Weiner increment, and $\alpha$ denotes the
point at which we evaluate the noise-amplitude in the stochastic integral, with
$\alpha = 0$ corresponding to the start point evaluation, i.e. Ito while $\alpha
= 1$ would correspond to the anti-Ito convention. Regardless of the choice of
$\alpha$ we can have an Ito representation of the process via
#+name: eq-sde-al-to-ito
\begin{equation}
    \mathrm{d} x_t = [\hat{a}(t, x_t, \lambda_t) + \alpha \epsilon \hat{b}(t, x_t, \lambda_t) \partial_x \hat{b}(t, x_t, \lambda_t)] \mathrm{d} t + \sqrt{\epsilon} \hat{b}(t, x_t, \lambda_t) \mathrm{d} W_t,
\end{equation}
which we will rewrite as
#+name: eq-gen-weak-noise-nssde
\begin{equation}
\mathrm{d}x_t = a(t, x_t, \lambda_t) \mathrm{d}t + \sqrt{\epsilon} b(t, x_t, \lambda_t) \mathrm{d}W_t,
\end{equation}
where
#+name: eq-a-def
\begin{equation}
a(t, x_t, \lambda_t) = 
\hat{a}(t, x_t, \lambda_t) + \alpha \epsilon \hat{b}(t, x_t, \lambda_t) \partial_x \hat{b}(t, x_t, \lambda_t),
\end{equation}
and
#+name: eq-b-def
\begin{equation}
b(t, x_t, \lambda_t) = \hat{b}(t, x_t \lambda_t).
\end{equation}
Obviously in our calculations we will employ Ito calculus on [[eq-sde-al-to-ito]]
and later affix the choice of $\alpha$ for the original problem.

Our goal is to close the SDE given in [[eq-sde-al-to-ito]] (and in turn [[eq-sde-al]])
using a quasi-stationary closure for the switching variable $\lambda_t$. That is
we seek the conditional probability density $P(\lambda \giv t, x_t)$, the
validity of the such a closure will become apparent later. Recall that away from
the discontinuity surface, $\lambda_t \in \{1, -1\}$, while near the it we have
$\lambda_t \in (-1, 1)$. In the former we have trivially $$P(\lambda | t, x_t
\in \mathcal{R}^{\pm}) = \delta(x \mp 1)$$ where $\delta(x)$ is the Dirac delta
distribution, on the other hand one expects a non-trivial probability density
with support on $\lambda \in (-1, 1)$.

To study the dynamics of $\lambda_t$ we first introduce the regularised 
#+name: eq-lam-reg
\begin{equation}
\Lambda_{\epsilon}(u) \idef
\left\{
\begin{matrix}
u / \epsilon & |u| < \epsilon, \\
\mathrm{sign}(u) & |u| \geq \epsilon,
\end{matrix}
\right.
\end{equation}
The function $\Lambda_{\epsilon}(u)$ can be written as
#+name: eq-lam-reg-conv-diff
\begin{equation}
\Lambda_{\epsilon}(u) = \psi^{+}_{\epsilon}(u) - \psi^{+}_{\epsilon}(u),
\end{equation}
where
#+name: eq-conv-psi12
\begin{equation}
\psi^{+}_{\epsilon}(u) \idef
\left\{
\begin{matrix}
-1 & u \leq -\epsilon \\
u / \epsilon &  u > -\epsilon
\end{matrix}
\right.
\qquad
\psi^{-}_{\epsilon}(u) \idef
\left\{
\begin{matrix}
0 & u \leq \epsilon \\
u / \epsilon -1 &  u > \epsilon
\end{matrix}
\right. ,
\end{equation}
are convex functions. We now want to consider the the dynamics of $\lambda_t = \Lambda_{\epsilon}(x_t)$, but obviously since $\Lambda_{\epsilon}(u)$ only has a second derivative in the distributional sense one cannot simply employ Ito's lemma and instead we must use Melyer-Ito. For the function $\Lambda_{\epsilon}$ that can be written as the difference of two convex functions, Ito-meyer states that
#+name: eq-lam-sde-meyer-ito
\begin{equation}
\Lambda_{\epsilon}(z_t) =  
\Lambda_{\epsilon}(z_0) + 
\int_{0}^{t}
\Lambda^{'-}_{\epsilon}(z_s) \rmd z_s 
+
\int_{0}^{t} L_t(z) \rmd \mu_{\Lambda^{''}_{\epsilon}}(z)
\end{equation}
where each of the terms are as follows. We that $\Lambda^{'-}_{\epsilon}(z_s)$ is the left derivative,
#+name: eq-z-sde
\begin{equation}
\begin{aligned}
\rmd z_t &= \ls (\mpdiff{\sigma}{x})^{\trans} a(t, x_t, \lambda_t) + \frac{\epsilon}{2}\mathrm{Tr}(b(t, x_t,    \lambda_t)^{\trans} (\mpdiff[2]{\sigma}{xx}) b(t, x_t, \lambda_t)) \rs \rmd t \\
&+ \sqrt{\epsilon} (\mpdiff{\sigma}{x})^{\trans}  c(t, x_t, \lambda_t) \rmd W_t.
\end{aligned}
\end{equation}
which is obtained by defining the andom variable $z_t \idef \sigma(x_t)$ where $\sigma \in C^2(\mathbb{R}^d)$ and  employing Ito's lemma. We also have 
#+name: eq-local-time-def
\begin{equation}
{\color{red} WRONG: } L_t(z) \idef \lim_{\delta \to 0}\frac{1}{4\delta} \mu{\lb |z_s - z| < \delta \giv  s \in [0, t] \rb}
\end{equation}
which is the so-called local time of $z_t$ at the point $z$, and lastly we denote the signed measure of the second derivative of $\Lambda_{\epsilon}$ with $\mu_{\Lambda^{''}_{\epsilon}}(z)$. For our case the left derivative of $\Lambda_{\epsilon}(u)$ given by
#+name: eq-lam-reg-left-deriv
\begin{equation}
\Lambda^{'-}_{\epsilon}(u) =
\left\{
\begin{matrix}
0 & u \leq -\epsilon \\
1 / \epsilon & \epsilon < u \leq \epsilon \\
0  & u >  \epsilon
\end{matrix}
\right.
\end{equation}
and the second derivative as a signed measure is  
#+name: eq-lam-reg-scnd-deriv
\begin{equation}
\mu_{\Lambda^{''}_{\epsilon}}(u) = \frac{1}{\epsilon}\delta_{-\epsilon} - \frac{1}{\epsilon}\delta_{\epsilon}
\end{equation}
where $\delta_{a} = \delta(x - z)$ is the Dirac-delta distribution.  Substituting [[eq-z-sde]], [[eq-lam-reg-left-deriv]], and [[eq-lam-reg-scnd-deriv]] in to [[eq-lam-sde-meyer-ito]] we obtain
#+name: eq-lam-sde-meyer-ito-full
\begin{equation}
\begin{aligned}
\Lambda_{\epsilon}(z_t) =  
\Lambda_{\epsilon}(z_0) &+ 
\frac{\mathbb{1}_{(-\epsilon, \epsilon]}(z_t)}{\epsilon}
\int_{0}^{t} \ls (\mpdiff{\sigma}{x})^{\trans} a(t, x_t, \lambda_t) + \frac{\epsilon}{2}\mathrm{Tr}(b(t, x_t, \lambda_t)^{\trans} (\mpdiff[2]{\sigma}{x}) b(t, x_t, \lambda_t)) \rs \rmd s \\
&+
\frac{\mathbb{1}_{(-\epsilon, \epsilon]}(z_t)}{\sqrt{\epsilon}}
\int_{0}^{t} (\mpdiff{\sigma}{x})^{\trans}  b(t, x_t, \lambda_t) \rmd W_s 
+ \frac{1}{\epsilon}L_t^{-\epsilon} - \frac{1}{\epsilon}L_t^{\epsilon}.
\end{aligned}
\end{equation}
Letting $\lambda_t = \Lambda_{\epsilon}(z_t)$ we write  
#+name: eq-lam-sde
\begin{equation}
\begin{aligned}
\rmd \lambda_t &=
\frac{\mathbb{1}_{(-\epsilon, \epsilon]}(z_t)}{\epsilon}
 \ls \mpdiff{\sigma}{x}^{\trans} a(t, x_t, \lambda_t) + \frac{\epsilon}{2}\mathrm{Tr}(b(t, x_t, \lambda_t)^{\trans} (\mpdiff[2]{\sigma}{xx}) b(t, x_t, \lambda_t)) \rs \rmd t \\
 &+ \frac{\mathbb{1}_{(-\epsilon, \epsilon]}(z_t)}{\sqrt{\epsilon}}
  \mpdiff{\sigma}{x}^{\trans}  b(t, x_t, \lambda_t) \rmd W_t
+\frac{1}{\epsilon}
 \rmd L_{t}^{-\epsilon} - \frac{1}{\epsilon}\rmd L_{t}^{\epsilon} 
\end{aligned}
\end{equation}
which describes the stochastic evolution of the switching variable.

#+begin_question
Not sure if the fact that we impose a noise interpretation on $x_t$ is enough for leaving [[eq-lam-sde]] as Ito or whether we have the freedom to intepret the noise on $\lambda_t$ different from $x_t$
#+end_question


We can obtain the generator ..

Let us now consider a smooth function $f \in C^2([-1, 1])$ and with the intiial condition  $\lambda_0 = \lambda$ $and consider
#+name: eq-mean-f
\begin{align}
&\mathbb{E}[f(\lambda_t) - f(\lambda)] =
\mathbb{E}{\ls \int_0^t \mpdiff{f(\lambda_s)}{\lambda} \rmd \lambda_s \rs}
+ \frac{1}{2}\mathbb{E}{\ls \int_0^t \mpdiff[2]{f(\lambda_s)}{\lambda \lambda} \rmd (\lambda, \lambda)_s \rs} 
\end{align}
which follows directly from Ito's lemma. The first term on the right hand side of [[eq-mean-f]] is easy to evaluate and gives
#+name: eq-mean-f-t1
\begin{align}
\mathbb{E}{\ls \int_0^t \mpdiff{f(\lambda_s)}{\lambda} \rmd \lambda_s \rs} &= 
\frac{1}{\epsilon} \mathbb{E}{\lc
\int_0^t
\mpdiff{f(\lambda_s)}{\lambda} \ls \mpdiff{\sigma}{x}^{\trans} a(s, x_s, \lambda_s)
+ \frac{\epsilon}{2}\mathrm{Tr}[b(s, x_s, \lambda_s)^{\trans} (\mpdiff[2]{\sigma}{xx}) b(s, x_s, \lambda_t)]  \rs \rmd s \rc} \\
 &+ \frac{1}{\epsilon}\mathbb{E}\ls \mpdiff{f(\lambda_t)}{\lambda} (L^{-\epsilon}_t - L^{\epsilon}_t ) \rs.
\end{align}

#+begin_todo
Explain why we have that the local time terms do not contribute to the quadratic integral
#+end_todo
For the second term, the local-time and drift terms do not contribute to the integral resulting in   
#+name: eq-mean-f-t2
\begin{align}
\mathbb{E}{\ls \int_0^t
\mpdiff[2]{f(\lambda_s)}{\lambda \lambda} \rmd (\lambda, \lambda)_s \rs} = 
  \frac{1}{2 \epsilon} \mathbb{E} 
\lc \int^{t}_{0}\mpdiff[2]{f(\lambda_s)}{\lambda\lambda}\ls (\mpdiff{\sigma}{x})^{\trans}
b(t, x_s, \lambda_s)
b(t, x_s, \lambda_s)^{\trans}
(\mpdiff{\sigma}{x}) \rs \rmd s \rc.
\end{align}
The generator of the process $A$, applied to a smooth function is then obtained by evaluating
#+name: eq-lam-gen-def
\begin{equation}
(\mathcal{A}f)(\lambda) = \lim_{t \to 0} \frac{1}{t} {\lc \mathbb{E}[f(\lambda_t)] - f(\lambda) \rc}.
\end{equation}
However, we since we have $L^{\pm \epsilon }_t = O(\sqrt{t})$, and since the choice of $f$ is arbitrary we must ensure that $\mpdiff{f}{\lambda} = 0$ to ensure that 
#+name: eq-lim-local-time-term
\begin{equation}
\lim_{t \to 0} \frac{1}{t}
\mathbb{E}{\ls \mpdiff{f(\lambda_t)}{\lambda} (L^{-\epsilon}_t - L^{\epsilon}_t ) \rs}  = 0.
\end{equation}
Putting it all together we obtain generator of $\lambda_t$,
#+name: eq-bws-lam-gen
\begin{equation}
\begin{aligned}
(\mathcal{A}f)(\lambda) = \frac{1}{\epsilon}
\mpdiff{f(\lambda)}{\lambda} \ls \mpdiff{\sigma}{x}^{\trans} a(t, x_t, \lambda)
+ \frac{\epsilon}{2}\mathrm{Tr}[b(t, x_t, \lambda)^{\trans} (\mpdiff[2]{\sigma}{xx}) b(t, x_t, \lambda)]  \rs \\   + \frac{1}{2 \epsilon} 
\mpdiff[2]{f(\lambda)}{\lambda\lambda} (\mpdiff{\sigma}{x})^{\trans}
b(t, x_t, \lambda)
b(t, x_t, \lambda)^{\trans}
(\mpdiff{\sigma}{x})  ,
\end{aligned}
\end{equation}
whose domain is 
#+name: eq-back-gen-domain
\begin{equation}
\mathcal{D}(\mathcal{A}) = {\lc f \in C^2 \giv \mpdiff{f}{\lambda}(-1)  = \mpdiff{f}{\lambda}(1)  = 0 \rc}.
\end{equation}
#+begin_todo
fix the definition of generator for explicit time dependence
#+name: eq-propdef
\begin{equation}
\lim_{\delta \to 0} \frac{1}{\delta} {\lc \mathbb{E}[f(x_{t + \delta}) - f(x_t)] \rc}
\end{equation}
#+end_todo

To obtain the forward generator we employ the defintion 
#+name: eq-bwd-fwd-gen-equiv
\begin{equation}
\int_{-1}^{1}P(\lambda, t)(\mathcal{A}f)(\lambda) \rmd \lambda 
=
\int_{-1}^{1}f(\lambda)(\mathcal{A}^{*}P)(\lambda, t) \rmd \lambda 
\end{equation}
where $P(\lambda, t)$ is the occupation probability density of $\lambda$, i.e. $\int_{A}P(\lambda, t)\rmd \lambda = \mathbb{P}[\lambda_t \in A]$, also note that this is conditioned on some fixed $x_t$. Inserting the generator ino [[eq-bwd-fwd-gen-equiv]] we obtain for the drift term
#+name: eq-fwd-gen-deriv-drif
\begin{equation}
\begin{aligned}
&\frac{1}{\epsilon} \int^{1}_{-1}
\mpdiff{f(\lambda)}{\lambda}
P(\lambda, t) \ls \mpdiff{\sigma}{x}^{\trans} a(t, x_t, \lambda)
+ \frac{\epsilon}{2}\mathrm{Tr}[b(t, x_t, \lambda)^{\trans} (\mpdiff[2]{\sigma}{xx}) b(t, x_t, \lambda)]  \rs \rmd \lambda  \\
&=\frac{1}{\epsilon}
\lc f(\lambda) P(\lambda, t)
\ls \mpdiff{\sigma}{x}^{\trans} a(t, x_t, \lambda)
+ \frac{\epsilon}{2}\mathrm{Tr}[b(t, x_t, \lambda)^{\trans} (\mpdiff[2]{\sigma}{xx}) b(t, x_t, \lambda)]  \rs \rc \bigg{|}_{-1}^{-1} \\
&- \frac{1}{\epsilon}\int^{1}_{-1}
f(\lambda)
\mpdiff{\lc P(\lambda, t) \ls \mpdiff{\sigma}{x}^{\trans} a(t, x_t, \lambda)
+ \frac{\epsilon}{2}\mathrm{Tr}[b(t, x_t, \lambda)^{\trans} (\mpdiff[2]{\sigma}{xx}) b(t, x_t, \lambda)]  \rs \rc}{\lambda} \rmd \lambda,
\end{aligned}
\end{equation}
and likewise for the diffusive term,
#+name: eq-fwd-gen-deriv-diff
\begin{equation}
\begin{aligned}
&\frac{1}{2\epsilon} \int^{1}_{-1}
\mpdiff[2]{f(\lambda)}{\lambda\lambda}P(\lambda,  t) (\mpdiff{\sigma}{x})^{\trans}
b(t, x_t, \lambda)
b(t, x_t, \lambda)^{\trans}
(\mpdiff{\sigma}{x})  \rmd \lambda
 \\
&=\frac{1}{2\epsilon}
\mpdiff{f(\lambda)}{\lambda}{\ls P(\lambda,  t) (\mpdiff{\sigma}{x})^{\trans}
b(t, x_t, \lambda)
b(t, x_t, \lambda)^{\trans}
(\mpdiff{\sigma}{x})  \rs} \bigg{|}_{-1}^{1}  \\
&-\frac{1}{2\epsilon}\int_{-1}^{1}
\mpdiff{f(\lambda)}{\lambda}\mpdiff{\ls P(\lambda,  t) (\mpdiff{\sigma}{x})^{\trans}
b(t, x_t, \lambda)
b(t, x_t, \lambda)^{\trans}
(\mpdiff{\sigma}{x})  \rs}{\lambda} \rmd \lambda, \\
&=\frac{1}{2\epsilon}
\mpdiff{f(\lambda)}{\lambda}{\ls P(\lambda,  t) (\mpdiff{\sigma}{x})^{\trans}
b(t, x_t, \lambda)
b(t, x_t, \lambda)^{\trans}
(\mpdiff{\sigma}{x})  \rs} \bigg{|}_{-1}^{1} \\
&- \frac{1}{2\epsilon}f(\lambda)\mpdiff{\ls P(\lambda,  t) (\mpdiff{\sigma}{x})^{\trans}
b(t, x_t, \lambda)
b(t, x_t, \lambda)^{\trans}
(\mpdiff{\sigma}{x})  \rs}{\lambda} \bigg{|}_{-1}^{1} \\
&+\frac{1}{2\epsilon}\int_{-1}^{1}
f(\lambda)\mpdiff[2]{\ls P(\lambda,  t) (\mpdiff{\sigma}{x})^{\trans}
b(t, x_t, \lambda)
b(t, x_t, \lambda)^{\trans}
(\mpdiff{\sigma}{x})  \rs}{\lambda\lambda} \rmd \lambda. \\
\end{aligned}
\end{equation}
Since we have $\mpdiff{f(-1)}{\lambda} = \mpdiff{f(1)}{\lambda} = 0$, arbitrary $f \in \mathcal{D}(\mathcal{A})$, the boundary terms must satisfy
#+name: eq-boundary-terms
\begin{equation}
\begin{aligned}
 & \bigg{\{} P(\lambda, t)
\ls \mpdiff{\sigma}{x}^{\trans} a(t, x_t, \lambda)
+ \frac{\epsilon}{2}\mathrm{Tr}[b(t, x_t, \lambda)^{\trans} (\mpdiff[2]{\sigma}{xx}) b(t, x_t, \lambda)]  \rs  \\
& -
\mpdiff{\ls P(\lambda,  t) (\mpdiff{\sigma}{x})^{\trans}
b(t, x_t, \lambda)
b(t, x_t, \lambda)^{\trans}
(\mpdiff{\sigma}{x})  \rs}{\lambda}\bigg{\}}  \bigg{|}_{-1}^{1}  = 0.
\end{aligned}
\end{equation}
Using [[eq-fwd-gen-deriv-drif]], [[eq-fwd-gen-deriv-diff]] and [[eq-boundary-terms]], we
obtain the forward generator
#+name: eq-fwd-lam-gen
\begin{equation}
\begin{aligned}
(\mathcal{A}^{*}P)(\lambda, t \giv x_t) &= - \frac{1}{\epsilon}
\mpdiff{\lc P(\lambda, t) \ls \mpdiff{\sigma}{x}^{\trans} a(t, x_t, \lambda)
+ \frac{\epsilon}{2}\mathrm{Tr}[b(t, x_t, \lambda)^{\trans} (\mpdiff[2]{\sigma}{xx}) b(t, x_t, \lambda)]  \rs \rc}{\lambda} \\
&+\frac{1}{2\epsilon}\mpdiff[2]{\ls P(\lambda,  t)
(\mpdiff{\sigma}{x})^{\trans}
b(t, x_t, \lambda)
b(t, x_t, \lambda)^{\trans}
(\mpdiff{\sigma}{x})  \rs}{\lambda\lambda}.
\end{aligned}
\end{equation}
One can then using the generator obtain the Fokker-Planck equation for $\lambda$ conditioned on the state $x_t = x$ via
#+name: eq-lam-fokker-plank-slow-t
\begin{equation}
\begin{aligned}
\mpdiff{P(\lambda, t \giv x)}{t} &= (\mathcal{A}^*P)(\lambda, t \giv x) \\
 &= 
-\frac{1}{\epsilon}\mpdiff{\lc P(\lambda, t \giv x) \ls \mpdiff{\sigma}{x}^{\trans} a(t, x, \lambda)
+ \frac{\epsilon}{2}\mathrm{Tr}[b(t, x, \lambda)^{\trans} (\mpdiff[2]{\sigma}{xx}) b(t, x, \lambda)]  \rs \rc}{\lambda} \\
&+\frac{1}{2\epsilon}\mpdiff[2]{\ls P(\lambda,  t \giv x)
(\mpdiff{\sigma}{x})^{\trans}
b(t, x_t, \lambda)
b(t, x_t, \lambda)^{\trans}
(\mpdiff{\sigma}{x})  \rs}{\lambda\lambda},
\end{aligned}
\end{equation}
supplemented with the boundary condition given in [[eq-boundary-terms]]. Switching to fast time $t = \epsilon \tau$ before taking the limit we obtain  
#+name: eq-lam-fokker-plank-fast-t
\begin{equation}
\begin{aligned}
\mpdiff{P(\lambda, \tau | x)}{\tau} &= 
- \mpdiff{\ls  \bigg.  P(\lambda, \tau \giv x) \Bigg. (\mpdiff{\sigma}{x}^{\trans}) a(\tau, x, \lambda )   \rs}{\lambda}  \\
&+\frac{1}{2} \mpdiff[2]{\lc P(\lambda, \tau \giv x)
(\mpdiff{\sigma}{x})^{\trans}
b(\tau, x, \lambda)
b(\tau, x, \lambda)^{\trans}
(\mpdiff{\sigma}{x})
\big. \rc}{\lambda},
\end{aligned}
\end{equation}
with the boundary condition
#+name: eq-lam-fokker-plank-bc-fst
\begin{equation}
P(\lambda, \tau \giv x) (\mpdiff{\sigma}{x})^{\trans} a(\tau, \lambda \giv x) 
+\frac{1}{2} \mpdiff{\lc P(\lambda, \tau \giv x)
(\mpdiff{\sigma}{x})^{\trans}
b(\tau, x, \lambda)
b(\tau, x, \lambda)^{\trans}
(\mpdiff{\sigma}{x})\rc}{\lambda}\bigg{|}_{\lambda \pm 1}  = 0
.
\end{equation}
Notice that the curvature of the discontinuity surface does not appear in [[eq-lam-fokker-plank-fast-t]]. 
$$
\renewcommand{asum}[1]{\ensuremath{\stackrel{+}{\overline{a}}(#1)}}
\renewcommand{adif}[1]{\ensuremath{\stackrel{-}{\overline{a}}(#1)}}
\renewcommand{bsum}[1]{\ensuremath{\stackrel{+}{\overline{b}}(#1)}}
\renewcommand{bdif}[1]{\ensuremath{\stackrel{-}{\overline{b}}(#1)}}
$$
#+name: eq-a-sum-dif-def
\begin{equation}
\asum{t, x_t} \idef \frac{1}{2}{\ls a^+(t, x_t) + a^-(t, x_t) \rs}, \quad
\adif{t, x_t} \idef \frac{1}{2}{\ls a^+(t, x_t) - a^-(t, x_t) \rs}, 
\end{equation}
Similarly we have
#+name: eq-b-sum-dif-def
\begin{equation}
\bsum{t, x_t} \idef \frac{1}{2}{\ls b^+(t, x_t) + b^-(t, x_t) \rs}, \quad
\bdif{t, x_t} \idef \frac{1}{2}{\ls b^+(t, x_t) - b^-(t, x_t) \rs}, 
\end{equation}

The fokker planck
#+name: eq-fpp
\begin{equation}
\begin{aligned}
-n^{\trans} a \mpdiff{P}{\lambda} - P n^{\trans}\lc \adif{\tau, x}  + \alpha \epsilon \sum_{j} \lc
J{[\bdif{\tau, x}_j]}[\bsum{\tau, x}_j + \lambda \bdif{\tau, x}]_j  \rd \rd \\
\ld \ld + J{[\bsum{\tau, x}_j + \lambda \bdif{\tau, x}]_j}[\bdif{\tau, x}_j]
 \rc \rc
\end{aligned}
\end{equation}


* Stochastic Sliding Dynamics
:PROPERTIES:
:ID:       ED3929D6-87FB-4B0D-8152-3A340435777F
:END:
Let us consider only planar switching surfaces and define $\nu_t = \sigma(x_t)$, clearly following the same reasoning as above we have in fast time  
#+name: eq-nu
\begin{equation}
\begin{aligned}
\rmd \nu_{\tau} &= \mpdiff{\sigma}{x} \cdot \rmd x_{\tau} + \frac{1}{2} \rmd x_{\tau}\mpdiff[2]{\sigma}{x} \rmd x^{\trans}_{\tau} \\
&= a^{(n)}(x_{\tau}, \nu_{\tau})\rmd t + b^{(n)}(x_{\tau}, \nu_{\tau}) \rmd W_{\tau}
\end{aligned}
\end{equation}
where
$$
a^{(n)}(x_{\tau}, \nu_{\tau}) = a^{(n)}(x_{\tau}, \lambda^{\epsilon}(\nu_{\tau})), \quad
b^{(n)}(x_{\tau}, \nu_{\tau}) = b^{(n)}(x_{\tau}, \lambda^{\epsilon}(\nu_{\tau}))
$$
with $\lambda^{\epsilon}$ defined in [[eq-lam-reg]] with $\beta = 1$. 



1. Solve for the steady state densite $P(\nu \giv x )$ 

When we have stochastic switching parameter, the mean switching paramter
$\bar{\lambda}(x)$ may not always correspond to the steady $\lambda^*(x)$ the
one obtains by closing the fast dynamics. A sufficient and not necessary
condition for $\bar{\lambda}(x) = \lambda^{*}(x)$ would be to have equal noise
amplitudes on either side of the discontinuity.



* Example
Let us start of with the following simple example inspired by the microtubule project
#+name: eq-sde-linear
\begin{equation}
\begin{pmatrix}
\mathrm{d}x_{t} \\
\mathrm{d}y_{t} 
\end{pmatrix}
= 
\left[
\begin{pmatrix}
-1 & \phantom{-}1 \\
\phantom{-}1 & -1 
\end{pmatrix}
\begin{pmatrix}
 x_t \\
 y_t 
\end{pmatrix}
 + 
\frac{1}{2}
\begin{pmatrix}
 v^+ +v^- + \lambda_t (v^+ -  v^-) \\
 v^+ +v^- + \lambda_t (v^+ -  v^-) 
\end{pmatrix}
\right]
\mathrm{d}t
+\sqrt{\epsilon}
B(\lambda_{t}) \mathrm{d}W_t,
\end{equation}
where
#+name: eq-complete-diff-mat
\begin{equation}
B(\lambda_t) = \frac{1}{2} \left[ \Sigma^+ +\Sigma^- +
\lambda_t (\Sigma^+ -\Sigma^-) \right],
\end{equation}
is the convex combination of of the noise amplitude, and as usual $\lambda \in [-1, 1]$ is the switching parameter. A schematic of the system is shown in [[fig-toy-psde-sch]]
#+name:   fig-toy-psde-sch
#+width: 40%
#+caption: Scematic of toy PSDE.
[[../assets/img/psde_toy_grow.svg]]
The discontinuity surface is defined via the zero set of $\sigma(x, y) = 1 - x - y$, that is $\mathcal{D} = {\left\{(x, y) \in \mathbb{R}^2 \,|\, \sigma(x,y) = 0 \right\}}$, it caps the growth. This corresponds with exactly the no-interaction limit of the single filament microtubule. We also have the SDE
#+name: eq-lam-sde-linear-slow
\begin{equation}
\mathrm{d}\lambda_t = \frac{1}{\epsilon}\left[\lambda_t (v^- -  v^+) - v^+ - v^- \right]\mathrm{d}t
+ \frac{1}{\sqrt{\epsilon}}B^{(n)}(\lambda_t) \mathrm{d}W_t
\end{equation}
where $B^{(n)}(\lambda_t)$ is the noise amplitude projected onto $n = \nabla \sigma = (-1, -1)^{\scriptsize{\mathsf{T}}}$. In slow time taking $\epsilon \to 0$ we obtain a standard piecewise ODE which permits a sliding mode with 
$$
\lambda^{*} = \frac{v^+ + v^-}{v^- - v^+} \in (-1, 1),\quad \text{with}\quad v^- < 0 < v^+.
$$
unsuprisingly this is exactly equivalent to obtaining the evolution of ${\mathbb{E}[ \lambda_{t} ]}$ using  [[eq-lam-sde-linear-slow]] and then taking steady state value. Substituting $\lambda^{*}$ into [[eq-sde-linear]] we obtain the dynamics near the discontinuity surface. Suppose now we consider the dynamics near the steady state $(1/2, 1/2)$, let $r_t = n \cdot (x_t - 1/2, y_t -1/2) / ||n||$ and $s_t = m \cdot (x_t - 1/2, y_t - 1/2) / ||m||$ where $m = (-1, 1)$ and is tangent to $\mathcal{D}$. Using Ito's lemma we obtain 
#+name: eq-norm-sde-slow
\begin{equation}
\mathrm{d}r_t =  \sqrt{\frac{\epsilon}{2}} B^{(n)}(\lambda^{*}) \mathrm{d}W_{t}
\end{equation}
and 
#+name: eq-tang-sde-slow
\begin{equation}
\begin{aligned}
\mathrm{d}s_t &=  \sqrt{2}(x_{t} - y_{t})\mathrm{d}t + \sqrt{\frac{\epsilon}{2}} B^{(m)}(\lambda^{*}) \mathrm{d}W_{t} \\
 &=  -\sqrt{2} s_t \mathrm{d}t + \sqrt{\frac{\epsilon}{2}} B^{(m)}(\lambda^{*}) \mathrm{d}W_{t}.
\end{aligned}
\end{equation}
The latter is clearly an Ornstein-Uhlenbeck process with the stationary density
#+name: eq-tang-stat-prob
\begin{equation}
P(s) = 
\end{equation}


#+begin_src jupyter-python :session sde :exports none :eval yes :results drawer file :file stoch-traj :cache nil
import numpy as np
import matplotlib.pyplot as pp
covp = np.eye(2) 
covm = np.eye(2) 
gam = 0.0
vm = -1
vp =  vm * (gam - 1) / (1 + gam)
ep = 0.01
num_traj = 1
max_t = 200
dt = 0.001
ap = np.array([vp, vp])
am = np.array([vm, vm])
ap_func = lambda t, z: z @ np.array([[-1, 1], [1, -1]]) + ap
am_func = lambda t, z: z @ np.array([[-1, 1], [1, -1]]) + am 
covp_func = lambda t, z: covp
covm_func = lambda t, z: covm
z0 = [0.5, 0.5]
args = (ap_func, am_func, covp_func, covm_func, ep)
s_dat = euler_maruyama(drift, diff, z0, 0.0, max_t, dt, trajectories=num_traj, args=args)

fig, axs = pp.subplots(ncols=2, figsize=[6, 2])
for ti in range(num_traj):
  axs[0].plot(s_dat[0], s_dat[1][ti, :, 0], c="k", alpha=0.1)
axs[0].set_xlabel(r"$t$")  
axs[0].set_ylabel(r"$x$")  

for ti in range(num_traj):
  axs[1].plot(s_dat[1][ti, :, 0], s_dat[1][ti, :, 1], c="k", alpha=0.1)

disc_line = np.array((np.linspace(0, 1, 100), 1 - np.linspace(0, 1, 100)))
disc_line_upper_bound = disc_line + ep * np.array((np.cos(np.pi/4), np.sin(np.pi/4)))[:, None]
disc_line_lower_bound = disc_line - ep * np.array((np.cos(np.pi/4), np.sin(np.pi/4)))[:, None]
axs[1].plot(disc_line[0, :], disc_line[1, :], linewidth=0.2)
axs[1].plot(disc_line_upper_bound[0, :], disc_line_upper_bound[1, :], linewidth=0.2)
axs[1].plot(disc_line_lower_bound[0, :], disc_line_lower_bound[1, :], linewidth=0.2)

axs[1].set_xlabel(r"$x$")  
axs[1].set_ylabel(r"$y$")  
axs[1].set_xlim([0, 1])
axs[1].set_ylim([0, 1])
fig.tight_layout()
#+end_src

#+RESULTS:
[[file:stoch-traj.png]]


[[file:pwsde-assets/stoch-traj.png]]



#+RESULTS:
[[file:./.ob-jupyter/a3663d97b1387268b6dbd49f983d00f27fe8ee94.png]]


#+begin_src jupyter-python :session sde  :eval yes
n_vec = np.array([-1, -1])
atpp = 0.5 *np.dot(n_vec, app)
atmm = 0.5 *np.dot(n_vec, amm)

covtpp = np.dot(n_vec, covpp) * 0.5
covtmm = np.dot(n_vec, covmm) * 0.5

lam_drift = lambda t, lam, _: atpp + lam * atmm
lam_diff = lambda t, lam, _ : np.array([covtpp + lam[0] * covtmm])


sig = n_vec @ covp @ covp @ n_vec[:, None]
coeff = np.sqrt(-atmm / sig  / np.pi)
prob_ss = lambda lam: coeff * np.exp(atmm / sig * (lam - atpp / -atmm)**2)


slam_bins = np.linspace(-2, 2, 400)
lam_s_dat = euler_maruyama(lam_drift, lam_diff, np.array([0.0]), 0.0, max_t*4, dt*0.5, trajectories=1)
slam_mean, slam_prob_centre, slam_prob = running_time_average_and_empirical_density(lam_s_dat[0], lam_s_dat[1][0, :, 0], slam_bins)
fig, ax = pp.subplots(figsize=[4, 2])
ax.scatter(slam_prob_centre, slam_prob)
ax.plot(slam_prob_centre, prob_ss(slam_prob_centre), zorder=99, c='r')
fig.tight_layout()
fig.savefig('lam-thing.png', bbox_inches='tight')
ax.set_xlabel(r"\lambda")
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/b1c16925dc2218a401e5b9bec5254969760af6c0.png]]





#+caption: Using the x,y trajectory to compute the lambda trajectory
#+begin_src jupyter-python :session sde :exports none :eval yes :results drawer file :cache nil

orth_traj = 1 - s_dat[1][:, :, 0] - s_dat[1][:, :, 1]
t_vals = s_dat[0]; orth_vals = orth_traj[0]

lforth_vals = (np.abs(orth_vals) < ep) * orth_vals/ep + (np.abs(orth_vals) >= ep) * np.sign(orth_vals)

orth_bins = np.linspace(-10*ep, 10*ep, 100)
orth_mean, orth_prob_centre, orth_prob = running_time_average_and_empirical_density(t_vals, orth_vals, orth_bins)


lforth_bins = np.linspace(-1.1, 1.1, 100)
lforth_mean, lforth_prob_centre, lforth_prob = running_time_average_and_empirical_density(t_vals, lforth_vals, lforth_bins)

fig, axs = pp.subplots(figsize=[5, 3], nrows=2)
ax = axs[0]
ax.plot(orth_prob_centre, orth_prob)
ax.plot(ep*np.ones(100), np.linspace(0, np.max(orth_prob), 100))
ax.plot(-ep*np.ones(100), np.linspace(0, np.max(orth_prob), 100))

axs[1].scatter(slam_prob_centre, slam_prob)
fig.tight_layout()
#+end_src 

#+RESULTS:
[[file:./.ob-jupyter/78d418459362c16b99e52b615697315e3c578b64.png]]


#+caption: Test
[[file:./pwsde-assets/lam-thing.png]]



#+begin_src jupyter-python :session sde :exports none :eval yes :results yes file :file ex-ss
# lam_space = np.linspace(-2, 2, 100)
# fig, ax = pp.subplots()
# ax.plot(lam_space, prob_ss(lam_space, v, sig))
# ax.set_xlabel(r"\lambda")
# ax.set_ylabel(r"P_{ss}(\lambda)")
# fig.savefig("pwsde-assets/ex-ss.png", bbox_inches="tight")
#+end_src

#+RESULTS[1027ea2a06dd05d94b2b29721938a3bc41f2b581]:






#+begin_src jupyter-python :session sde :exports none :eval yes :results yes
import numpy as np
import matplotlib.pyplot as pp
covp = np.eye(2) 
covm = np.eye(2) 
gam = 0.0
vm = -1
vp =  vm * (gam - 1) / (1 + gam)
ep = 0.01
num_traj = 60
max_t = 5
dt = 0.001
ap = np.array([vp, vp])
am = np.array([vm, vm])
ap_func = lambda t, z: z @ np.array([[-1, 1], [1, -1]]) + ap
am_func = lambda t, z: z @ np.array([[-1, 1], [1, -1]]) + am 
covp_func = lambda t, z: covp
covm_func = lambda t, z: covm
z0 = [1.0, 0.0]
args = (ap_func, am_func, covp_func, covm_func, ep)
s_dat = euler_maruyama(drift, diff, z0, 0.0, max_t, dt, trajectories=num_traj, args=args)
args = (ap_func, am_func, covp_func, covm_func, ep*0.1)
mpp_dat = euler_maruyama(drift, lambda t, z, *args: z*0, z0, 0.0, max_t, dt, trajectories=1, args=args)[1][0]



t_vals = s_dat[0]
state_vals = s_dat[1]
mean_state_vals = state_vals.mean(0)
fig, ax = pp.subplots()
for ti in range(num_traj):
    ax.plot(t_vals, state_vals[ti, :, 0], c='k', alpha=0.1)
ax.plot(t_vals, mean_state_vals[:, 0])

#+end_src

#+RESULTS[c578ad8fd1a283651af92a8aeea093b56b5bd310]:
[[file:./.ob-jupyter/e8f80330a428e205f4df3f2edd03c0226c3c7ff9.png]]




* Understanding [[https://www.sciencedirect.com/science/article/pii/S0167278922001671?casa_token=CpEZCgN3GWgAAAAA:pSx8GzP48UUk2bQ5vytjX8PetKp6ca52FX8nIxXhwNUqKVonT-nZbdMoYtRNlNvgp7vWqln7][Hill et.al. 2022]]
In this paper they use $\Gamma$-convergence in 


* Numerical 

#+begin_src jupyter-python :session sde :exports none :eval no :results drawer 
import numpy as np
import matplotlib.pyplot as pp
import sdeint 

def emperical_density(x_series, time_series, bins, start=0):
  import numpy as np
  x = x_series[start:-1][:, None]
  delta_t = np.diff(time_series)
  bin_centres = 0.5*(bins[:-1] + bins[1:])
  bin_widths  = np.diff(bins)
  hists = (x > bins[:-1]) & (x < bins[1:])
  time_in_bin_cum = (hists * delta_t[:, None]).cumsum(0)
  t_cum = time_series[1:] - time_series[0]
  emp_prob_per_bin = time_in_bin_cum / t_cum[:, None]
  emp_density = emp_prob_per_bin / bin_widths[None, :]
  return emp_density, bin_centres, time_series[:-1]

#+end_src

#+RESULTS[27872b1f7c185d879841496923a64d19ae18b74f]:

#+name:   fig-layer-ss
#+caption: Steady state distrbution the deviations normal to $\mathcal{D}$ from the fixed 
#+begin_src jupyter-python :session sde :eval no :results none graphics :file ../assets/img/layer-sde.png :exports none

vp = 0.4
vm = -0.4
c = 1.0
ep = 0.01
delta = ep


sigma_p = 1.0 * np.array([[1.0, 0.0], [0.0, 1.0]])
sigma_m = 1.0 * np.array([[1.0, 0.0], [0.0, 1.0]])

def lam_func(x, ep):
  sig = 1 - x[0] - x[1]
  if abs(sig) < ep:
    return 1/ep * sig
  else:
    return np.sign(sig)
   

def a(x, t):
  xt = x[0]
  yt = x[1]
  la = lam_func(x, ep)
  dxdt = c*yt - c*xt + 0.5*(vp + vm + la * (vp - vm))
  dydt = c*xt - c*yt + 0.5*(vp + vm + la * (vp - vm))
  return np.array([dxdt, dydt])

def b(x, t):
  xt = x[0]
  yt = x[1]
  la = lam_func(x, ep)
  val = np.sqrt(delta) * 0.5 * (sigma_p + sigma_m + la * (sigma_p - sigma_m))
  return val

dt = 0.005
t_max = 300.0
tspan = np.linspace(0.0, t_max, 1 + int(t_max / dt))
trials = 1
x0 = np.array([0.5, 0.5])
result = np.array([sdeint.itoint(a, b, x0, tspan) for i in range(trials)])
fig, axs = pp.subplots(ncols=2)
for ax in axs:
  ax.plot(result[0, :, 0], result[0, :, 1])
  ax.plot(np.linspace(0, 1, 30), 1 - np.linspace(0, 1, 30), zorder=99, c="black")
  ax.plot(np.linspace(0, 1, 30) - ep/np.sqrt(2), 1 - np.linspace(0, 1, 30) - ep/np.sqrt(2), zorder=99, c="red")
  ax.plot(np.linspace(0, 1, 30) + ep/np.sqrt(2), 1 - np.linspace(0, 1, 30) + ep/np.sqrt(2), zorder=99, c="red")
  ax.set_xlabel("x")
  ax.set_ylabel("y")
  ax.set_aspect('equal')



axs[0].set_xlim([0.0, 1.0])
axs[0].set_ylim([0.0, 1.0])
axs[1].set_xlim([0.4, 0.6])
axs[1].set_ylim([0.4, 0.6])
fig.tight_layout()


fig.savefig("../assets/img/toy-psde-phase.png", bbox_inches="tight")

result_norm = -(result - 0.5).sum(2)
result_tang = ((result - 0.5) * np.array([1.0, -1.0])).sum(2)

norm_space = np.linspace(-0.2, 0.2, 901)

bn = np.array([-1, -1]) @ b(np.array([0.05, 0.05]), 1) / np.sqrt(delta)
bn = np.sqrt(bn @ bn.T) / np.sqrt(2) 
pdf = np.sqrt(vp / 2 / np.pi / bn**2) * np.exp(-vp / bn**2 * (norm_space**2)) 

result_norm_trans = result_norm.T
result_tang_trans = result_tang.T


# result_norm_trans_filt = result_norm_trans[abs(result_norm_trans) < ep, :]
# result_norm_trans_filt = result_norm_trans[abs(result_norm_trans) < ep, :]

emp_norm_prob, emp_norm_space, emp_norm_t = emperical_density(result_norm_trans[:, 0], tspan, np.linspace(-np.sqrt(2)*2, np.sqrt(ep)*2, 501))
emp_tang_prob, emp_tang_space, emp_tang_t = emperical_density(result_tang_trans[:, 0], tspan, np.linspace(-np.sqrt(2)*2, np.sqrt(ep)*2, 501))
 
bar = np.linspace(0, np.max(emp_norm_prob))
fig_hist, ax_hist = pp.subplots(ncols=2, figsize=[8, 3])

ax_hist[0].scatter(emp_norm_space, emp_norm_prob[-1, :])
ax_hist[0].plot(norm_space, pdf)
ax_hist[0].plot(bar*0 -ep, bar)
ax_hist[0].plot(bar*0 +ep, bar)
ax_hist[0].set_xlim([-20*ep, 20*ep])
ax_hist[0].set_ylim([0, 20])
ax_hist[0].set_xlabel(r"r")
ax_hist[0].set_ylabel(r"$P(r)$")

v = (vp - vm) * np.sqrt(2)
sig_diff = np.sqrt(ep)
fine_norm_space = np.linspace(-np.sqrt(2)*2, np.sqrt(ep)*2, 901)
ax_hist[0].plot(fine_norm_space, np.sqrt(v / np.pi / sig_diff**2) * np.exp(-v * fine_norm_space**2 / sig_diff**2))


ax_hist[1].scatter(emp_tang_space, emp_tang_prob[-1, :])
ax_hist[1].set_xlim([-1, 1])
ax_hist[1].set_ylim([0, 5])
ax_hist[1].set_xlabel(r"s")
ax_hist[1].set_ylabel(r"$P(s)$")

fig_hist.legend()
fig_hist.tight_layout()
fig_hist.savefig("../assets/img/layer-sde.png", bbox_inches="tight")

fig_norm_hist, ax_norm_hist = pp.subplots(figsize=[6, 3])
ax_norm_hist.scatter(emp_norm_space, emp_norm_prob[-1, :])

norm_pdf = lambda x, mu, sig: np.exp(-(x - mu)**2 / 2 / sig**2) / np.sqrt(2 * np.pi * sig**2)
ax_norm_hist.plot(bar*0 -ep, np.linspace(0, 1, len(bar))*np.max(emp_norm_prob[:, -1]))
ax_norm_hist.plot(bar*0 +ep, np.linspace(0, 1, len(bar))*np.max(emp_norm_prob[:, -1]))

v = (vp - vm) / np.sqrt(2)
sig_diff = np.sqrt(ep)
# pp.plot(norm_space, np.sqrt(v / np.pi / sig_diff**2) * np.exp(-v * norm_space**2 / sig_diff**2))

ax_norm_hist.set_xlim([-5*ep, 5*ep])
ax_norm_hist.set_xlabel(r"r")
ax_norm_hist.set_ylabel(r"$P(r)$")

ax_hist_hist.plot(fine_norm_space, np.sqrt(v / np.pi / sig_diff**2) * np.exp(-v * fine_norm_space**2 / sig_diff**2))
fig_norm_hist.tight_layout()
fig_norm_hist.savefig("../assets/img/layer-norm-sde.png", bbox_inches="tight")

#+end_src

#+name:   fig-toy-psde-phase
#+caption: Stochastic trajectory starting at the steady-state value. The black line is the discontinuity surface and the red lines indicate the boundaries of the $\epsilon$-layer.
[[../assets/img/toy-psde-phase.png]]


#+name:   fig-toy-psde-layer
#+caption: Steady state distrbution the deviations from the fixed point at $(1/2, 1/2)$ which are normal (left) and tangential (right) to $\mathcal{D}$.
[[../assets/img/layer-sde.png]]



#+name:   fig-toy-psde-layer-layer
#+caption: Steady state distrbution the deviations from the fixed point at $(1/2, 1/2)$ which are normal to $\mathcal{D}$.
[[../assets/img/layer-norm-sde.png]]



#+begin_src jupyter-python :session sde :exports none :eval no :results drawer
import numpy as np

x0 = np.array([0.0])
def av(x, t):
  return -2/np.sqrt(2) * (vp - vm) * x

def bv(x, t):
  return np.array([[np.sqrt(ep)]])

v = np.sqrt(2) * (vp - vm)
sig_diff = np.sqrt(ep)

dt = 0.001
t_max = 1000.0
tspan = np.linspace(0.0, t_max, 1 + int(t_max / dt))
result = sdeint.itoint(av, bv, x0, tspan)
lam_space = np.linspace(-np.sqrt(ep)*2, np.sqrt(ep)*2, 301)


(emp_prob, emp_space, tt) = emperical_density(result[:, 0], tspan, lam_space)
pp.scatter(emp_space, emp_prob[-1, :], s=10, label='Empirical (time-weighted)')
pp.plot(lam_space, np.sqrt(v / np.pi / sig_diff**2) * np.exp(-v * lam_space**2 / sig_diff**2))

#+end_src

#+RESULTS[f988200410e52f9a4597683b785ecb9a03aee9bf]:
[[file:./.ob-jupyter/0a2a5018d2492b8899b2207a7e758e3e37fd55a4.png]]


#+begin_src jupyter-python :session sde :exports none :eval yes :results drawer
import numpy as np
import matplotlib.pyplot as pp
import sdeint 
v = 1.0
diff = np.pi
ep = np.pi/3/100 * 0.01
def av(x, t):
  sig = 1 - x[0]
  if abs(sig) < ep:
    lam =  1/ep * sig
  else:
    lam = np.sign(sig)
  return np.array([lam * v])

def bv(x, t):
  sig = 1 - x[0]
  if abs(sig) < ep:
    lam =  1/ep * sig
  else:
    lam = np.sign(sig)
  return np.array([[ep**(1/2) * diff]])


dt = 0.001
t_max = 100.0
x0 = np.array([1.0])
tspan = np.linspace(0.0, t_max, 1 + int(t_max / dt))
result = sdeint.itoint(av, bv, x0, tspan)


x_space = np.linspace(0.5, 1.5 , 501)
emp_prob, emp_space, tt = emperical_density(result[:, 0], tspan, x_space)

v = v
sig_diff = ep**(1/2) * diff
pp.plot(emp_space, emp_prob[-1, :])
pp.plot(x_space, np.sqrt(v / np.pi / sig_diff**2) * np.exp(-v * (x_space - 1)**2 / sig_diff**2))


#+end_src

#+RESULTS[5a26d48b862ce485343b97ff78c4a96ecc72908a]:
[[file:./.ob-jupyter/c37cfd97dfed35d2302001d2baac18723569ea70.png]]





