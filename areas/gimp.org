
#+TITLE: Another NSSDE
#+SLUG: anothernssde
#+INCLUDE: "_macros.org"
#+PROPERTY: header-args:jupyter-python :eval no :exports code :results none :session none
#+LATEX_HEADER: \addbibresource{library.bib}
# If notes.cls doesn't load TikZ, uncomment:
# #+LATEX_HEADER: \usepackage{tikz}

#+begin_center
*18pt On stochastic differential equations with piecewise-smooth drift
and noise coefficients.*

#+end_center

#+begin_center
*14pt Seeralan Sarvaharman \(# emoji.lemon\) \(\cdot\) Aljaz Godec
\(#{emoji.lemon}^2\)*

#+end_center

*  Introduction
:PROPERTIES:
:CUSTOM_ID: introduction
:END:
** Physical Motivation
:PROPERTIES:
:CUSTOM_ID: physical-motivation
:END:
We consider stochastic differential equations arising from the
large-\(N\) limit of chemical master equations, which themselves emerge
from coarse-graining of Potts models. The resulting SDEs have two key
features:

1. *Piecewise-smooth drift*: The deterministic dynamics has a
   discontinuity across a co-dimension-one switching manifold

2. *Multiplicative noise*: The noise coefficient depends on the state
   inherited from the underlying CME

Our goal is to compute the Gaussian envelope of fluctuations around
deterministic orbits, particularly near and on the discontinuity
surface.

**  Literature and Gap
:PROPERTIES:
:CUSTOM_ID: literature-and-gap
:END:
The Freidlin-Wentzell theory of large deviations
[[#freidlinwentzell1998book][[freidlinwentzell1998book]]] provides the
foundational framework for weak-noise asymptotics of SDEs with smooth
coefficients. Extensions to piecewise-smooth systems include:

- *Chiang-Sheu* [[#chiangsheu2000][[chiangsheu2000]]],
  [[#chiangsheu2002][[chiangsheu2002]]]: Large deviations for
  discontinuous drift with additive noise, using occupation times and
  local times

- *Chen-Baule-Touchette-Just* [[#chenetal2013][[chenetal2013]]], Mostly
  asymptotics, and the system is very simple it is piecewise constant
  with additive noise.

  - Useful to check if my results match theirs in the limit.

- *Hill-Zanetell-Gemmer* [[#hilletal2022][[hilletal2022]]]: Most
  probable paths via with mollification + \(\Gamma\)-convergence,
  estimates are on the functional level, additive noise only.

  - For some reason they did not cite
    [[#chiangsheu20002][[chiangsheu20002]]]

The gap: No existing work treats multiplicative noise with discontinuous
noise coefficient and derives the Gaussian fluctuations near the
switching manifold. None have ever attempted to resolve the case when we
have hidden dynamics.

- this requires one to obtain estimates for higher moments of
  \(\lambda\) not just the mean

** Literature Gap
:PROPERTIES:
:CUSTOM_ID: literature-gap
:END:
The Freidlin-Wentzell theory of large deviations
[[#freidlinwentzell1998book][[freidlinwentzell1998book]]] deals with
weak noise SDEs with smooth drift and noise coefficient.

**  Main Contributions
:PROPERTIES:
:CUSTOM_ID: main-contributions
:END:
1. Derivation of the switching variable dynamics via Meyer-Itō

2. Rigorous derivation of the fast Fokker-Planck equation with
   reflecting boundaries, via intermediate timescale

3. Averaging principle for the slow dynamics

4. Explicit formula for the Gaussian envelope including contributions
   from switching variable fluctuations

** Background
:PROPERTIES:
:CUSTOM_ID: sec-background
:END:
#+begin_definition
Let \(\sigma : \mathbb{R}^d mapsto \mathbb{R}\) be a smooth function,
\(\epsilon > 0\), and \[x \in \mathbb{R}^d\] be a deterministic
processes satisfying the ODE

\[\frac{(\mathrm{d} x) }{(\mathrm{d} t)} = \begin{cases}
 a^{+}\left(x\right) \quad \sigma(x) > 0 \\
 a^{-}\left(x\right) \quad \sigma(x) < 0
\end{cases}\] where
\(a^{pm}: \left[0 , \infty\right) \times \mathbb{R}^d mapsto \mathbb{R}^d\)
are smooth vector fields.

#+end_definition
The switching parameter \[\lambda = \begin{cases}
 & 1 \quad \sigma(x) > 0 \\
 - & 1 \quad \sigma(x) < 0
\end{cases}\]

\[a\left(t , x , \lambda\right) = \frac{1}{2} \left(1 + \lambda\right) a_{+} \left(x\right) + \frac{1}{2} \left(1 - \lambda\right) a_{-} \left(x\right) + \left(1 - \lambda^2\right) h\left(x\right)\]

*  Piecewise-Smooth Stochastic Differential Equations
:PROPERTIES:
:CUSTOM_ID: piecewise-smooth-stochastic-differential-equations
:END:
We are interested in treating stochastic systems with weak noise whose
behaviour switches on either side of a discontinuity set. However, away
from discontinuity set we have sufficient smoothness in both the drift
field and the noise amplitude. The following definition formalises this
setup.

#+begin_definition
Let \(T > 0\), \(t \in \left[0 , T\right]\), \(\epsilon > 0\),
\(\alpha \in \left\{0 , 1 \/ 2 , 1\right\}\),
\[\sigma : \mathbb{R}^d mapsto \mathbb{R}\] be a smooth function, and
\(x_t \in \mathbb{R}^d\) be a stochastic processes satisfying the SDE

\[\mathrm{d} x_t = a\left(t , x_t\right) \mathrm{d} t + \sqrt{\epsilon} b\left(t , x_t\right) *^{\alpha} \mathrm{d} W_t,\]

where \[a\left(t , x\right) \eqdef \begin{cases}
 a^{+}\left(t , x\right) \quad \sigma(x) > 0 , \\
 a^{-}\left(t , x\right) \quad \sigma(x) < 0 ,
\end{cases} \quad b\left(t , x\right) \eqdef \begin{cases}
 b^{+}\left(t , x\right) \quad \sigma(x) > 0 , \\
 b^{-}\left(t , x\right) \quad \sigma(x) < 0 ,
\end{cases}\]

are, respectively, piecewise smooth drift and noise coefficients which
switch on the discontinuity set
\[\mathcal{D} \eqdef \left\{x \in \mathbb{R}^d | \sigma(x) = 0\right\}\]
and satisfy following conditions:

1. (A1 - Smoothnes) The constituent coefficients are sufficiently smooth
   \(a^{pm} \in C^2\left(\left[0 , T\right] \times \mathbb{R}^d; \mathbb{R}^d\right)\)
   and
   \(b^{pm}\in C^2\left(\left[0 , T\right] \times \mathbb{R}^d; \mathbb{R}^{d \times m}\right)\).
   Why did I need it to be C2? (for the tubes?)
   \(C^2 \Rightarrow \text{Lip}\)

2. (A2 - Linear growth) We have
   \[\| a^{pm}\left(t , x\right)\| + \| b^{pm}\left(t , x\right)\| \leq C^{pm} \left(1 + \| x\|\right)\]
   for some \(C > 0\), where \(\| a^{pm}\left(\cdot , \cdot\right)\|\)
   is the Euclidean norm and
   \[\| b^{pm} \left(\cdot , \cdot\right)\| = \sqrt{\sum_{i j} | b_{i j} \left(\cdot , \cdot\right) |^2} .\]

3. (A3 - Lipschitz continuity) For any \(x , y \in \mathbb{R}^d\) and
   any \(s , t \in \left[0 , T\right] ,\) we have
   \[\| a^{pm}\left(t , x\right) - a^{pm}\left(s , y\right)\| + \| b^{pm}\left(t , x\right) - b^{pm}\left(s , y\right)\| \leq K^{pm}_x \| x - y\| + K^{pm}_T | t - s | ,\]
   for some \(K^{pm} > 0\).

4. (A4 - Transversality ) For any \(x \in \mathcal{D}\)
   \[\|\partial_x \sigma(x)^{tns} b^{pm} \left(x\right)\| \geq M^{pm} > 0 .\]

5. (A5 - Bounded Jacobian)
   \[\left\| J_x[ b^{pm}_j\left(t , x\right) ]\right\| \leq C^{pm}_J\]

6. (A6 - Lipschitz Jacobian)
   \[\left\| J_x[ b^{+}_j\left(t , x\right) + b^{-}_j\left(t , x\right) ] [ b^{+}_j\left(t , x\right) + b^{-}_j\left(t , x\right) ] \\
   - J_x[ b^{+}_j\left(s , x\right) + b^{-}_j\left(t , x\right) ] [ b^{+}_j\left(t , x\right) + b^{-}_j\left(t , x\right) ]\right\| \leq H_x \| x - y\| + H_T | t - s | ,\]
   where \(b^{pm}_j\) is the \(j^{\text{th}}\) column of the noise
   matrix \(b^{pm}\).

It may be that we need the condition A4 for
\(x \in \mathcal{D}_{\epsilon}\)

The \(\alpha\) is used to control evaluation point of the stochastic
integral.

#+end_definition

The conditions (A1-3) ensure that away from the discontinuity set, that
is \[x \notin \mathcal{D}\] , we have the existence and uniqueness of
solutions. In other words away from \(\mathcal{D}\), one can employ
standard methods of SDE theory to analyse the dynamics, while near the
discontinuity one can The stochastic integral in
[[#eq-gen-sde][[eq-gen-sde]]] is understood in the α--sense, i.e. with
evaluation point
\(\left(1 - \alpha\right) x_t + \alpha x_{t + \Delta t}\). While the
recasting of typical \(\alpha\)-SDE into an Itō form is straight
forward, see for example, [[#oksendal2013book][[oksendal2013book]]] or
[[#gardiner2009book][[gardiner2009book]]], one cannot naively follow the
procedure here as the noise coefficient does not have a continuous
derivative.

Instead, we must first employ Filippovs convex construction
[[#filippov2013book][[filippov2013book]]] for the drift and noise
coefficient, with \(\lambda \in \left[- 1 , 1\right]\) we define the
convex combinations

\[a\left(t , x , \lambda\right) \eqdef \frac{1}{2}\left(1 + \lambda\right) a^{+}\left(t , x\right) + \frac{1}{2}\left(1 - \lambda\right) a^{-}\left(t , x\right) ,\]
and
\[b\left(t , x , \lambda\right) \eqdef \frac{1}{2}\left(1 + \lambda\right) b^{+}\left(t , x\right) + \frac{1}{2}\left(1 - \lambda\right) b^{-}\left(t , x\right) ,\]

which are smooth in \(\lambda\), as well as \(x\) and \(t\) as they
inherit the smoothness conditions given in
[[#def-ns-gen-sde][[def-ns-gen-sde]]]. These definitions allow as to
recast [[#eq-gen-sde][[eq-gen-sde]]] into the Itō analogue

\[\mathrm{d} x_t = \left[a\left(t , x_t, \lambda_t\right) + \alpha \epsilon c\left(t , x_t, \lambda_t\right)\right] \mathrm{d} t + \sqrt{\epsilon} b\left(t , x_t, \lambda_t\right) \mathrm{d} W_t,\]
where \(\lambda_t \in \left[- 1 , 1\right]\) for all \(t\) is a
stochastic variable and where the spurious drift is
\[c\left(t , x , \lambda\right) \eqdef \sum_j J_x \left[b_j \left(t , x , \lambda\right)\right] b_j \left(t , x , \lambda\right) .\]

with \(b_j \left(t , x , \lambda\right)\) denoting the
\(j^{#}{\text{\text{th}}}\) column of the matrix
\(b\left(t , x , \lambda\right)\) and \(J_x \left(\cdot\right)\) is the
Jacobian matrix of the vector argument with respect to \(x\).

#+begin_lemma
Let \(\epsilon > 0\) and \(\alpha \in \left[0 , 1\right]\), let
\(a : \left[0 , T\right] \times \mathbb{R}^d \times \left[- 1 , 1\right] mapsto \mathbb{R}^d\)
and
\(b : \left[0 , T\right] \times \mathbb{R}^d \times \left[- 1 , 1\right] mapsto \mathbb{R}^d\)
be defined, respectively, according to [[#eq-a-def][[eq-a-def]]] and
[[#eq-ito-al-cor-term][[eq-ito-al-cor-term]]] along with regularity
conditions given in [[#def-ns-gen-sde][[def-ns-gen-sde]]]. Then
\[a_{\alpha , \epsilon}\left(t , x , \lambda\right) \eqdef a\left(t , x , \lambda\right) + \alpha \epsilon c\left(t , x , \lambda\right) ,\]

satisfies the following regularity conditions:

1. Linear growth

\[\| a_{\alpha , \epsilon}\left(t , x , \lambda\right)\| \leq C_{\alpha} \left(1 + \| x\|\right)\]

1. Lipschitz continuity

\[\| a_{\alpha , \epsilon}\left(t , x , \lambda\right) - a_{\alpha , \epsilon}\left(s , y , \lambda\right)\| \leq K_{\alpha , x} \| x - y\| + K_{\alpha , T} | t - s |\]

#+end_lemma

#+begin_proof
/Proof./ We verify linear growth and Lipschitz continuity for
\(a_{\alpha , \epsilon}\left(t , x , \lambda\right) = a\left(t , x , \lambda\right) + \alpha \epsilon c\left(t , x , \lambda\right)\).

Linear growth. From
[[#eq-ab-lin-growth-bound][[eq-ab-lin-growth-bound]]] we have
\(\| a\left(t , x , \lambda\right)\| \leq C\left(1 + \| x\|\right)\).
For the spurious drift, \[\begin{aligned}
\| c\left(t , x , \lambda\right)\| & = \left\|\sum_jJ_x[ b_j \left(t , x , \lambda\right) ] b_j( t , x , \lambda )\right\| \\
 &\leq \sum_j \| J_x \left[b_j \left(t , x , \lambda\right)\right]\| \cdot \| b_j \left(t , x , \lambda\right)\| \\
 &\leq C_J \sum_j \| b_j \left(t , x , \lambda\right)\| \\
 &\leq C_J C \left(1 + \| x\|\right) ,
\end{aligned}\] using (A5) and linear growth of \(b\). Thus
\(\| a_{\alpha , \epsilon}\left(t , x , \lambda\right)\| \leq C\left(1 + \| x\|\right) + \alpha \epsilon C_J C \left(1 + \| x\|\right) \leq C_{\alpha}\left(1 + \| x\|\right)\)
with \(C_{\alpha} = C\left(1 + C_J\right)\).

Lipschitz continuity. From [[#eq-ab-lip-bound][[eq-ab-lip-bound]]] we
have the Lipschitz bound on \(a\). For \(c\), using (A6),
\[\begin{aligned}
\| c\left(t , x , \lambda\right) - c\left(s , y , \lambda\right)\| &\leq H_x \| x - y\| + H_T | t - s | .
\end{aligned}\] Combining,
\(\| a_{\alpha , \epsilon}\left(t , x , \lambda\right) - a_{\alpha , \epsilon}\left(s , y , \lambda\right)\| \leq K_{\alpha , x} \| x - y\| + K_{\alpha , T} | t - s |\)
with \(K_{\alpha , x} = K + \alpha \epsilon H_x\) and
\(K_{\alpha , T} = K_T + \alpha \epsilon H_T\). ◻

#+end_proof
The regularity of \(a_{\alpha , \epsilon}\) ensures that the system
[[#eq-ito-sde][[eq-ito-sde]]] inherits existence and uniqueness from
standard SDE theory away from \(\mathcal{D}\) where
\(\lambda \in \left\{- 1 , 1\right\}\). We now consider the behaviour
near and on the discontinuity set.

**  Manifestation of hidden dynamics
:PROPERTIES:
:CUSTOM_ID: sec-hidden-dyn
:END:
Notice purely by the fact that we have a non-Itō interpretation of the
multiplicative noise (\(\alpha \neq 0\)), we have have nonlinear
dependence on the switching variable and that we must have a dynamics
that exist on the discontinuity set. To elucidate this we can decompose
the drift into \[\begin{aligned}
a_{\alpha , \epsilon}\left(t , x , \lambda\right) & = \frac{1}{2}\left(1 + \lambda\right)\left\{a^{+}\left(t , x , \lambda\right) + \frac{1}{2}\left(1 + \lambda\right) \sum_j J_x\left[b^{+}_j\left(t , x\right)\right] b^{+}_j\left(t , x\right)\right\} \\
 & + \frac{1}{2}\left(1 - \lambda\right)\left\{a^{-}\left(t , x , \lambda\right) + \frac{1}{2}\left(1 - \lambda\right) \sum_j J_x\left[b^{-}_j\left(t , x\right)\right] b^{-}_j\left(t , x\right)\right\} \\
 & + \left(1 - \lambda^2\right) h\left(t , x\right) ) , \\
\end{aligned}\] where
\[h\left(t , x\right) = \eqdef \frac{1}{4} \sum_j \left\{J_x\left[b^{+}_j\left(t , x\right)\right] b^{-}_j\left(t , x\right) + J_x\left[b^{-}_j\left(t , x\right)\right] b^{+}_j\left(t , x\right)\right\} .\]

The first two terms are the expected contributions from either side of
the discontinuity, weighted by the convex interpolation. The third term,
proportional to \(\left(1 - \lambda^2\right)\), is qualitatively
different. It vanishes when \(\lambda = pm 1\) and attains its maximum
when \(\lambda = 0\), i.e. precisely on the discontinuity set
\(\mathcal{D}\). We call \(h\left(t , x\right)\) the *hidden drift*.

In deterministic piecewise-smooth systems, hidden terms of this form
arise in the analysis of sliding modes and can affect the dynamics on
the discontinuity set even though they vanish away from it
[[#jeffrey2014][[jeffrey2014]]],
[[#jeffrey2018book][[jeffrey2018book]]],
[[#kuehn2015book][[kuehn2015book]]]. Here the situation is more subtle:
the switching variable \(\lambda_t\) is stochastic, and the contribution
of \(h\left(t , x\right)\) to the averaged dynamics depends on the
second moment \(\EE\left[\lambda^2\right]\) under the stationary
distribution \(P_{ss}\left(\lambda | x\right)\) obtained as the long
time limit of the fast dynamics of \(\lambda\), whilst fixing \(x\).

To see this, suppose we wish to replace [[#eq-ito-sde][[eq-ito-sde]]]
with an averaged counterpart. The averaged drift takes the form
\[\begin{aligned}
\bar{a}_{\alpha , \epsilon}\left(t , x\right) & = \int_{- 1}^1 a_{\alpha , \epsilon}\left(t , x , \lambda\right) P_{ss}\left(\lambda | x\right) \mathrm{d} \lambda \\
 & = \frac{1}{2}\left(1 + \bar{\lambda}\right)\left[a^{+}\left(t , x\right) + \frac{(\alpha \epsilon)}{2} c^{+}\left(t , x\right)\right] + \frac{(\alpha , \epsilon)}{4} \left(\bar{\lambda} + \bar{\lambda^2}\right) c^{+}\left(t , x\right) \\
 & + \frac{1}{2}\left(1 - \bar{\lambda}\right)\left[a^{-}\left(t , x\right) + \frac{(\alpha \epsilon)}{2} c^{-}\left(t , x\right)\right] + \frac{(\alpha , \epsilon)}{4} \left(\bar{\lambda} + \bar{\lambda^2}\right) c^{-}\left(t , x\right) \\
 & + \frac{(\alpha \epsilon)}{4} \left(1 - \bar{\lambda^2}\right) h\left(t , x\right) ,
\end{aligned}\]

where \(\bar{\lambda} = \EE\left[\lambda\right]\) and
\(\bar{\lambda^2} = \EE\left[\lambda^2\right]\) are moments under
\(P_{ss}\left(\lambda | x\right)\), and
\[c^{pm} \left(t , x\right) = \sum_j J_x \left[b^{pm}_j\right] b^{pm}_j\]
are the Itō corrections on either side. We see that if we wish to
replace the [[#eq-ito-sde][[eq-ito-sde]]], with an average counterpart,
averaged over the differential inclusion, we must know at least the
second moment, i.e. \(\EE\left[\lambda^2\right]\), if we wish to be
faithful to the hidden dynamics.

This is a crucial distinction from existing work on piecewise-smooth
SDEs which have been primarily interested in PWS drift fields and with
smooth additive noise. In such a case one has \(b^{+} = b^{-}\), the
hidden drift \(h\left(t , x\right)\) vanishes identically and the
averaged dynamics depends only on \(\bar{\lambda}\). Whereas we not only
consider the case \(b^{+} \neq b^{-}\) but also when the noise is
multiplicative as is often the case in biological and chemical systems.

*  Main Result
:PROPERTIES:
:CUSTOM_ID: main-result
:END:
Our main result concerns the typical paths of the piecewise-smooth SDE
[[#eq-ito-sde-simp][[eq-ito-sde-simp]]]. We show that \(x_t\) is
well-approximated by a reduced SDE obtained by averaging over the fast
switching dynamics, and that this approximation is sufficiently strong
to characterise both the typical paths and the Gaussian fluctuations
around them. In more formal terms, suppose \(x_t\) solves
[[#eq-ito-sde-simp][[eq-ito-sde-simp]]] with coefficients satisfying the
regularity conditions of [[#def-ns-gen-sde][[def-ns-gen-sde]]], and
suppose \(y_t\) solves the reduced SDE

\[\mathrm{d} y_t = \bar{a}_{\alpha , \epsilon}\left(t , y_t\right) \mathrm{d} t + \sqrt{\epsilon} \bar{b}\left(t , y_t\right) \mathrm{d} W_t,\]
where \(\bar{a}\) and \(\bar{b}\) are obtained by averaging against the
stationary distribution \(P_{ss}\left(\lambda | x\right)\) of the
switching variable obtained by fixing \(x \in \mathcal{D}\). Then for
any \(T > 0\) and \(\gamma > 0\), we show that
\[\PP\left[\sup_{t \in \left[0 , T\right]} \| x_t - y_t\| > \gamma\right] \leq \frac{C_T }{\gamma^2} \sqrt{\epsilon} ,\]
where \(C_T\) depends on \(T\) and the regularity constants.

The reduced system has sufficiently smooth coefficients as wells as
inheriting the regularity conditions from
[[#def-ns-gen-sde][[def-ns-gen-sde]]], it therefore satisfies a large
deviation principle via Freidlin-Wentzell theory with rate function
\[I_T \left[\varphi\right] = \begin{cases}
 \frac{1}{2} \int_0^T \|\left[\dot{\varphi}_t - \bar{a}\left(t , \varphi_t\right)\right]^{tns}\bar{d}\left(t , \varphi_t\right)^{- 1}\left[\dot{\varphi}_t - \bar{a}\left(t , \varphi_t\right)\right]\|^2 \mathrm{d} t \quad & \varphi \in \text{a.c. on } \left[0 , T\right] \\
 +\infty \quad & \text{otherwise}
\end{cases}\] where \(\varphi_0 = y_0\) and
\[\bar{d}\left(t , x\right) \eqdef \bar{b}\left(t , x\right) \bar{b}\left(t , x\right)^{tns}.\]

The \(\mathcal{O}\left(\sqrt{\epsilon}\right)\) error bound on the paths
of \(x_t\) and \(y_T\) is not sufficient to transfer the LDP from
\(y_t\) to \(x_t\). However, it does ensure that the paths of \(x_t\)
lie in some neighbourhood around the typical paths of \(y_t\) obtained
by the minimisation of \(I_T\). The bound is also sufficient to transfer
the Gaussian flucations around the typical, that is a Gaussian tube from
\(y_t\) on to \(x_t\).

The remainder of the manuscript is organised as follows. In
[[#sec-dyn-lam][4]] we derive the dynamics of the switching variable via
Meyer-Itô calculus. In [[#sec-delta-time][5]] we introduce the
intermediate timescale and justify the separation between fast and slow
dynamics. In [[#sec-est-on-del][6]] we establish probabilistic estimates
for the switching variable, including exponential mixing. In
[[#sec-avg-principle][7]] we prove the averaging principle for the
piecewise-smooth SDE. Finally, in [[#sec-typical-paths][8]] we show that
the typical paths of the original and averaged systems coincide.

*  Dynamics of the switching variable
:PROPERTIES:
:CUSTOM_ID: sec-dyn-lam
:END:
The switching variable depends on the state and we will regularise the
definition given in [[#eq-lam-def][[eq-lam-def]]] as
\[\lambda = \Lambda_{\epsilon}\left[\sigma(x)\right]\]

where \[\Lambda_{\epsilon} \left(u\right) \eqdef \begin{cases}
 u \/ \epsilon \quad &\sigma( x) & \leq \epsilon \\
 sign\left[\sigma(x)\right] \quad &\sigma( x) & > \epsilon
\end{cases}\]

is an auxiliary function used to control the regularisation. Notice that
the regularisation implicitly defines the layer

\[\mathcal{D}_{\epsilon} \eqdef \left\{x \in \mathbb{R}^d | |\sigma( x) | \leq \epsilon\right\} ,\]

and which affords a precise meaning to the term dynamics near the
discontinuity, i.e. when \(x_t \in \mathcal{D}\).

Due to the dependent on the stochastic state variable \(\lambda\) is
itself a stochastic variable since it dependends on \(x_t\) via
\[\lambda_t = \Lambda_{\epsilon}\left[\sigma(x_t)\right]\] , and, like
its deterministic counterpart is dynamic on the the much faster
timescale \(\mathcal{O}\left(1 \/\epsilon\right)\). However, one cannot
simply employ Itōs Lemma on
\(\lambda_t = \Lambda_{\epsilon}\left[\sigma(x_t)\right]\) as the latter
is not a smooth function of \(x_t\). Instead to study the dynamics of
\(\lambda_t\) we must first introduce two new concepts: local time of a
semi-martingale and the Meyer-Itō Theorem.

Local time of a semi-martingale \(x_t\), denoted with
\(L^x_t \left(z\right)\)is a measure of the visits of the process on a
given value \(z\) for times up to \(t\). It is given via Tanakas formula
which we summarise in the following definition.

#+begin_definition
Let \(x_t\) be a semi-martingale in \(\mathbb{R}^d\), and let
\(L^x_{t\left(z\right)}\) be the local time of the process at level

\[| x_t - z | = | x_0 - z | + \int_0^t \operatorname{sign}(x_t - a) \mathrm{d} x_s + L^x_t \left(z\right)\]
where

\[\operatorname{sign}(x) = \begin{cases}
 & 1 \quad & x & > 0 , \\
 - & 1 \quad & x & \leq 0 .
\end{cases}\]

#+end_definition
For derivation and discussion see See Chap. 3 of
[[#karatzasshreve2014book][[karatzasshreve2014book]]], and Chap. IV of
[[#protter2012book][[protter2012book]]]. Secondly we require the
Meyer-Itō theorem, also called the genearlised Itōs formula. We restate
it here without the proof which can be found in Theorem 70, Chapter IV
of [[#protter2012book][[protter2012book]]].

#+begin_theorem
Let \(f : \mathbb{R}^d mapsto \mathbb{R}\) be the difference of two
convex functions, \(f^{-}\) denote its left derivative, \(\mu_f\) be
signed measure of the second derivative of \(f\) in the generalised
function (distribution) sense, and let \(x_t\) be a semi-martingale in
\(\mathbb{R}^d\) then evolution of \(f\left(x_t\right)\) is given by
\[f\left(x_t\right) = f\left(x_0\right) + \int_0^t f^{-}\left(x_t\right) \mathrm{d} x_t + \frac{1}{2} \int_{\mathbb{R}^d} L^x_t \left(z\right) \mathrm{d} \mu_f\left(z\right)\]

where \(L^x_t \left(z\right)\) is the local time of \(x_t\) at \(z\) and
the final integral in [[#eq-ito-meyer][[eq-ito-meyer]]] is a
Lebesgue-Stieltjes integral.

#+end_theorem

For \(f \in C^2\), the local time integral vanishes and
[[#eq-ito-meyer][[eq-ito-meyer]]] reduces to Itōs lemma. The local time
\(L^x_{t\left(z\right)}\) can equivalently be defined as

\[L_t^x \left(z\right) = \lim_{\delta \downarrow 0} \frac{1}{(2\delta)} \int_0^t \mathbb{1}_{\left(z - \delta , z + \delta\right)}\left(x_s\right) \mathrm{d} \langle x \rangle_s,\]
which measures the accumulated quadratic variation of \(x_t\) at level
\(z\).

- convex functions of martingales are themselves martingales

- generalises itos theorem

  - add example about how it reduces to the standard itos lemma when
    \(f\) has a second derivative

In order to apply [[#thm-ito-meyer][[thm-ito-meyer]]] to
\(\lambda_t = \Lambda_{\epsilon}\left[\sigma(x_t)\right]\), we must
first express the regulariser as a difference of convex functions which
is easily done as the following lemma shows.

#+begin_lemma
The function \(\Lambda_{\epsilon} \left(u\right)\) as defined in
[[#eq-big-lam-def][[eq-big-lam-def]]], can written as

\[\Lambda_{\epsilon} \left(u\right) = \varphi_{\epsilon}^{+} \left(u\right) - \varphi_{\epsilon}^{-} \left(u\right)\]
where \(\varphi^{pm}\left(u\right)\) are convex functions.

#+end_lemma

#+begin_proof
/Proof./ Let \[\psi_{+ , \epsilon}\left(u\right) \eqdef \begin{cases}
 - 1 \quad & u &\leq -\epsilon , \\
 u \/ \epsilon \quad & u & > -\epsilon ,
\end{cases} \quad \quad \psi_{- , \epsilon}\left(u\right) \eqdef \begin{cases}
 0 \quad & u &\leq \epsilon , \\
 u \/ \epsilon - 1 \quad & u & > \epsilon
\end{cases} ,\] which are convex in \(u\). ◻

#+end_proof
Notice that the functions \(\psi^{pm}\) chosen are left continuous, i.e.
\[\lim_{u \downarrow a}\psi_{pm , \epsilon} = \psi_{pm , \epsilon} \left(a\right)\]
, for all \(a \in \mathbb{R}\). This is intentional as we must require
the left derivative of \(\Lambda_{\epsilon(u)}\) given by
\[\begin{aligned}
\Lambda^{-}_{\epsilon(u)} & = \psi^{-}_{+ , \epsilon}\left(u\right) - \psi^{-}_{- , \epsilon}\left(u\right) = \begin{cases}
 0 \quad & u\leq -\epsilon , \\
 1 \/\epsilon \quad &\epsilon < u \leq \epsilon , \\
 0 \quad & u > \epsilon .
\end{cases}
\end{aligned}\]

Similarly we have second derivative as a signed measure
\[\mu_{\Lambda_{\epsilon}^}\left(u\right) = \frac{1}{\epsilon} \delta(u + \epsilon) - \frac{1}{\epsilon} \delta(u - \epsilon) ,\]

where \(\delta(u)\) is the Dirac-delta distribution. Since
\(\Lambda_{\epsilon}\) is DC, its left derivative and distributional
second derivative are well-defined, which we require for Meyer-Itō. For
the latter, also need the dynamics of scalar observable \(\sigma(x_t)\)
which we state in the following lemma.

#+begin_lemma
Let \(\lambda \in \left[- 1 , 1\right]\),
\(\sigma \in C^2\left(\mathbb{R}^d, \mathbb{R}\right)\), \(x_t\) be an
Itō process according to [[#eq-ito-sde][[eq-ito-sde]]], supplemented by
the regularity conditions in [[#def-ns-gen-sde][[def-ns-gen-sde]]] and
[[#lem-coeffs-lam][[lem-coeffs-lam]]] then the random variable
\(z_t = \sigma(x_t)\) evolves according to the SDE

\[\mathrm{d} z_t = \widetilde{a}_{\alpha , \epsilon}\left(t , x_t, \lambda_t\right) \mathrm{d} t + \sqrt{\epsilon}\widetilde{b}\left(t , x_t, \lambda_t\right) \mathrm{d} W_t,\]
where
\[\widetilde{a}_{\alpha , \epsilon}\left(t , x , \lambda\right) \eqdef \partial_x \sigma(x)^{tns} \left[a\left(t , x , \lambda\right) + \alpha \epsilon c\left(t , x , \lambda\right)\right] + \frac{\epsilon}{2} trc\left[b\left(t , x , \lambda\right) \partial^2_{x x} \sigma(x) b\left(t , x , \lambda\right)\right] ,\]
and
\[\widetilde{b}\left(t , x , \lambda\right) \eqdef \partial_x \sigma(x)^{tns} b\left(t , x , \lambda\right) ] ,\]

#+end_lemma

#+begin_proof
/Proof./ This is trivial application of Itōs lemma. Since
\(\sigma(x_t)\) is smooth, apply Itōs lemma to obtain
\[\mathrm{d} z_t = \partial_x \sigma(x_t)^{tns} \mathrm{d} x_t + \mathrm{d} x_t^{tns} \partial^2_{x x} \sigma(x) \mathrm{d} x^{tns},\]

then substitute for \(\mathrm{d} x_t\) from
[[#eq-ito-sde][[eq-ito-sde]]] into
[[#eq-dz-ito-lemma][[eq-dz-ito-lemma]]] and apply Itōs product rule. ◻

#+end_proof
We are now in a position to consider the dynamics of the switching
variable as an SDE. By combining [[#thm-ito-meyer][[thm-ito-meyer]]]
with [[#lem-z-sde][[lem-z-sde]]] we obtain the dynamics of the switching
variable. The dynamics of the switching variable, much like its
deterministic counterpart, operates on the faster timescale
\(\mathcal{O}\left(1 \/\epsilon\right)\). Unlike the deterministic case,
however, the SDE contains local time terms at the boundaries
\(\lambda = pm 1\) which enforce reflection and keep \(\lambda_t\) in
the interval \(\left[- 1 , 1\right]\). We formulate this precisely in
the following theorem.

#+begin_theorem
Let \(\epsilon > 0\),
\(\sigma \in C^2\left[\mathbb{R}^d, \mathbb{R}\right]\) such that
\[\mathcal{D}_{\epsilon} = \left\{x \in \mathbb{R}^d | \sigma(x) \leq \epsilon\right\}\]
is close set, let \(x_t \in \mathcal{D}_{\epsilon}\) evolve according to
according to [[#eq-ito-sde][[eq-ito-sde]]], and let
\(\Lambda_{\epsilon} \left(u\right)\) be a be a family of regularisers
of the sign function as defined in
[[#eq-big-lam-def][[eq-big-lam-def]]]. then the switching variable
\(\lambda_t = \Lambda_{\epsilon} \left[\sigma(x_t)\right]\) evolves in
the interval interval [1, 1] according to the SDE \[\begin{aligned}
\mathrm{d} \lambda_t & = \frac{1}{\epsilon} \mathbb{1}_{\left(-\epsilon , \epsilon\right]}\left[\sigma(x_t)\right] \widetilde{a}_{\alpha , \epsilon}\left(t , x_t, \lambda_t\right) \mathrm{d} t + \frac{1}{\sqrt{\epsilon}} \mathbb{1}_{\left(-\epsilon , \epsilon\right]}\left[\sigma(x_t)\right] \widetilde{b}\left(t , x_t, \lambda_t\right) \mathrm{d} W_t \\
 & + \frac{1}{\epsilon} \left[\mathrm{d} L_t^z\left(-\epsilon\right) - \mathrm{d} L_t^z\left(\epsilon\right)\right] , \\
\end{aligned}\]

where \(\widetilde{a}_{\alpha , \epsilon}\left(t , x , \lambda\right)\)
and \(\widetilde{b}\left(t , x , \lambda\right)\) are defined in
[[#eq-a-tilde-def][[eq-a-tilde-def]]] and
[[#eq-b-tilde-def][[eq-b-tilde-def]]] respectively,
\(\mathrm{d} L_t^z\left(pm \epsilon\right)\) is the change in the local
time of \(z_t\) at \(z = pm \epsilon\) where the evolution of \(z_t\) is
given by [[#eq-z-sde][[eq-z-sde]]].

#+end_theorem

#+begin_proof
/Proof./ Since \(\Lambda_{\epsilon} \left(u\right)\) is a difference of
convex functions, whose left derivative is given in
[[#eq-big-lam-left-deriv][[eq-big-lam-left-deriv]]] and signed second
derivative given as a measure given in
[[#eq-big-lam-sec-deriv][[eq-big-lam-sec-deriv]]], it then follows from
[[#thm-ito-meyer][[thm-ito-meyer]]], that for a generic random variable
\(z_t\) we have
\[\Lambda_{\epsilon}\left(z_t\right) = \Lambda_{\epsilon}\left(z_0\right) + \frac{1}{\epsilon} \int_0^t \mathbb{1}_{\left(-\epsilon , \epsilon\right]}\left(z_t\right) \mathrm{d} z_t + \frac{\epsilon}{2} \left[L^z_t\left(-\epsilon\right) - L^z_t\left(\epsilon\right)\right] .\]
By letting
\(\lambda_t = \Lambda_{\epsilon} \left(z_t = \sigma(x_t)\right)\), and
using [[#lem-z-sde][[lem-z-sde]]] we obtain \[\begin{aligned}
\lambda_t & = \mu + \int_0^t \frac{1}{\epsilon} \mathbb{1}_{\left(-\epsilon , \epsilon\right]}\left[\sigma(x_s)\right] \widetilde{a}_{\alpha , \epsilon}\left(s , x_s, \lambda_s\right) \mathrm{d} s + \frac{1}{\sqrt{\epsilon}} \int_0^t \mathbb{1}_{\left(-\epsilon , \epsilon\right]}\left[\sigma(x)\right] \widetilde{b}\left(s , x_s, \lambda_s\right) \mathrm{d} W_s \\
 & + \frac{1}{\epsilon} \left[L_t^z\left(-\epsilon\right) - L_t^z\left(\epsilon\right)\right] .
\end{aligned}\] ◻

#+end_proof
The local time terms in [[#eq-lam-sde][[eq-lam-sde]]] enforce reflection
at \(\lambda = pm 1\), or analogously when \(z_t\) reaches
\(pm \epsilon\), the switching variable saturates and the local time
increments prevent escape from \(\left[- 1 , 1\right]\). The dynamics of
the full system are then represented by a coupled SDE

#+begin_corollary
Under the conditions of [[#thm-lam-sde][[thm-lam-sde]]], the pair
\(\left(t , x_t, \lambda_t\right)\) with
\(x_t \in \mathcal{D}_{\epsilon}\) and
\(\lambda_t = \Lambda_{\epsilon}\left(\sigma(x_t)\right) \in \left[- 1 , 1\right]\),
satisfies the coupled system \[\begin{aligned}
\mathrm{d} x_t & = a_{\alpha , \epsilon}\left(t , x_t, \lambda_t\right) \mathrm{d} t + \sqrt{\epsilon} b\left(t , x_t, \lambda_t\right) \mathrm{d} W_t, \\
 \mathrm{d} \lambda_t & = \frac{1}{\epsilon} \mathbb{1}_{\left(-\epsilon , \epsilon\right]}\left[\sigma(x_t)\right] \widetilde{a}_{\alpha , \epsilon}\left(t , x_t, \lambda_t\right) \mathrm{d} t + \frac{1}{\sqrt{\epsilon}} \mathbb{1}_{\left(-\epsilon , \epsilon\right]}\left[\sigma(x_t)\right] \widetilde{b}\left(t , x_t, \lambda_t\right) \mathrm{d} W_t \\
 & + \frac{1}{\epsilon} \left[\mathrm{d} L_t^z\left(-\epsilon\right) - \mathrm{d} L_t^z\left(\epsilon\right)\right] ,
\end{aligned}\] where
\(a_{\alpha , \epsilon}\left(t , x , \lambda\right)\) and
\(b\left(t , x , \lambda\right)\) are defined, respectively, in
[[#eq-a-al-ep-def][[eq-a-al-ep-def]]] and [[#eq-b-def][[eq-b-def]]],
while \(\widetilde{a}_{\alpha , \epsilon}\left(t , x , \lambda\right)\)
and \[\widetilde{b}\left(x , \lambda\right)\] are given defined in
[[#eq-a-tilde-def][[eq-a-tilde-def]]] and
[[#eq-b-tilde-def][[eq-b-tilde-def]]] respectively.

#+end_corollary

The coupled system is a slow-fast stochastic system, and our goal is to
obtain controlled approximation for the dynamics of the slow process by
closing the dynamics of the switching variable \(\lambda_t\). Before we
study that let us recapitulate the various coefficients that we have
discussed: \(a^{pm} \left(t , x\right)\) and
\(b^{pm} \left(t , x\right)\) are the drift and noise coefficients for
the SDE on either side of the discontinuity from
[[#def-ns-gen-sde][[def-ns-gen-sde]]]; \(a\left(t , x , \lambda\right)\)
and \(b\left(t , x , \lambda\right)\) are the convex combination of the
drift and noise coefficients defined in [[#eq-a-def][[eq-a-def]]] and
[[#eq-b-def][[eq-b-def]]] respectively;
\(a_{\alpha , \epsilon}\left(t , x , \lambda\right)\) is the full drift
for the Itō SDE including the spurious drift,
\[\widetilde{a}_{\alpha , \epsilon}\left(t , x , \lambda\right)\] and
\(\widetilde{b}\left(t , x , \lambda\right)\) are the convex combination
of the drift and noise coefficients projected onto the (unscaled) normal
of the discontinuity set and are defined in
[[#eq-a-tilde-def][[eq-a-tilde-def]]] and
[[#eq-b-tilde-def][[eq-b-tilde-def]]] respectively; lastly it is useful
to define the projected diffusion coefficient

\[\widetilde{d}\left(t , x , \lambda\right) \eqdef \widetilde{b}\left(t , x , \lambda\right) \widetilde{b}\left(t , x , \lambda\right)^{tns} = \partial_x \sigma(x)^{tns} b\left(t , x , \lambda\right) b\left(t , x , \lambda\right)^{tns} \partial_x \sigma(x) .\]

Despite the switching variable being random, because it is bounded,
\[\lambda_t \in \left[- 1 , 1\right]\] , all of these coefficients
inherit the conditions of \(a\) and \(b\) as laid out in
[[#def-ns-gen-sde][[def-ns-gen-sde]]]. We summerise these in the
following lemma as they will then be used in the later results.

#+begin_lemma
Let \(x \in \mathcal{D}_{\epsilon}\) and
\(\lambda \in \left[- 1 , 1\right]\). Suppose the coefficients
\(a^{pm}\) and \(b^{pm}\) satisfy assumptions (A1)--(A4) of
[[#def-ns-gen-sde][[def-ns-gen-sde]]], and let
\(a\left(t , x , \lambda\right)\) and \(b\left(t , x , \lambda\right)\)
be the convex combinations defined in [[#eq-a-def][[eq-a-def]]] and
[[#eq-b-def][[eq-b-def]]], and let
\(\widetilde{b}\left(t , x , \lambda\right)\) and
\[\widetilde{d}\left(x , \lambda\right)\] be projected coefficients
defined in [[#eq-b-tilde-def][[eq-b-tilde-def]]] and
[[#eq-d-tilde-def][[eq-d-tilde-def]]]. Then there exist constants
\(C , K , \widetilde{M} > 0\), independent of \(\lambda\), such that the
following bounds hold.

1. Linear growth. For any \(x \in \mathbb{R}^2\) and
   \(t \in\left[0 , T\right]\),

\[\| a_\left(t , x , \lambda\right)\| + \| b\left(t , x , \lambda\right)\| \leq C \left(1 + \| x\|\right) .\]

1. Lipschitz continuity. For any \(x , y \in \mathbb{R}^d\) and any
   \(t , s \in \left[0 , T\right]\),

\[\| a\left(t , x , \lambda\right) - a\left(s , y , \lambda\right)\| + \| b\left(t , x , \lambda\right) - b\left(s , y , \lambda\right)\| \leq K \| x - y\| + K_T | t - s | .\]

1. Transversality. For any \(x\) in \(\mathcal{D}_{\epsilon}\) and
   \(\lambda \in \left[- 1 , 1\right]\)
   \[\| \widetilde{b}\left(t , x , \lambda\right) \| \geq \widetilde{M} > 0 , \quad \| \widetilde{d}\left(t , x , \lambda\right) \| \geq \widetilde{M}^2 > 0 .\]

#+end_lemma

#+begin_proof
/Proof./

1. Linear growth. Using the definition of combined coefficients \(a\)
   and the triangle inequality we obtain

   \[\begin{aligned}
   \| a\left(t , x , \lambda\right)\| &\leq \frac{1}{2} \left(1 + \lambda\right) \| a_{+} \left(t , x\right)\| + \frac{1}{2} \left(1 - \lambda\right) \| a_{-} \left(t , x\right)\| , \\
    &\leq \frac{1}{2} \left[\left(1 + \lambda\right) C_{+} + \left(1 - \lambda\right) C_{-}\right] \left(1 + | x |\right) , \\
    &\leq \left(C_{+} + C_{-}\right)\left(1 + \| x\|\right) .
   \end{aligned}\] Carrying out the same steps for \(b\) and combining
   them gives bound for \(b\) is carried in the same manner gives the
   linear growth bound in the lemma where \(C = C_{+} + C_{-}\)

2. Lipschitz continuity. For any \(x , y \in \mathbb{R}^d\) and any
   \(t , s \in \left[0 , T\right]\) we have by the triangle inequality
   \[\begin{aligned}
   \| a\left(t , x , \lambda\right) - a\left(s , y , \lambda\right)\| &\leq \frac{1}{2} \left(1 + \lambda\right) \| a^{+}\left(t , x\right) - a^{+}\left(s , y\right)\| \\
    & + \frac{1}{2} \left(1 - \lambda\right) \| a^{-}\left(t , x\right) - a^{-}\left(s , y\right)\| , \\
    &\leq \frac{1}{2} \| x - y\| \left[\left(1 + \lambda\right) K^{+} + \left(1 - \lambda\right) K^{+}\right], \\
    & + \frac{1}{2} | t - s | \left[\left(1 + \lambda\right) K^{+}_T + \left(1 - \lambda\right) K^{+}_T\right] \\
    &\leq \| x - y\| \left(K^{+} + K^{-}\right) + | t - s | \left(K^{+}_T + K^{-}_T\right).
   \end{aligned}\]

   Again carrying out the same procedure for \(b\) and combining them
   gives the condition in the lemma where \(K_T = K^{+}_T + K^{-}_T\)
   and \(K = K^{+} + K^{-}\).

3. Transversality. From the definition of
   \(\widetilde{b}\left(t , x , \lambda\right)\) we have
   \[\begin{aligned}
   \| \widetilde{b}\left(t , x , \lambda\right) \| & = \|\partial_x \sigma(x)^{tns} b\left(t , x , \lambda\right)\| , \\
    & = \left\|\frac{1}{2}\partial_x\sigma(x)^{tns}[\left(1 + \lambda\right) b^{+} \left(t , x\right) + \left(1 - \lambda\right) b^{-} \left(t , x\right) ]\right\| , \\
    &\geq \frac{1}{2} \left[\left(1 + \lambda\right) M^{+} + \left(1 - \lambda\right) M^{-}\right] , \\
    &\geq \min(M^{+}, M^{-}) .
   \end{aligned}\] Setting \(\widetilde{M} = \min(M^{+}, M^{-})\) gives
   the bound in the lemma while taking the square gives the bound on the
   projected diffusion coefficient.

 ◻

#+end_proof
The linear growth conditions also
[[#lem-coeff-tilde-bounds][[lem-coeff-tilde-bounds]]] imply finite
polynomial moments which we summerise in the following lemma.

#+begin_lemma
Let \(x_t\) evolve according to
[[#eq-x-lam-sde-pair][[eq-x-lam-sde-pair]]], let
\(x_0 \in \mathbb{R}^d\) be some initial condition, let
\[t \in \left[0 , T\right]\] , then there exists a constant
\(C_{2 , T} > 0\) such that

\[\EE\left[\| x_t\|^2\right] \leq C_{2 , T} \left(1 + \| x_0\|^2\right).\]

Maybe we can show by induction for all \(k\).

#+end_lemma

#+begin_proof
/Proof./ By setting
\(f\left(x\right) = \| x\|^2 = \sum_i \left(x^{\left(i\right)}\right)^2\)
and applying Itōs lemma to [[#eq-ito-sde-simp][[eq-ito-sde-simp]]],
\[\begin{aligned}
\mathrm{d} \| x_t\|^2 & = \sum_i 2 x^{\left(i\right)}_t \mathrm{d} x^{\left(i\right)}_t + \sum_i \mathrm{d} \langle x^{\left(i\right)} \rangle_t \\
 & = 2 x_t^{tns} \left[a_{\alpha , \epsilon}\left(t , x_t, \lambda_t\right) \mathrm{d} t + \sqrt{\epsilon} b\left(t , x_t, \lambda_t\right) \mathrm{d} W_t\right] \\
 &\quad + \epsilon \sum_{i , j} | b_{i j}\left(t , x_t, \lambda_t\right)|^2 \mathrm{d} t \\
 & = 2 x_t^{tns} a_{\alpha , \epsilon}\left(t , x_t, \lambda_t\right) \mathrm{d} t + 2 \sqrt{\epsilon} x_t^{tns} b\left(t , x_t, \lambda_t\right) \mathrm{d} W_t \\
 &\quad + \epsilon \| b\left(t , x_t, \lambda_t\right)\|^2 \mathrm{d} t .
\end{aligned}\]

Taking expectations, the stochastic integral vanishes and we obtain
\[\frac{\mathrm{d} }{(\mathrm{d} t)} \EE\left[\| x_t\|^2\right] = 2 \EE\left[x_t^{tns} a_{\alpha , \epsilon}\left(t , x_t, \lambda_t\right)\right] + \epsilon \EE\left[\| b\left(t , x_t, \lambda_t\right)\|^2\right].\]

For the drift term, by Cauchy-Schwarz and the linear growth bound
[[#eq-ab-lin-growth-bound][[eq-ab-lin-growth-bound]]], \[\begin{aligned}
\EE\left[x_t^{tns} a_{\alpha , \epsilon}\left(t , x_t, \lambda_t\right)\right] &\leq \EE\left[\| x_t\| \cdot \| a_{\alpha , \epsilon}\left(t , x_t, \lambda_t\right)\|\right] \\
 &\leq C_{\alpha} \EE\left[\| x_t\| \left(1 + \| x_t\|\right)\right] \\
 & = C_{\alpha} \EE\left[\| x_t\|\right] + C_{\alpha} \EE\left[\| x_t\|^2\right] \\
 &\leq C_{\alpha} \left(1 + \EE\left[\| x_t\|^2\right]\right).
\end{aligned}\] where in the last step we used
\(\EE\left[\| x_t\|\right] \leq 1 + \EE\left[\| x_t\|^2\right]\)
which follows from \(a \leq 1 + a^2\) for \(a \geq 0\).

For the diffusion term, again by linear growth, \[\begin{aligned}
\EE\left[\| b\left(t , x_t, \lambda_t\right)\|^2\right] &\leq C^2 \EE\left[\left(1 + \| x_t\|\right)^2\right] \\
 & = C^2 \EE\left[1 + 2\| x_t\| + \| x_t\|^2\right] \\
 &\leq C^2 \left(3 + 3 \EE\left[\| x_t\|^2\right]\right),
\end{aligned}\] again by using \(2 a \leq 1 + a^2\). Combining both
estimates, \[\begin{aligned}
\frac{\mathrm{d} }{(\mathrm{d} t)} \EE\left[\| x_t\|^2\right] &\leq 2 C_{\alpha} \left(1 + \EE\left[\| x_t\|^2\right]\right) + 3 \epsilon C^2 \left(1 + \EE\left[\| x_t\|^2\right]\right) \\
 & = \left(2 C_{\alpha} + 3 \epsilon C^2\right)\left(1 + \EE [| | x_t\|^2]\right) \\
 &\leq C\left(1 + \EE\left[\| x_t\|^2\right]\right),
\end{aligned}\] with \(C = 2 C_{\alpha} + 3 C^2\) (taking
\(\epsilon \leq 1\)). Finally, employing Gronwalls inequality we obtain
\[\EE\left[\| x_t\|^2\right] \leq \left(\| x_0\|^2 + C T\right) ee^{C T} \eqdef C_{2 , T}\left(1 + \| x_0\|^2\right).\] ◻

#+end_proof
The moment bound ensure that all coefficients remain sufficiently
controlled on \(\left[0 , T\right]\), which we require for the
intermediate timescale estimates.

*  The intermediate timescale
:PROPERTIES:
:CUSTOM_ID: sec-delta-time
:END:
From [[#eq-lam-sde][[eq-lam-sde]]], the switching variable evolves on
timescale \(\mathcal{O}\left(1 \/\epsilon\right)\) while \(x_t\) evolves
on \(\mathcal{O}\left(1\right)\). The standard approach would be to
rescale time and take \(\epsilon \rightarrow 0\). We show this fails and
introduce an intermediate timescale \(\delta\) with
\(\epsilon \ll \delta \ll 1\) to resolve the difficulty.

**  Necessity of an intermediate timescale.
:PROPERTIES:
:CUSTOM_ID: necessity-of-an-intermediate-timescale.
:END:
From [[#eq-lam-sde][[eq-lam-sde]]], it is evident that the switching
variable \(\lambda_t\) evolves on a faster timescale compared to the
state variable \(x_t\) when near the discontinuity set. As we have
discussed in [[#sec-background][1.5]], in the deterministic setting, the
standard approach is to rescale time via \(t = \epsilon \tau\), take the
limit \(\epsilon \rightarrow 0\), and solve the resulting algebraic
condition to obtain a \(\lambda^{*} \in \left(- 1 , 1\right)\) which
gives us our sliding mode. It is tempting to follow the same procedure
here, where instead of a single value for the switching variable, we
obtain the steady-state distribution
\[\lim_{t \rightarrow \infty}P_{ss}\left(\lambda , t , | x\right)\] .
However we shall see the stochastic nature of the problem yields
multiple objections concerning the mathematical subtleties in the
scaling, the physical interpretation, and the analysis of the original
problem given in [[#def-ns-gen-sde][[def-ns-gen-sde]]], that must be
addressed individually.

***  Objection I: Incompatible scaling of the dynamics.
:PROPERTIES:
:CUSTOM_ID: objection-i-incompatible-scaling-of-the-dynamics.
:END:
Before we attempt to rescale time we must first clarify the
\(\epsilon\)-order of local time terms in [[#eq-lam-sde][[eq-lam-sde]]],
which we do in the following lemma.

#+begin_lemma
Let \(z_t\) be a stochastic processes defined in
[[#eq-z-sde][[eq-z-sde]]] with quadratic variation
\[\mathrm{d} \langle z \rangle_t = \epsilon \widetilde{b}\left(t , x_t, \lambda_t\right) \widetilde{b}\left(t , x_t, \lambda_t\right)^{tns} \mathrm{d} t\] .
Then

\[\mathrm{d} \EE\left[L^z_t \left(a\right)\right] = \epsilon P^{\left(z\right)}\left(a , t\right) \widetilde{b}\left(t , x_t, \lambda_t\right)\widetilde{b}\left(t , x_t, \lambda_t\right)^{tns} \mathrm{d} t ,\]
where \(P^{\left(z\right)}\left(a , t\right)\) denotes the density of
\(z_t\) at level \(a\).

#+end_lemma

#+begin_proof
/Proof./ Taking the expectation of
[[#eq-local-time-def][[eq-local-time-def]]],

\[\begin{aligned}
\EE\left[L^z_t \left(a\right)\right] & = \EE\left[\lim_{\delta \downarrow 0} \frac{1}{(2\delta)} \int_0^t \mathbb{1}_{\left(a - \delta , a + \delta\right)} \left(z_s\right) \mathrm{d} \langle z \rangle_s\right], \\
 & = \lim_{\delta \downarrow 0} \frac{1}{(2\delta)} \int_0^t \EE\left[\mathbb{1}_{\left(a - \delta , a + \delta\right)} \mathrm{d} \langle z \rangle_s\right] \\
 & = \lim_{\delta \downarrow 0} \frac{1}{(2\delta)} \int_0^t \epsilon \EE\left[\mathbb{1}_{\left(a - \delta , a + \delta\right)}\widetilde{b}\left(s , x_s, \lambda_s\right) \widetilde{b}\left(s , x_s, \lambda_s\right)^{tns}\right] \mathrm{d} s , \\
 & = \epsilon \int_0^t \lim_{\delta \downarrow 0} \frac{1}{(2\delta)} \int_{a - \delta}^{a + \delta} P^{\left(z\right)}\left(a , s\right) \widetilde{b} \left(x_s, \lambda_s\right) \widetilde{b}\left(x_s, \lambda_s\right)^{tns} \mathrm{d} s , \\
 & = \epsilon \int_0^t P^{\left(z\right)}\left(a , s\right) \widetilde{b} \left(x_s, \lambda_s\right) \widetilde{b}\left(x_s, \lambda_s\right)^{tns} \mathrm{d} s , # <eq-local-time-exp-z-int> \\
\end{aligned}\]

The result follows by differentiation. ◻

#+end_proof
Having established the scaling of the local time terms, we now show that
no time rescaling can balance all contributions to the
\(\lambda\)-dynamics in the following lemma.

#+begin_lemma
Let \(t = \epsilon^{\beta} \tau\) for \(\beta > 0\). Under this
rescaling, the terms in [[#eq-lam-sde][[eq-lam-sde]]] scale as:

\[\begin{aligned}
\text{Drift:} &\mathbb{1}_{\left(-\epsilon , \epsilon\right]}\left[\sigma(x_{\tau})\right] \widetilde{a}_{\alpha , \epsilon}\left(x_{\tau}, \lambda_{\tau}\right) \mathrm{d} \tau , \quad & &\mathcal{O}\left(\epsilon^{\beta - 1}\right), \\
 \text{Martingale:} &\mathbb{1}_{\left(-\epsilon , \epsilon\right]}\left[\sigma(x_{\tau})\right] \widetilde{b}\left(x_{\tau}, \lambda_{\tau}\right) \mathrm{d} W_{\tau}, \quad & &\mathcal{O}\left(\epsilon^{\frac{(\beta - 1)}{2}}\right), \\
 \text{Local time:} &\mathrm{d} L_{\tau}^z\left(a\right) , \quad & &\mathcal{O}\left(\epsilon^{\beta}\right).
\end{aligned}\] No choice of \(\beta > 0\) brings all three
contributions to the same order as \(\epsilon \rightarrow 0\).

#+end_lemma

#+begin_proof
/Proof./ The rescaling gives
\(\mathrm{d} t = \epsilon^{\beta} \mathrm{d} \tau\) and
\(\mathrm{d} W_t = \epsilon^{\frac{\beta}{2}} \mathrm{d} W_{\tau}\). The
drift term in [[#eq-lam-sde][[eq-lam-sde]]] carries a factor
\(\epsilon^{- 1}\) from the layer dynamics, yielding order
\(\epsilon^{\beta - 1}\). The martingale term similarly yields order
\(\epsilon^{\frac{(\beta - 1)}{2}}\). By
[[#lem-local-time-scaling][[lem-local-time-scaling]]], the local time
contribution is \(\mathcal{O}\left(\epsilon\right)\) in original time,
hence \(\mathcal{O}\left(\epsilon^{\beta + 1}\right)\) after rescaling.

The naive choice \(\beta = 1\) places drift and martingale at
\(\mathcal{O}\left(1\right)\), but the local time term becomes
\(\mathcal{O}\left(\epsilon^2\right)\) and vanishes in the limit.
Balancing drift and local time requires \(\beta - 1 = \beta + 1\), which
has no solution. Balancing martingale and local time requires
\(\frac{(\beta - 1)}{2} = \beta + 1\), giving \(\beta = - 3\), which
violates \(\beta > 0\). ◻

#+end_proof
This presents a fundamental technical hurdle: the three contributions to
the dynamics of \(\lambda\) operate on incompatible scales. Any
rescaling followed by \(\epsilon \rightarrow 0\) necessarily discards at
least one contribution.

***  Objection II: Loss of physical interpretation.
:PROPERTIES:
:CUSTOM_ID: objection-ii-loss-of-physical-interpretation.
:END:
Even granting mathematical well-posedness, the
\(\epsilon \rightarrow 0\) limit produces an object whose physical
meaning has degenerated. As \(\epsilon \rightarrow 0\):

1. The layer
   \(\mathcal{D}_{\epsilon} = \left\{x \in \mathbb{R}^d : |\sigma( x) | \leq \epsilon\right\}\)
   shrinks to the co-dimension-1 surface
   \(\mathcal{D} = \left\{x : \sigma(x) = 0\right\}\).

2. The switching variable \(\lambda \in \left[- 1 , 1\right]\)
   parametrises a convex interpolation between the vector fields
   \(a^{pm}\) and noise coefficients \(b^{pm}\). This interpolation only
   has meaning within the layer, where the dynamics transitions between
   the two regimes.

3. The stationary distribution
   \(P_{ss}^{\epsilon} \left(\lambda | x\right)\) converges to some
   limiting distribution on \(\left[- 1 , 1\right]\), but this limit
   lives on a domain whose connection to the original geometry has been
   lost.

In the deterministic case, the \(\epsilon \rightarrow 0\) limit yields a
single value \(\lambda^{*} \left(x\right)\), the Filippov sliding mode.
The interpretation is clear: \(\lambda^{*}\) selects the unique convex
combination that keeps trajectories on the discontinuity surface. In the
stochastic setting, one retains a distribution over \(\lambda\) rather
than a single value, that is we furnish the differential inclusion set
with a probability measure, specifically a density distribution.
However, this but this distribution becomes detached from the layer on
which \(\lambda\) was defined.

***  Objection III: Incompatibility with weak-noise analysis.
:PROPERTIES:
:CUSTOM_ID: objection-iii-incompatibility-with-weak-noise-analysis.
:END:
The most fundamental objection concerns the purpose of the analysis. The
weak-noise framework treats \(\epsilon\) as the small parameter
governing the asymptotic expansion. For our purpose, the objects of
interest are not only typical paths obtained by minimising a
hypothetical Freidlin-Wentzell action functional, but the Gaussian
fluctuations around the most probable path at order
\(\mathcal{O}\left(\sqrt{\epsilon}\right)\). These phenomena are
intrinsically \(\epsilon\)-dependent.

The stationary distribution \(P_{ss}\left(\lambda | x\right)\) at finite
\(\epsilon\) encodes how noise selects among the continuum of Filippov
solutions and determines the fluctuation structure near the
discontinuity. Taking \(\epsilon \rightarrow 0\) collapses this to a
deterministic Filippov vector field, eliminating precisely the phenomena
we set out to analyse. In other words, consistency demands that
\(\epsilon\) be preserved throughout the analysis, including in the
treatment of the fast variable.

**  The intermediate timescale resolution
:PROPERTIES:
:CUSTOM_ID: the-intermediate-timescale-resolution
:END:
The preceding objections share a common source: they arise from taking
\[\epsilon \rightarrow 0\] in the layer dynamics. The resolution is to
avoid this limit entirely. We introduce an intermediate timescale
\(\delta\) satisfying

\[\epsilon \ll \delta \ll 1 .\]

At fixed \(\epsilon > 0\), all quantities remain well-defined:

- The layer \(\mathcal{D}_{\epsilon}\) has finite width and the
  boundaries \(pm \epsilon\) are well-separated

- The switching variable \(\lambda\) retains its meaning as
  parametrising the interpolation within a layer of finite width. The
  stationary distribution \(P_{ss}\left(\lambda | x\right)\) describes
  the steady-state density of \(\lambda\) within this layer for a fixed
  \(x\).

- The parameter \(\epsilon\) appears throughout the dynamics, preserving
  the weak-noise structure required for fluctuation analysis.

The conditions on \(\delta\) encode a separation of timescales. The
condition \(\delta \gg \epsilon\) ensures the fast variable \(\lambda\)
equilibrates to \(P_{ss}\left(\lambda | x\right)\) within the
\(\delta\)-window. The condition \(\delta \ll 1\) ensures the slow
variable \(x\) remains approximately frozen over this window. A concrete
realisation is \(\delta = \epsilon^{\alpha}\) for
\(\alpha \in \left(0 , 1\right)\); the value of \(\alpha\) does not
affect the limiting dynamics provided the relevant estimates hold
uniformly.

*  Estimates for the dynamics on the intermediate timescale
:PROPERTIES:
:CUSTOM_ID: sec-est-on-del
:END:
We proceed to establish the estimates that justify the timescale
separation. On the intermediate timescale \(\delta\) satisfying
[[#eq-delta-ordering][[eq-delta-ordering]]], the dynamics of \(x_t\) is
frozen while the dynamics of \(\lambda_t\) equilibrates to a
steady-state distribution. Let us obtain estimates for the variation in
the slow variable \(x_t\) on this time scale

#+begin_theorem
Let \(x_t \in \mathcal{D}_{\epsilon}\) and \(\delta > 0\) satisfying
[[#eq-delta-ordering][[eq-delta-ordering]]] and \(\delta \rightarrow 0\)
as \(\epsilon \rightarrow 0\), then

\[\PP\left[\sup_{0\leq s\leq\delta} | x_{t + s} - x_t| > \gamma\right] \leq \frac{C}{\gamma^2} \left(\delta^2 + \epsilon \delta\right)\]
for some \(C ,\gamma > 0\).

#+end_theorem

#+begin_proof
/Proof./ We start by bounding the squared deviation in the \(\delta\)
time window, \[\begin{aligned}
\EE\left[| x_{t + s} - x_t|^2\right] & = \EE\left[\left|\int_t^{t + s}a\left(x_{\tau}, \lambda_{\tau}\right)\mathrm{d}\tau +\sqrt{\epsilon}\int_t^{t + s}b\left(x_{\tau}, \lambda_{\tau}\right)\mathrm{d} W_{\tau}\right|^2\right], \\
 &\leq 2\EE\left[\left|\int_t^{t + s}a\left(x_{\tau}, \lambda_{\tau}\right)\mathrm{d}\tau\right|^2\right] + 2 \epsilon \EE\left[\left|\int_t^{t + s}b\left(x_{\tau}, \lambda_s\right)\mathrm{d} W_{\tau}\right|^2\right]. \\
\end{aligned}\]

We will bound each integral term separately, for the drift part we have
\[\begin{aligned}
\EE\left[\left|\int_t^{t + s}a\left(x_{\tau}, \lambda_{\tau}\right)\mathrm{d}\tau\right|^2\right] &\leq s \int_t^{t + s} \EE\left[\left|a\left(x_{\tau}, \lambda_{\tau}\right)\right|^2\right] \mathrm{d} \tau , \\
 &\leq s \int_t^{t + s} C \left(1 + \EE\left[| x_{\tau}|^2\right]\right) \mathrm{d} \tau , \\
 &\leq C s^2,
\end{aligned}\] and for the martingale part we have by Itō isometry
\[\begin{aligned}
\EE\left[\left|\int_t^{t + s}b\left(s , x_s, \lambda_s\right)\mathrm{d} W_s\right|^2\right] &\leq \int_t^{t + s}\EE\left[\left\| b\left(s , x_s, \lambda_s\right)\right\|^2\right]\mathrm{d} s \\
 &\leq \int_t^{t + s} C \left(1 + \EE\left[| x_s|^2\right]\right)\mathrm{d} s \\
 &\leq C s .
\end{aligned}\] Putting both bounds together we obtain
[[#eq-slow-var-x][[eq-slow-var-x]]], we obtain \[\begin{aligned}
\EE\left[| x_{t + s} - x_t|^2\right] &\leq C\left(s^2 + \epsilon s\right) ,
\end{aligned}\] and taking the supremum over the interval we find
\[\begin{aligned}
\EE\left[\sup_{0\leq s\leq\delta}| x_{t + s} - x_t|^2\right] &\leq \sup_{0\leq s\leq\delta}C\left(s^2 + \epsilon s\right) \leq C\left(\delta^2 + \epsilon \delta\right) ,
\end{aligned}\]

Using Markovs inequality on [[#eq-expec-ineq][[eq-expec-ineq]]] yeilds
\[\PP\left[\sup_{0\leq s\leq\delta}| x_{t + s} - x_t|^2 > \gamma^2\right] \leq\frac{1}{\gamma^2} \EE\left[\sup_{0\leq s\leq\delta}| x_{t + s} - x_t|^2\right] \leq \frac{1}{\gamma^2} C\left(\delta^2 + \epsilon \delta\right) .\] ◻

#+end_proof
The consequence of [[#thm-slow-var][[thm-slow-var]]] becomes more
apparent when we choose any mesoscopic scale \(\delta(\epsilon)\)
satisfying [[#eq-delta-ordering][[eq-delta-ordering]]], e.g.
\(\delta(\epsilon) = \epsilon^{\beta}\), for some \(\beta > 0\) and then
letting \[\epsilon \rightarrow 0\] . The bound in
[[#eq-slow-var-x][[eq-slow-var-x]]] ensures that for any fixed
\(\gamma\),

\[\PP\left[\sup_{0\leq s\leq\delta(\epsilon)}| x_{t + s} - x_t| > \gamma\right] \leq \frac{C}{\gamma^2} \left[\delta^2\left(\epsilon\right) + \epsilon \delta(\epsilon)\right] \rightarrow 0 ,\]

and therefore the slow variable \(x_t\), with probability tending to
one, remains constant on the entire interval
\(\left[t , t + \delta(\epsilon)\right]\). Simultaneously, we have

\[\frac{\delta(\epsilon)}{\epsilon} = \epsilon^{\beta - 1} \rightarrow \infty , \quad #\text{[as]} \epsilon \rightarrow 0 ,\]

for \(\beta \in \left(0 , 1\right)\), which shows that the
\(\delta\)-window is arbitrarily large on the fast
\(\lambda\)--timescale. Thus, in \(\delta\)-interval, the slow variable
may be regarded as fixed while the fast variable has sufficient time to
equilibrate.

Having now established the error associated with fixing the value of
\(x\) to its value at the start of \(\delta\)-time window, we now turn
to demonstrate the mixing of the switching variable, \(\lambda\), for a
fixed \(x \in \mathcal{D}_{\epsilon}\). We start by obtaining relevant
facts about the dynamics of the former. Using
[[#eq-lam-sde][[eq-lam-sde]]] from [[#thm-lam-sde][[thm-lam-sde]]], we
can easily obtain the backward generator as the following lemma shows.

#+begin_lemma
Let \(\delta > 0\) satisfying
[[#eq-delta-ordering][[eq-delta-ordering]]], let
\[t \in \left[t , t + \delta\right] \subset \left[0 , T\right]\] for
some \(t \in \left[0 , T -\delta\right]\). Let
\(x_t = x \in \mathcal{D}_{\epsilon}\) be fixed (see
[[#thm-slow-var][[thm-slow-var]]]). Then the backward generator
\(\mathcal{A}_x\) of \(\lambda_t \in \left[- 1 , 1\right]\) evolving
according to [[#eq-lam-sde][[eq-lam-sde]]], acts on sufficently smooth
test function \(f : \left[- 1 , - 1\right] mapsto \mathbb{R}\) via

\[\begin{aligned}
\left(\mathcal{A}_x f\right)\left(\lambda\right) & = \frac{1}{\epsilon} \partial_{\lambda} f\left(\lambda\right)\left\{\partial_x \sigma(x)^{tns} a\left(t , x , \lambda\right) + \frac{\epsilon}{2} trc\left[b\left(t , x , \lambda\right)^{tns} \partial^2_{x x} \sigma(x) b\left(t , x , \lambda\right)\right]\right\} \\
 & + \frac{1}{(2 \epsilon)} \partial^2_{\lambda \lambda}f\left(\lambda\right) \partial_x \sigma(x)^{tns} b\left(t , x , \lambda\right) b\left(t , x , \lambda\right)^{tns} \partial_x \sigma(x) ,
\end{aligned}\]

with the domain

\[\operatorname{dom}(\mathcal{A}_x) = \left\{f \in C^2\left(\left[- 1 , 1\right]\right) | \partial_{\lambda}\left(1\right) = \partial_{\lambda}\left(- 1\right) = 0\right\} .\]
Note that the generator is conditional on \(x\).

#+end_lemma

#+begin_proof
/Proof./ With \(x_t = x\) fixed on the interval
\(t \in \left[t , t + \delta\right] \subset \left[0 , T\right]\) for
some \(t \in \left[0 , T\right]\) and \(\delta > 0\), (see
[[#thm-slow-var][[thm-slow-var]]]). Let
\(f \in C^2\left(\left[- 1 , 1\right]\right)\) and set an initial
conditoin \(\lambda_t = \lambda \in \left[- 1 , 1\right]\). Applying
Itōs lemma to \(f\left(\lambda_t\right)\) to yield

\[f\left(\lambda_t\right) - f\left(\lambda\right) = \int_t^t \partial_{\lambda} f\left(\lambda_s\right) \mathrm{d} \lambda_s + \frac{1}{2} \int_t^t \partial^2_{\lambda \lambda} f\left(\lambda_s\right) \mathrm{d} \langle \lambda \rangle_s,\]

where \(\langle \lambda \rangle\) is the quadratic variation of
\(\lambda_t\). Substituting [[#eq-lam-sde][[eq-lam-sde]]] into first the
first integral [[#eq-gen-ito-start][[eq-gen-ito-start]]] we obtain the
decomposition

\[\int_t^t \partial_{\lambda} f\left(\lambda_s\right) \mathrm{d} \lambda_s = I^{\left(1\right)}_t + I^{\left(2\right)}_t + M_t ,\]

where

\[\begin{aligned}
I^{\left(1\right)}_t & \eqdef \frac{1}{\epsilon} \int_0^t \partial_{\lambda} f\left(\lambda_s\right) \widetilde{a}_{\alpha , \epsilon}\left(t , x , \lambda_s\right) \mathrm{d} s , \\
 I^{\left(2\right)}_t & \eqdef \frac{1}{\epsilon} \int_0^t \partial_{\lambda} f\left(\lambda_s\right) \left[\mathrm{d} L_s^z\left(-\epsilon\right) - \mathrm{d} L_s^z\left(\epsilon\right)\right] , \\
\end{aligned}\]

and \(M_t\) is the martingale term arising from the stochastic integral
with respect to \(W_t\). For the quadratic variation, since we know from
[[#lem-local-time-scaling][[lem-local-time-scaling]]] that
\(\mathrm{d} L^z_t \left(pm \epsilon\right) = O\left(\mathrm{d} t\right)\),
the second integral in [[#eq-gen-ito-start][[eq-gen-ito-start]]] becomes

\[\frac{1}{2} \int_t^t \partial^2_{\lambda \lambda} f\left(\lambda_s\right) \mathrm{d} \langle \lambda \rangle_s = I^{\left(3\right)}_t \eqdef = \frac{1}{(2 \epsilon)} \int_0^t \partial^2_{\lambda \lambda} f\left(\lambda_s\right) \widetilde{b}\left(t , x , \lambda_s\right) \widetilde{b}\left(t , x , \lambda_s\right)^{tns} \mathrm{d} s , \\\]

Taking expectations, the martingale term vanishes leaving

\[\EE\left[f\left(\lambda_t\right) - f\left(\lambda\right)\right] = \EE\left[I^{\left(1\right)}_t\right] + \EE\left[I^{\left(2\right)}_t\right] + \EE\left[I^{\left(3\right)}_t\right].\]

Interior terms. The terms \(I^{\left(1\right)}_t\) and
\(I^{\left(3\right)}_t\) are the drift and diffusion on the interior of
the [1, 1], i.e. for \(\lambda \in \left(- 1 , 1\right)\). Since the
coefficients are continious in \(t\), we have

\[\lim_{t \rightarrow t} \frac{1}{t} \EE\left[I^{\left(1\right)}_t\right] = \frac{1}{\epsilon} \partial_{\lambda} f\left(\lambda\right) \widetilde{a}_{\alpha , \epsilon}\left(t , x , \lambda\right) , \\
 \lim_{t \rightarrow t} \frac{1}{t} \EE\left[II^{\left(3\right)}_t\right] = \frac{1}{(2 \epsilon)} \partial^2_{\lambda \lambda} f\left(\lambda\right) \widetilde{b}\left(t , x , \lambda\right) \widetilde{b}\left(t , x , \lambda\right)^{tns},\]

hence, the interior contribution to the generator is the right-hand side
of [[#eq-bwd-gen][[eq-bwd-gen]]] when we express
\(\widetilde{a}_{\alpha , \epsilon}\) and \(\widetilde{b}\) in terms of
\(a\) and \(b\) using [[#eq-a-tilde-def][[eq-a-tilde-def]]] and
[[#eq-b-tilde-def][[eq-b-tilde-def]]].

Local time term. For the local time contribution
\(I^{\left(2\right)}_t\), we know that when \(z_t = pm \epsilon\), we
have \(\lambda_t = pm 1\), thus
\[\partial_{\lambda} f\left(\lambda_s\right) = \partial_{\lambda} f\left(pm 1\right)\]
and

\[\EE\left[I^{\left(2\right)}_t\right] = \frac{1}{\epsilon} \int_0^t \EE\left[\partial_{\lambda} f\left(- 1\right) \mathrm{d} L^z_s \left(-\epsilon\right) - \partial_{\lambda} f\left(1\right) \mathrm{d} L^z_s \left(\epsilon\right)\right] .\]

Using also [[#eq-diff-ee-lt][[eq-diff-ee-lt]]] (see
[[#lem-local-time-scaling][[lem-local-time-scaling]]]), we have

\[\begin{aligned}
\mathrm{d} \EE\left[\partial_{\lambda} f\left(pm 1\right) L_t^z\left(pm \epsilon\right)\right] & = \partial_{\lambda} f\left(pm 1\right) \mathrm{d} \EE\left[L_t^z\left(pm \epsilon\right)\right] , \\
 & = \epsilon \partial_{\lambda} f\left(pm 1\right) P^{\left(z\right)}\left(pm \epsilon , t\right) \widetilde{b}\left(t , x , \lambda_t\right) \widetilde{b}\left(t , x , \lambda_t\right)^{tns} \mathrm{d} t ,
\end{aligned}\] from which we conclude
\[\lim_{t \rightarrow t} \frac{1}{t} \EE\left[I^{\left(2\right)}_t\right] = \epsilon C_{pm}\left(x , t\right) \partial_{\lambda} f\left(pm 1\right) ,\]

where \(| C_{pm}\left(x , t\right) | < \infty\) are smooth \(x , t\)
dependent coefficients. combining all of the expectation of the
integrals together gives

Combining all of the intergral expecations with
[[#eq-gen-decomp-expect][[eq-gen-decomp-expect]]] and dividing by \(t\)
gives

\[\lim_{t \rightarrow t} \frac{1}{t} \EE\left[f\left(\lambda_t\right) - f\left(\lambda\right)\right] = \left(\mathcal{A}_x f\right)\left(\lambda\right) + C_{+}\left(x , t\right) \partial_{\lambda} f\left(1\right) - C_{-}\left(x , t\right) \partial_{\lambda} f\left(- 1\right) ,\]
where \(\mathcal{A}_x\) is the interior differential operator defined in
[[#eq-bwd-gen][[eq-bwd-gen]]]. By definition of the generator of a
Markov process, and equivalently by Dynkins formula, the infinitesimal
generator must satisfy
\[\lim_{t \downarrow 0} \frac{1}{t} \EE\left[f\left(\lambda_t\right) - f\left(\lambda\right)\right] = \left(\mathcal{A}_x f\right)\left(\lambda\right)\]
without any additional boundary terms. In view of
[[#eq-gen-limit-with-bdry][[eq-gen-limit-with-bdry]]], this is possible
if and only if
\[C^{+}\left(x , t\right) \partial_{\lambda} f\left(1\right) - C^{-}\left(x , t\right) \partial_{\lambda} f\left(- 1\right) = 0 ,\]

Since \(C^{pm} \left(x , t\right)\) are non-zero for
\(x \in \mathcal{D}_{\epsilon}\) due to the accumulation of local time
at the boundaries, the only way this can hold for all
\(x \in \mathcal{D}_{\epsilon}\) is to impose the Neumann boundary
conditions
\[\partial_{\lambda} f\left(1\right) = \partial_{\lambda} f\left(- 1\right) = 0 .\]

This characterises precisely the domain of \(\mathcal{A}_x\) claimed in
the lemma. ◻

#+end_proof
From the backward generator it is then possible to obtain the forward
generator using the \(L^2\)-adjoint relation

\[\int_{-}^1 P_x\left(t , \lambda\right) \left(\mathcal{A}_x f_t\right) \left(\lambda\right) \mathrm{d} \lambda = \int_{-}^1 \left(\mathcal{A}^{*}_x P_x\right)\left(t , \lambda\right) f_t \left(\lambda\right) \mathrm{d} \lambda , \quad \forall f_t \in \operatorname{dom}(\mathcal{A}_x)\]

where \(t \in \left[t , t + \delta\right] \subset \left[0 , T\right]\),
\(P_x\left(t , \lambda\right)\) is the occupation probability density of
the switching variable \(\lambda\), and \(\mathcal{A}^{*}_x\) acts only
on the spatial argument of \(P_x\). The forward generator is formulated
in the following lemma.

#+begin_lemma
Let \(\delta > 0\) satisfying
[[#eq-delta-ordering][[eq-delta-ordering]]], let
\[t \in \left[t , t + \delta\right] \subset \left[0 , T\right]\] for
some \(t \in \left[0 , T -\delta\right]\). Let
\(x_t = x \in \mathcal{D}_{\epsilon}\) be fixed (see
[[#thm-slow-var][[thm-slow-var]]]). Then the forward generator
\(\mathcal{A}^{*}_x\) of \(\lambda_t \in \left[- 1 , 1\right]\) evolving
according to [[#eq-lam-sde][[eq-lam-sde]]], acts on sufficently smooth
probability density
\[P_x: \left[0 , T\right] \times \left[- 1 , 1\right] mapsto \left[0 , \infty\right)\]
via \[\begin{aligned}
\left(\mathcal{A}^{*}_x P_x\right)\left(t , \lambda\right) & = - \frac{1}{\epsilon} \partial_{\lambda} \left(P_x\left(t , \lambda\right) \left\{\partial_x \sigma(x_t)^{tns} a\left(t , x , \lambda\right) + \frac{\epsilon}{2} trc\left[b\left(t , x , \lambda\right)^{tns} \partial^2_{x x} \sigma(x) b\left(t , x , \lambda\right)\right]\right\}\right) \\
 & + \frac{1}{(2 \epsilon)} \partial^2_{\lambda \lambda}\left[P_x\left(t , \lambda\right) \partial_x \sigma(x_t)^{tns} b\left(t , x , \lambda\right) b\left(t , x , \lambda\right)^{tns} \partial_x \sigma(x_t)\right] ,
\end{aligned}\] with the domain

\[\operatorname{dom}(\mathcal{A}_x^{*}) = \left\{P_x \in C^2\left(\left[- 1 , 1\right] ; \left[0 , \infty\right)\right) | J_t \left(pm 1\right) = 0\right\} ,\]
where

\[\begin{aligned}
J_t \left(\lambda\right) & = P_x \left(t , \lambda\right) \left\{\partial_x \sigma(x_t)^{tns} a\left(t , x , \lambda\right) + \frac{\epsilon}{2} trc\left[b\left(t , x , \lambda\right)^{tns} \partial^2_{x x} \sigma(x) b\left(t , x , \lambda\right)\right]\right\} \\
 & - \frac{1}{(2 )} \partial_{\lambda}\left[P_x \left(t , \lambda\right) \partial_x \sigma(x_t)^{tns} b\left(t , x , \lambda\right) b\left(t , x , \lambda\right)^{tns} \partial_x \sigma(x_t)\right] ,
\end{aligned}\]

is the scaled probability current.

#+end_lemma

#+begin_proof
/Proof./ Let \(P_x\left(t , \lambda\right)\) denote the occupation
density of the switching variable
\(\lambda_t \in \left[- 1 , 1\right]\), conditioned on a frozen value of
\[x_t = x \in \mathcal{D}_{\epsilon}\] . Inserting the backward
generator from [[#lem-bwd-gen][[lem-bwd-gen]]] into
[[#eq-adjoint-def][[eq-adjoint-def]]] we obtain

\[\frac{1}{\epsilon} \int_{- 1}^1 P_x\left(t , \lambda\right) \partial_{\lambda} f\left(\lambda\right) \widetilde{a}_{\alpha , \epsilon}\left(t , x , \lambda\right) + \frac{1}{(2 \epsilon)} \int_{- 1}^1 P_x\left(t , \lambda\right) \partial^2_{\lambda \lambda}f\left(\lambda\right) \widetilde{b}\left(t , x , \lambda\right) \widetilde{b}\left(t , x , \lambda\right)^{tns} \\
 = \int_{- 1}^1 f_t \left(\lambda\right) \left(\mathcal{A}^{*}_x P_t\right)\left(\lambda\right)\]

\[\begin{aligned}
\left(\mathcal{A}_x f\right)\left(\lambda\right) & = \frac{1}{\epsilon} \partial_{\lambda} f\left(\lambda\right)\left\{\partial_x \sigma(x_t)^{tns} a\left(t , x , \lambda\right) + \frac{\epsilon}{2} trc\left[b\left(t , x , \lambda\right)^{tns} \partial^2_{x x} \sigma(x) b\left(t , x , \lambda\right)\right]\right\} \\
 & + \frac{1}{(2 \epsilon)} \partial^2_{\lambda \lambda}f\left(\lambda\right) \partial_x \sigma(x_t)^{tns} b\left(t , x , \lambda\right) b\left(t , x , \lambda\right)^{tns} \partial_x \sigma(x_t) .
\end{aligned}\] We treat the drift and diffusion contributions
seperately.

Drift contribution. Integration by parts gives \[\begin{aligned}
\frac{1}{\epsilon} \int_{- 1}^1 \partial_{\lambda} f\left(\lambda\right) P_x\left(t , \lambda\right) \widetilde{a}_{\alpha , \epsilon}\left(t , x , \lambda\right) \mathrm{d} \lambda & = \left(\frac{1}{\epsilon} f\left(\lambda\right) P_x( t , \lambda )\widetilde{a}_{\alpha , \epsilon}( t , x , \lambda )\right|_{- 1}^1 \\
 & - \frac{1}{\epsilon} \int_{- 1}^1 f\left(\lambda\right) \partial_{\lambda} \left[P_x\left(t , \lambda\right) \widetilde{a}_{\alpha , \epsilon}\left(t , x , \lambda\right)\right] \mathrm{d} \lambda ,
\end{aligned}\]

Diffusion contribution. Employing intrgration by parts twice yields
\[\begin{aligned}
\frac{1}{(2\epsilon)} \int_{- 1}^1 \partial^2_{\lambda \lambda} f\left(\lambda\right) P_x\left(t , \lambda\right) \widetilde{b} \widetilde{b}^{tns} \mathrm{d} \lambda & = \left(\frac{1}{(2\epsilon)}\partial_{\lambda}f\left(\lambda\right)\left[P_x\left(t , \lambda\right) \widetilde{b} \widetilde{b}^{tns}\right] -\frac{1}{(2\epsilon)} f\left(\lambda\right)\partial_{\lambda}[ P_x\left(t , \lambda\right) \widetilde{b} \widetilde{b}^{tns}]\right|_{- 1}^1 \\
 & + \frac{1}{(2\epsilon)} \int_{- 1}^1 f\left(\lambda\right) \partial^2_{\lambda \lambda} \left[P_x\left(t , \lambda\right) \widetilde{b} \widetilde{b}^{tns}\right] \mathrm{d} \lambda ,
\end{aligned}\]

where the arguments \(\left(t , x , \lambda\right)\) are dropped in the
notation of \(\widetilde{a}_{\alpha , \epsilon}\) and \(\widetilde{b}\)
for clarity. Since
\[f \in \operatorname{dom}(\mathcal{A}) = \left\{f \in C^2\left(\left[- 1 , 1\right]\right) | \partial_{\lambda} f\left(pm 1\right) = 0\right\}\]
, all boundary terms proportional to
\(\partial_{\lambda} f\left(pm 1\right)\) vanish. The remaining boundary
terms must also vanish to respect conservation of probability (i.e. zero
probability flux through \(\lambda = pm 1\)), giving the boundary
condtion

\[\left\{P_x\left(t , \lambda\right) \widetilde{a}_{\alpha , \epsilon}\left(x_t, \lambda\right) - \frac{1}{2} \partial_{\lambda} \left[P_x\left(t , \lambda\right) \widetilde{b}\left(t , x , \lambda\right) \widetilde{b}\left(t , x , \lambda\right)^{tns}\right]\right\}_{- 1}^1 = 0 .\]

Using [[#eq-forward-drift][[eq-forward-drift]]]
[[#eq-forward-diffusion][[eq-forward-diffusion]]], and enforcing
[[#eq-forward-zero-flux][[eq-forward-zero-flux]]], we identify the
forward operator as
\[\left(\mathcal{A}^{*}_x P_x\right)\left(t , \lambda\right) = - \frac{1}{\epsilon} \partial_{\lambda} \left[P_x\left(t , \lambda\right) \widetilde{a}_{\alpha , \epsilon}\left(t , x , \lambda\right)\right] + \frac{1}{(2\epsilon)} \partial^2_{\lambda \lambda} \left[P_x\left(t , \lambda\right) \widetilde{b}\left(t , x , \lambda\right) \widetilde{b}\left(t , x , \lambda\right)^{tns}\right].\]

Substituting the definitions in [[#eq-a-tilde-def][[eq-a-tilde-def]]]
[[#eq-b-tilde-def][[eq-b-tilde-def]]] yields the defnition give in the
lemma. ◻

#+end_proof
The operator \(\mathcal{A}^{*}_x\) is also called the Fokker--Planck or
Kolmogorov forward operator associated with the dynamics of the
switching variable \(\lambda_t\), in our case, however, it is
conditional on \(x_t = x \in \mathcal{D}_{\epsilon}\).

[ *Remark.* body ]

[ *Remark.* body ]

**  Bounds on the probability density of the switching variable
:PROPERTIES:
:CUSTOM_ID: bounds-on-the-probability-density-of-the-switching-variable
:END:
With the forward generator in hand, we turn to quantitative estimates on
the density of the switching variable. Remember that our goal is to
establish mixing of the dynamics of \(\lambda\), for which we require
various estimates for \(P_x\left(t , \lambda\right)\).

Since we allow for the fact that at \(t = 0\) we allow a Dirac-delta
initial condition, i.e.
\(P_x\left(0 , \lambda\right) = \delta(\lambda - \Lambda_{\epsilon}\left(\sigma(x_0)\right))\)
where \(x_0\) is the initial condition of \(x_t\), we must show that
despite such initial conditions, \(P_x\left(t , \lambda\right)\) becomes
instantaneously smooth for any \(t > 0\). In our case the ellipticity of
the generator, which is guarrenteed by the transversality condition in
[[#def-ns-gen-sde][[def-ns-gen-sde]]], is key to show the instantaneous
smoothing as we show via the following lemma.

#+begin_lemma
Let \(x \in \mathcal{D}_{\epsilon}\) fixed, and let \(\lambda_t\) ​
evolve according to the SDE with forward generator \(\mathcal{A}^{*}_x\)
given by [[#lem-fwd-gen][[lem-fwd-gen]]], let
\[\rho_x\left(t , \lambda giv \mu\right)\] with
\(\mu \in \left[- 1 , 1\right]\) be the Greenss function solution to
\(\partial_t \rho_x = \mathcal{A}^{*}_x \rho_x\) with the localised
intial condition and let the diffusion coefficient satisfy

\[0 < C_1 \left(x\right) \leq \widetilde{d}\left(t , x ,\lambda\right)\leq C_2 \left(x\right) .\]
Then for any \(t \in \left(0 , T\right]\), the Greenss function satifies

\[\frac{(R_{\text{L}}\left(x\right))}{\sqrt{t}} \exp\left[-\frac{(C_1\left(x\right)\left(\lambda -\mu\right)^2 )}{t}\right] \leq \rho_x\left(t , \lambda giv \mu\right) \leq \frac{(R_{\text{U}}\left(x\right))}{\sqrt{t}} \exp\left[-\frac{(C_2\left(x\right)\left(\lambda - \mu\right)^2 )}{t}\right] ,\]

where \(R_{\text{L}}\), \(R_{\text{U}}\), \(C_1\) and \(C_2\) constants
that depends on \(x\), upper and lower bounds for the diffusion
coefficient which are dependnet on \(x\) but uniform in \(\lambda\) and
\(T\).

#+end_lemma

#+begin_proof
/Proof./ The proof is a direct consequence from Aronson, Theorem 7 in
[[#aronson1968][[aronson1968]]] (see also
[[#aronson1967][[aronson1967]]]). Let us work directly with the
Fokker-Planck equation, using the definition of \(\mathcal{A}^{*}_x\) in
[[#lem-fwd-gen][[lem-fwd-gen]]] we have
\[\partial_t \rho_x\left(t , \lambda giv \mu\right) = -\frac{1}{\epsilon} \partial_{\lambda} \left[\widetilde{a}_{\alpha , \epsilon}\left(t , x , \lambda\right) \rho_x\left(t , \lambda giv \mu\right)\right] + \frac{1}{(2 \epsilon)} \partial^2_{\lambda \lambda} \left[\widetilde{d}\left(t , x , \lambda\right) \rho_x\left(t , \lambda giv \mu\right)\right] ,\]
with the Dirac-delta initial conditions
\[\rho_x\left(0 , \lambda giv \mu\right) = \delta(\lambda - \mu)\] and
where \(\widetilde{a}_{\alpha , \epsilon}\) and \(\widetilde{d}\) are
defined in [[#eq-a-tilde-def][[eq-a-tilde-def]]] and
[[#eq-d-tilde-def][[eq-d-tilde-def]]] respectively. Recasting in the
divergence form we have
\[\partial_t \rho_x\left(t , \lambda giv \mu\right) = \partial_{\lambda} \left[A\left(t , x , \lambda\right) \rho_x\left(t , \lambda giv \mu\right) + B\left(t , x , \lambda\right) \partial_{\lambda}\rho_x\left(t , \lambda giv \mu\right)\right] ,\]

where

\[A\left(t , x , \lambda\right) = \frac{1}{\epsilon} \left[\frac{1}{2} \partial_{\lambda} \widetilde{d}\left(t , x , \lambda\right) - \widetilde{a}_{\alpha , \epsilon}\left(t , x , \lambda\right)\right] , \quad B\left(t , x , \lambda\right) = \frac{1}{(2 \epsilon)} \widetilde{d}\left(t , x , \lambda\right) .\]

In order to apply Aronsons result we must show that both \(A\) and \(B\)
are bounded and that there exists a constant \(\nu \geq 1\) such that
the inequality
\[\frac{1}{\nu} \leq \| B\left(t , x , \lambda\right)\| \leq \nu ,\]

is satisfied. Since we know that that \(a_{\alpha , \epsilon}\) is
bounded via linear growth bound in
[[#lem-a-spur-bound][[lem-a-spur-bound]]], to bound \(A\) we need only
show that \(\partial_{\lambda}\widetilde{d}\) is bounded. We have from
the definition in [[#eq-d-tilde-def][[eq-d-tilde-def]]]
\[\begin{aligned}
\partial_{\lambda}\widetilde{d}\left(t , x , \lambda\right) & = \partial_x \sigma(x)^{tns} \left\{\partial_{\lambda}\left[b\left(t , x , \lambda\right) b\left(t , x , \lambda\right)^{tns}\right]\right\} \partial_x \sigma(x) \\
 & = \frac{1}{2} \partial_x \sigma(x)^{tns} \left(\left[b^{+}\left(t , x\right) - b^{-}\left(t , x\right)\right] b\left(t , x , \lambda\right)^{tns} \\
 & + b\left(t , x , \lambda\right) \left[b^{+}\left(t , x\right) - b^{-}\left(t , x\right)\right]^{tns}\right) \partial_x \sigma(x) .
\end{aligned}\] Taking the norm of both sides yeilds yeilds
\[\begin{aligned}
\| \partial_{\lambda}\widetilde{d}\left(t , x , \lambda\right)\| &\leq \|\partial_x \sigma(x)\|^2\cdot \| b\left(t , x , \lambda\right)\|\cdot\| b^{+}\left(t , x\right) - b^{-}\left(t , x\right)\| \\
 &\leq \|\partial_x \sigma(x)\|^2\cdot \| b\left(t , x , \lambda\right)\|\cdot\| b^{+}\left(t , x\right) + b^{-}\left(t , x\right)\| \\
 &\leq C \|\partial_x \sigma(x)\|^2 \left(1 + \| x\|^2\right),
\end{aligned}\]

for some \(C > 0\), and where we have used
[[#lem-coeff-tilde-bounds][[lem-coeff-tilde-bounds]]], and
\[\| x\| \leq 1 + \| x\|^2\] . Moreover, since we know that
\[\widetilde{d}\left(t , x , \lambda\right) \leq 2 C^2 \left(1 + \| x\|^2\right)\]
and
\(\widetilde{d}\left(t , x , \lambda\right) \geq \widetilde{M}^2 > 0\)
by the linear growth bound and the transversality condition in
[[#lem-coeff-tilde-bounds][[lem-coeff-tilde-bounds]]], we can satisfy
[[#eq-aronson-cond][[eq-aronson-cond]]] by defining

\[\nu(x) \eqdef \max\left[2 \epsilon \/ \widetilde{M}^2, 2 C^2 \left(1 + \| x\|^2\right), 1\right] .\] ◻

#+end_proof
While [[#lem-lam-smooth-denst][[lem-lam-smooth-denst]]] gives us
estimates for the transient density, we also require the invariant
density, that is quasi-stationary density obtained by fixing \(x\) to be
static whilst allowing \(\lambda\) to be dynamics. We can compute this
invariant density explicitly.

#+begin_lemma
Let \(x \in \mathcal{D}_{\epsilon}\) be fixed, and let
\[\widetilde{a}_{\alpha , \epsilon}\left(x , \lambda\right) \eqdef \widetilde{a}_{\alpha , \epsilon}\left(t , x , \lambda\right) |_{t = t_0}\]
and
\[\widetilde{d}\left(x , \lambda\right) \eqdef \widetilde{d}\left(t , x , \lambda\right) |_{t = t_0}\]
denote the coefficients evaluated at some fixed time
\(t_0 \in \left[0 , T\right]\). Let the forward generator
\(\mathcal{A}^{*}_x\) of \(\lambda_t\) be defined in
[[#eq-fwd-gen][[eq-fwd-gen]]] with these frozen coefficients. Then the
invariant measure \(P_{ss}\left(\lambda | x\right)\) satisfying
\(\left(\mathcal{A}^{*}_x P_{ss}\right)\left(\lambda\right) = 0\) is
given by
\[P_{ss}\left(\lambda | x\right) = \frac{(R\left(x\right)) }{(\widetilde{d}\left(x , \lambda\right))} \exp(2 \int_{- 1}^{\lambda} \frac{(\widetilde{a}_{\alpha , \epsilon}\left(x , \nu\right)) }{(\widetilde{d}\left(x , \nu\right))} \mathrm{d} \nu) ,\]
where
\[R\left(x\right) = \left[\int_{- 1}^1 \frac{1 }{(\widetilde{d}\left(x , \lambda\right))} \exp(2 \int_{- 1}^{\lambda} \frac{(\widetilde{a}_{\alpha , \epsilon}\left(x , \nu\right)) }{(\widetilde{d}\left(x , \nu\right))} \mathrm{d} \nu) \mathrm{d} \lambda\right]^{- 1},\]
is an \(x\)-dependent normalisation constant.

#+end_lemma

#+begin_proof
/Proof./ The proof is a direct trivial calulation. We have
\[\left(\mathcal{A}^{*} P_{ss}\right)\left(\lambda\right) = - \frac{1}{\epsilon} \partial_{\lambda} \left[P_{ss} \left(\lambda\right) \widetilde{a}_{\alpha , \epsilon}\left(t , x , \lambda\right)\right] + \frac{1}{(2\epsilon)} \partial^2_{\lambda \lambda} \left[P_{ss} \left(\lambda\right) \widetilde{d}\left(t , x , \lambda\right)\right] = 0 ,\]

which immediately gives us the ordinary differential equation

\[\begin{aligned}
P_{ss} \left(\lambda\right) \widetilde{a}_{\alpha , \epsilon}\left(t , x , \lambda\right) & = \frac{1}{2} \partial_{\lambda} \left[P_{ss} \left(\lambda\right) \widetilde{d}\left(t , x , \lambda\right)\right] . \\
\end{aligned}\]

It follows then that
\[\frac{(\partial_{\lambda} P_{ss} \left(\lambda\right)) }{(P_{ss} \left(\lambda\right))} = \frac{(2 \widetilde{a}_{\alpha , \epsilon}\left(t , x , \lambda\right) - \partial_{\lambda} \widetilde{d}\left(t , x , \lambda\right)) }{(\widetilde{d}\left(t , x , \lambda\right))} ,\]
which after intergrating both sides with respect to \(\lambda\) we
obtain

\[\ln P_{ss} \left(\lambda\right) = 2 \int_{- 1}^{\lambda} \frac{(\widetilde{a}_{\alpha , \epsilon}\left(x , \nu\right)) }{(\widetilde{d}\left(x , \nu\right))} \mathrm{d} \nu - \ln \widetilde{d}\left(t , x , \lambda\right) + \ln R\left(x\right) ,\]

where \(R\left(x\right)\) is an integration constant. Enforcing
normalisation on the invariant density gives
[[#eq-p-inv-norm-const][[eq-p-inv-norm-const]]]. ◻

#+end_proof
The explicit formula for \(P_{ss}\left(\lambda | x\right)\) allows us to
control its dependence on the frozen variable \(x\), whis is not
required to show exponential mixing but will be required later for
averaging principle.

#+begin_lemma
Let \(x , y \in \mathcal{D}_{\epsilon}\) and let
\(P_{ss}\left(\lambda | x\right)\) denote the invariant density from
[[#lem-invariant-density][[lem-invariant-density]]]. Then there exists
\(K_P > 0\) such that
\[\| P_{ss}\left(\cdot | x\right) - P_{ss}\left(\cdot | y\right)\|_{L^1} \leq K_P \| x - y\| .\]

#+end_lemma

#+begin_proof
/Proof./ The proof is straightforward via MD simulations.  ◻

#+end_proof
With estimates for both the transient dynamics
([[#lem-lam-smooth-denst][[lem-lam-smooth-denst]]]) and the invariant
density ([[#lem-invariant-density][[lem-invariant-density]]]), we now
establish convergence to equilibrium. The strategy we will follow is
standard. From [[#lem-lam-smooth-denst][[lem-lam-smooth-denst]]], we
will extract a uniform lower bound on the Greens function (the Doeblin
constant), use it to show contraction in total variation, and iterate to
obtain exponential mixing, see notes on convergence of Markov processes
in [[#hairer2021][[hairer2021]]] for the procedure.

#+begin_lemma
Let \(x \in \mathcal{D}_{\epsilon}\) be fixed, let \(\lambda_t\) evolve
acccording to the forward generator \(\mathcal{A}^{*}_x\) given by
[[#lem-fwd-gen][[lem-fwd-gen]]] and let
\(\rho_x\left(t , \lambda giv \mu\right)\) denote the Greens function
from [[#lem-lam-smooth-denst][[lem-lam-smooth-denst]]] evaluated at time
\(t \in \left[0 , T\right]\). Then there exists a positif function
\(\eta_t\left(x\right) > 0\) such that
\[\rho_x\left(t , \lambda giv \mu\right) \geq \eta_t\left(x\right) \quad \forall \lambda , \mu \in \left[- 1 , 1\right] ,\]

#+end_lemma

#+begin_proof
/Proof./ From [[#lem-lam-smooth-denst][[lem-lam-smooth-denst]]], we have
\[\begin{aligned}
\rho_x\left(t , \lambda giv \mu\right) &\geq \frac{(R_{\text{L}}\left(x\right))}{\sqrt{t}} \exp\left[-\frac{(C_1\left(x\right)\left(\lambda -\mu\right)^2 )}{t}\right] , \\
\end{aligned}\] from which we can define \[\begin{aligned}
\eta_t\left(x\right) & \eqdef \inf_{\lambda , \mu} \frac{(R_{\text{L}}\left(x\right))}{\sqrt{t}} \exp\left[-\frac{(C_1\left(x\right)\left(\lambda -\mu\right)^2 )}{t}\right] , \\
 & = \frac{(R_{\text{L}}\left(x\right))}{\sqrt{t}} \exp\left[-\frac{(4 C_1\left(x\right) )}{t}\right] . \\
\end{aligned}\] ◻

#+end_proof
#+begin_corollary
Due to the existance of \(\eta_t\left(x\right)\) one can always
decompose the Greens function into
\[\rho_x\left(t , \lambda giv \mu\right) = \eta_t\left(x\right) + r_t\left(\lambda giv x , \mu\right) ,\]

where \(r_t\left(\lambda giv x , \mu\right) \geq 0\) is the contribution
to the kernel the spends on the initial condition \(\mu\) and the state
\(\lambda\). Notice that we have
\[\int_{- 1}^1 r_t\left(\lambda giv x , \mu\right) \mathrm{d} \lambda = 1 - 2 \eta_t \left(x\right) ,\]
due to the normalisation of the Greens function over \(\lambda\), which
inturn implies that
\(\eta_t\left(x\right) \in \left[0 , 1 \/ 2\right]\).

#+end_corollary

#+begin_corollary
Since \(\eta_t\left(x\right)\), when it exists it must be finite, and
since we can always globally bound \(\| x_t\|\) on the interval
\(\left[0 , T\right]\), there must exist uniform lower bound on the
interval \(t \in \left(0 , T\right]\). We call this

\[C_{T , \eta} \eqdef \inf_{t \in \left[0 , T\right]} \eta_t \left(x_t\right).\]

#+end_corollary

Reviewed to here.

A useful object that we weill employ in our upcomoing proofs is the
called the transition operator. We will defnote it iwth
\(\mathcal{T}_t\) and its action on action on action on on a probability
density \(P_s \in \operatorname{dom}(\mathcal{A}^{*}_x)\) is defined via
\[\left(\mathcal{T}_t P_s\right)\left(x\right) \eqdef \int_{- 1}^1 \rho_x\left(t , \lambda giv \mu\right) P_s\left(\mu giv x\right) \mathrm{d} \mu ,\]
from which
\[P_{t + s} \left(\lambda\right) = \left(\mathcal{T}_s P_t\right)\left(x\right) ,\]

follows. Note that by definition of the invarint density we must have
\(P_{ss}\left(\lambda\right) = \mathcal{T}_s P_{ss} \left(\lambda\right)\).

#+begin_lemma
Let \(x \in \mathcal{D}_{\epsilon}\) be fixed, and let \(\lambda_t\) ​
evolve according to the SDE with forward generator \(A^{*}_x\) given by
[[#lem-fwd-gen][[lem-fwd-gen]]], let
\[P_t \left(\lambda giv x\right) , Q_t \left(\lambda giv x\right) \in \operatorname{dom}(\mathcal{A}^{*}_x)\]
with some normalised initial condition. Let \(\mathcal{T}_t\) be the
transition operator defined in [[#eq-def-trans-op][[eq-def-trans-op]]],
and let \(t , s > 0\). Then the inequality

\[\begin{aligned}
\operatorname{lpnorm}(P_{s + t}\left(\lambda giv x\right) - Q_{s + t}\left(\lambda giv x\right), \text{TV}, ) &\leq \left[1 - 2 \eta_s\left(x\right)\right] \operatorname{lpnorm}(P_t\left(\lambda giv x\right) - Q_t\left(\lambda giv x\right), \text{TV}, ) ,
\end{aligned}\] is ssatisfied where \(\eta(x)\) is the constant given in
[[#lem-doeblin][[lem-doeblin]]].

#+end_lemma

#+begin_proof
/Proof./ Using the definition of the transtion operator from
[[#eq-def-trans-op][[eq-def-trans-op]]] we obtain
\[\left(\mathcal{T}_s P_t\right)\left(\lambda\right) - \left(\mathcal{T}_s Q_t\right)\left(\lambda\right) = \int_{- 1}^1 \rho_x\left(s , \lambda giv \mu\right) \left(P_t \left(\mu\right) - Q_t \left(\mu\right)\right)\mathrm{d} \mu ,\]
where \(\rho_x\left(s , \lambda giv \mu\right)\) is the Greens function
for the forward equation, and where we have drop the conditional
dependence on \(x\) in the notation for clarity. Substituting in the
decomposition given in [[#eq-green-decomp][[eq-green-decomp]]] into
[[#eq-tv-bound-setup][[eq-tv-bound-setup]]] yeilds

\[\begin{aligned}
\left(\mathcal{T}_s P_t\right)\left(\lambda\right) - \left(\mathcal{T}_s Q_t\right)\left(\lambda\right) & = \eta(x) \int_{- 1}^1 \left(P_t\left(\mu\right) - Q_t\left(\mu\right)\right)\mathrm{d} \mu \int_{- 1}^1 r_s\left(\lambda , \mu\right) \left(P_t\left(\mu\right) - Q_t\left(\mu\right)\right)\mathrm{d} \mu , \\
 & = \int_{- 1}^1 r_s\left(\lambda , \mu\right) \left(P_t\left(\mu\right) - Q_t\left(\mu\right)\right)\mathrm{d} \mu .
\end{aligned}\]

Taking the absolute value on both sides allows to obtain the inequality
\[\begin{aligned}
\left|(\mathcal{T}_s P_t) (\lambda ) - (\mathcal{T}_s Q_t) (\lambda )\right| & = \left|\int_{- 1}^1r_s(\lambda , \mu ) ( P_t\left(\mu\right) - Q_t\left(\mu\right) )\mathrm{d}\mu\right| \\
 &\leq \int_{- 1}^1 r_s\left(\lambda , \mu\right) \left|P_t(\mu ) - Q_t(\mu )\right|\mathrm{d} \mu .
\end{aligned}\]

Finally, integrating both sides w.r.t \(\lambda\) allows to eliminate
\(r_s \left(\lambda , \mu\right)\) using
[[#cor-lem-doeblin-res][[cor-lem-doeblin-res]]] yeilding
\[\begin{aligned}
\int_{- 1}^{- 1} \left|(\mathcal{T}_s P_t) (\lambda ) - (\mathcal{T}_s Q_t) (\lambda )\right|\mathrm{d} \lambda &\leq \int_{- 1}^1 \left|P_t(\mu ) - Q_t(\mu )\right| \left(\int_{- 1}^1 r_s\left(\lambda , \mu\right) \mathrm{d} \lambda\right) \mathrm{d} \mu , \\
 &\leq \left[1 - 2 \eta_s\left(x\right)\right] \int_{- 1}^1 \left|P_t(\mu ) - Q_t(\mu )\right| \mathrm{d} \mu ,
\end{aligned}\] or in the norm-notation \[\begin{aligned}
\operatorname{lpnorm}(\left(\mathcal{T}_s P_t\right)\left(\lambda\right) - \left(\mathcal{T}_s Q_t\right)\left(\lambda\right), L^1, ) &\leq \left[1 - 2 \eta_s\left(x\right)\right] \operatorname{lpnorm}(P_t\left(\mu\right) - Q_t\left(\mu\right), L^1, ) .
\end{aligned}\]

To write [[#eq-l1-norm-tp][[eq-l1-norm-tp]]] in terms of the total
variation we employ the fact that that \(P_t\) and \(Q_t\) are
absolutely continuous with respect to the Lebesgue measure, hence
\[\begin{aligned}
\operatorname{lpnorm}(P_t \left(\lambda\right) - Q_t \left(\lambda\right), \text{TV}, ) //&\eqdef sup_(omega in cal(B)([-1, 1]))|P_(t) (lambda) - Q_(t) (lambda)|,\ & = \frac{1}{2} \int_{- 1}^1 | P_t \left(\lambda\right) - Q_t \left(\lambda\right) | \mathrm{d} \lambda . \\
\end{aligned}\] ◻

#+end_proof
#+begin_lemma
For any probability densities \(P\), \(Q\) on a compact set
\(\Omega \subseteq \mathbb{R}^d\),
\[\operatorname{lpnorm}(P - Q, \text{TV}, ) \leq 1\]

#+end_lemma

#+begin_proof
/Proof./ We define
\(\Omega^{+} = \left\{\omega \in \Omega | P\left(\omega\right) \geq Q\left(\omega\right)\right\}\),
and
\[\Omega^{-} = \left\{\omega \in \Omega | P\left(\omega\right) < Q\left(\omega\right)\right\}\]
then
\[\int_{\Omega}| P\left(\omega\right) - Q\left(\omega\right) | \mathrm{d} \omega = \int_{\Omega^{+}}\left[P\left(\omega\right) - Q\left(\omega\right)\right] \mathrm{d} \omega + \int_{\Omega^{-}}\left[Q\left(\omega\right) - P\left(\omega\right)\right] \mathrm{d} \omega .\]
By exploiting the normalisation of the densities we have that
\[\int_{\Omega^{+}}\left[P\left(\omega\right) - Q\left(\omega\right)\right] \mathrm{d} \omega = \int_{\Omega^{-}}\left[Q\left(\omega\right) - P\left(\omega\right)\right] \mathrm{d} \omega ,\]
and calling this common quantity \(C\), we observe that
\[C \eqdef \int_{\Omega^{+}}\left[P\left(\omega\right) - Q\left(\omega\right)\right] \mathrm{d} \omega \leq \int_{\Omega^{+}}\left[P\left(\omega\right)\right] \mathrm{d} \omega \leq \int_{\Omega}\left[P\left(\omega\right)\right] \mathrm{d} \omega \leq 1 .\]
Then from the defintion of the the total variation we have
\[\operatorname{lpnorm}(P - Q, \text{TV}, ) = \frac{1}{2} \int_{\Omega}| P\left(\omega\right) - Q\left(\omega\right) | \mathrm{d} \omega = C \leq 1 .\] ◻

#+end_proof
#+begin_theorem
Let \(x \in \mathcal{D}_{\epsilon}\) be fixed, let \(t > 0\) and let
\(\lambda_t\) evolve according to the SDE with the forward generate
\(\mathcal{A}^{*}_x\) given by [[#lem-fwd-gen][[lem-fwd-gen]]], and let
\(P_t \in \operatorname{dom}(\mathcal{A})^{*}_x\) represent the
occupation probability density with the initial condition
\(P_0\left(\lambda giv x\right)\). Let \(P_{ss}\) be the invariant
density satisfying
\(\left(\mathcal{A}^{*}_x P_{ss}\right)\left(\lambda\right) = 0\). Then
for any \(\tau \in \left(0 , t\right)\), there exisits constants
\(C\left(x\right) > 0\) and \(\kappa_{\tau}\left(x\right) > 0\) such
that
\[\operatorname{lpnorm}(P_t \left(\lambda giv x\right) - P_{ss}\left(\lambda giv x\right), \text{TV}, ) \leq C\left(x\right) ee^{-\kappa_{\tau}\left(x\right) t},\]
where \(\kappa_{\tau}\left(x\right) = 2 \eta_{\tau}\frac{(x) }{\tau}\)
with \(\eta_{\tau}\left(x\right)\) the Doeblin constant from
[[#lem-doeblin][[lem-doeblin]]].

#+end_theorem

#+begin_proof
/Proof./ Let \(\tau > 0\) such that \(\tau \ll t\) and let
\(m \eqdef \left\lfloor t \/\tau\right\rfloor\), then using the fact that
\(\mathcal{T}_{\tau} P_{ss}\left(\lambda\right)\) and
[[#lem-tv-bound][[lem-tv-bound]]] we obtain
\[\operatorname{lpnorm}(P_{m \tau}\left(\lambda\right) - P_{ss}\left(\lambda\right), \text{TV}, ) \leq \left(1 - 2\eta_{\tau}\left(x\right)\right)\operatorname{lpnorm}( P_{\left(m - 1\right)\tau}\left(\lambda\right) - P_{ss}\left(\lambda\right), \text{TV}, ) ,\]
and using the same lemma repeatedly, that is utilising the semigrouip
property, yeilds \[\begin{aligned}
\operatorname{lpnorm}(P_{m \tau}\left(\lambda\right) - P_{ss}\left(\lambda\right), \text{TV}, ) &\leq \left(1 - \eta_{\tau}\left(x\right)\right)^m \operatorname{lpnorm}(P_0\left(\lambda\right) - P_{ss}\left(\lambda\right), \text{TV}, ) , \\
 &\leq \left(1 - 2\eta_{\tau}\left(x\right)\right)^m,
\end{aligned}\]

where in the last step we have employed
[[#lem-tv-upper-bound][[lem-tv-upper-bound]]]. We can rewrite the right
hand side in [[#eq-tv-bound-1][[eq-tv-bound-1]]] using exponentials to
obtain \[\begin{aligned}
\left(1 - \eta_{\tau}\left(x\right)\right)^m & = e^{m \ln\left[1 - \eta(x)\right]} \leq ee^{- 2\eta( x) \left\lfloor t \/\tau\right\rfloor} \leq ee^{- 2\eta( x) \left(t \/\tau - 1\right)} = C_1\left(x\right) ee^{-\kappa_{\tau}\left(x\right) t},
\end{aligned}\] where
\(C_1\left(x\right) \eqdef ee^{2\eta_{\tau}\left(x\right)}\) and
\(\kappa_{\tau}\left(x\right) \eqdef 2\eta_{\tau}\left(x\right) \/ \tau\).
With \(\eta_{\tau}\left(x\right) \in \left(0 , 1 \/ 2\right]\), we take
\(C_1\left(x\right) \leq \operatorname{ee}(1) = C\) to get the desired
bound. ◻

#+end_proof
#+begin_corollary
The bound on the differences between probability measures obtained in
[[#thm-exp-mixing-doe][[thm-exp-mixing-doe]]] affords us a further
bound, namely on the differences in expectations. As before with
\(0 < \tau < t\)

\[\begin{aligned}
\left|\EE\left[f\left(\lambda_t\right)\right]-\int^1_{- 1}f\left(\lambda\right) P_{ss}(\lambda )\mathrm{d}\lambda\right| &\leq \int_{- 1}^1 \left|f\left(\lambda\right) [ P_t\left(\lambda\right) - P_{ss}\left(\lambda\right) ]\right| \mathrm{d} \lambda , \\
 &\leq \operatorname{lpnorm}(f\left(\lambda\right), L^{\infty}, ) \operatorname{lpnorm}(P_t\left(\lambda\right) - P_{ss}\left(\lambda\right), L^1, ) , \\
 &\leq 2 C ee^{-\kappa_{\tau}\left(x\right) t} \operatorname{lpnorm}(f\left(\lambda\right), L^{\infty}, ) . \\
\end{aligned}\]

where we have used Hoelders inequality to obtain the penultimate bound .
Obviously, the final supremum bound is of course only meaningful when we
have bounded \(f\) on the interval \(\lambda \in \left[- 1 , 1\right]\).

#+end_corollary

In summary, we have established the existence of an intermediate
timescale \(\delta\) with \(\epsilon \ll \delta \ll 1\) on which \(x_t\)
remains approximately fixed while \(\lambda_t\) rapidly equilibrates to
\(P_{ss}\left(\lambda | x\right)\). We also proved that equilibration
occurs through exponential mixing for which the transversality was
crucial. These estimates are essential to derive the averaging principle
in the next section.

*  Averaging Principle
:PROPERTIES:
:CUSTOM_ID: sec-avg-principle
:END:
We are now ready to introduce the averaging principle for the fast
switching variable dynamics

#+begin_definition
Let \(x_t \in \mathcal{D}_{\epsilon}\) be a solution of the
piecewise-smooth SDE given in [[#def-ns-gen-sde][[def-ns-gen-sde]]], and
let \[\lambda \in \left[- 1 , 1\right]\] be the switching variable
parametrising the convex interpolation

\[\begin{aligned}
a\left(t , x , \lambda\right) & = \frac{1}{2}\left(1 + \lambda\right) a^{+}\left(t , x\right) + \frac{1}{2}\left(1 - \lambda\right) a^{-}\left(t , x\right) , \\
 b\left(t , x , \lambda\right) & = \frac{1}{2}\left(1 + \lambda\right) b^{+}\left(t , x\right) + \frac{1}{2}\left(1 - \lambda\right) b^{-}\left(t , x\right) ,
\end{aligned}\]

between the piecewise-smooth coefficients \(a^{pm}\) and \(b^{pm}\). Let
\(P_{ss}\left(\lambda | x\right)\) denote the stationary distribution of
the switching variable conditional on \(x\), satisfying
\[\mathcal{A}_x^{*} P_{ss} = 0\] with zero-flux boundary conditions (see
[[#lem-fwd-gen][[lem-fwd-gen]]]). The reduced SDE is

\[\mathrm{d} y_t = \left[\bar{a}_{\alpha , \epsilon}\left(t , y_t\right) + \alpha \epsilon \bar{c}\left(t , y_t\right)\right] \mathrm{d} t + \sqrt{\epsilon}\text{ }\bar{b}\left(t , y_t\right) \mathrm{d} W_t,\]

where the averaged coefficients are

\[\begin{aligned}
\bar{a}_{\alpha , \epsilon}\left(t , x\right) & = \int_{- 1}^1 a_{\alpha , \epsilon}\left(t , x , \lambda\right) P_{ss}\left(\lambda | x\right) \mathrm{d} \lambda , # <eq-avg-a> \\
 \bar{b}\left(t , x\right) & = \int_{- 1}^1 b\left(t , x , \lambda\right) P_{ss}\left(\lambda | x\right) \mathrm{d} \lambda , # <eq-avg-b> \\
 \bar{c}\left(t , x\right) & = \int_{- 1}^1 c\left(t , x , \lambda\right) P_{ss}\left(\lambda | x\right) \mathrm{d} \lambda , # <eq-avg-c>
\end{aligned}\]

and

\[c\left(t , x , \lambda\right) = \sum_j J_x \left[b_j \left(t , x , \lambda\right)\right] b_j \left(t , x , \lambda\right)\]

is the Itō correction arising from the \(\alpha\)-interpretation of the
stochastic integral, with \(b_j \left(t , x , \lambda\right)\) denoting
the \(j\)-th column of \(b\left(t , x , \lambda\right)\) and
\(J_x \left(\cdot\right)\) the Jacobian with respect to \(x\).

#+end_definition

Unsurprisingly, without any hidden term in the dynamics we require only
the mean from the distribution \(P_{ss} \left(\lambda\right)\),

#+begin_lemma
Let \(x \in \mathcal{D}_{\epsilon}\), \[t \in \left[0 , T\right]\] , and
let \(\bar{a}_{\alpha , \epsilon}\left(t , x\right)\),
\(\bar{b}\left(t , x\right)\), and \[\bar{c}\left(t , x\right)\] be the
averaged coefficients defined in [[#eq-avg-a][[eq-avg-a]]]
[[#eq-avg-b][[eq-avg-b]]] [[#eq-avg-c][[eq-avg-c]]]. Then \(\bar{a}\),
\(\bar\left\{b\right\}\), and \(\bar{c}\) inherit the regularity of the
convex combinations \(a\left(t , x , \lambda\right)\),
\(b\left(t , x , \lambda\right)\), and
\[c\left(t , x , \lambda\right)\] . Specifically, there exist constants
\[\bar{C} , \bar{K} , \bar{K}_T > 0\] such that:

1. Linear growth. For any \(x \in \mathbb{R}^2\) and
   \(t \in\left[0 , T\right]\),
   \[\|\bar{a}_{\alpha , \epsilon}\left(t , x\right)\| + \|\bar{b}\left(t , x\right)\| \leq C\left(1 + \| x\|\right) .\]

2. Lipschitz continuity. For any \(x , y \in \mathbb{R}^2\) and
   \(s , t \in\left[0 , T\right]\)
   \[\|\bar{a}_{\alpha , \epsilon}\left(t , x\right) - \bar{a}_{\alpha , \epsilon}\left(t , y\right)\| + \|\bar{b}\left(t , x\right) - \bar{b}\left(t , y\right)\| \leq C\left(1 + \| x\|\right) .\]

#+end_lemma

#+begin_proof
/Proof./ Linear growth. For
\(\bar{a}_{\alpha , \epsilon}\left(t , x\right)\), using the definition
[[#eq-avg-a][[eq-avg-a]]] and the linear growth bound on
\(a\left(t , x , \lambda\right)\) from
[[#lem-coeff-tilde-bounds][[lem-coeff-tilde-bounds]]], \[\begin{aligned}
\|\bar{a}_{\alpha , \epsilon}\left(t , x\right)\| & = \left\|\int_{- 1}^1a\left(t , x , \lambda\right) P_{ss}(\lambda | x )\mathrm{d}\lambda\right\| \\
 &\leq \int_{- 1}^1 \| a\left(t , x , \lambda\right)\| P_{ss}\left(\lambda | x\right) \mathrm{d} \lambda \\
 &\leq \int_{- 1}^1 C\left(1 + \| x\|\right) P_{ss}\left(\lambda | x\right) \mathrm{d} \lambda \\
 & = C\left(1 + \| x\|\right) ,
\end{aligned}\] since \(P_{ss}\left(\lambda | x\right)\) is a
probability density. The same argument applies to
\(\bar{b}\left(t , x\right)\) using the linear growth bound on
\(b\left(t , x , \lambda\right)\), giving
\[\|\bar{b}\left(t , x\right)\| \leq C\left(1 + \| x\|\right) .\] For
\(\bar{c}\left(t , x\right)\), using [[#eq-avg-c][[eq-avg-c]]] and the
bound on \(c\left(t , x , \lambda\right)\) from
[[#lem-coeffs-lam][[lem-coeffs-lam]]],
\[\|\bar{c}\left(t , x\right)\| \leq \int_{- 1}^1 \| c\left(t , x , \lambda\right)\| P_{ss}\left(\lambda | x\right) \mathrm{d} \lambda \leq C_J C \left(1 + \| x\|\right) .\]
Thus all averaged coefficients satisfy linear growth with
\(\bar{C} = \max\left\{C , C_J C\right\}\).

Lipschitz continuity. For
\(\bar{a}_{\alpha , \epsilon}\left(t , x\right) - \bar{a}_{\alpha , \epsilon}\left(s , y\right)\),
we write \[\begin{aligned}
\bar{a}_{\alpha , \epsilon}\left(t , x\right) - \bar{a}_{\alpha , \epsilon}\left(s , y\right) & = \int_{- 1}^1 a_{\alpha , \epsilon}\left(t , x , \lambda\right) P_{ss}\left(\lambda | x\right) \mathrm{d} \lambda - \int_{- 1}^1 a_{\alpha , \epsilon}\left(s , y , \lambda\right) P_{ss}\left(\lambda | y\right) \mathrm{d} \lambda , \\
 & = \int_{- 1}^1 \left[a_{\alpha , \epsilon}\left(t , x , \lambda\right) - a_{\alpha , \epsilon}\left(s , y , \lambda\right)\right] P_{ss}\left(\lambda | x\right) \mathrm{d} \lambda \\
 &\quad + \int_{- 1}^1 a_{\alpha , \epsilon}\left(s , y , \lambda\right) \left[P_{ss}\left(\lambda | x\right) - P_{ss}\left(\lambda | y\right)\right] \mathrm{d} \lambda .
\end{aligned}\]

For the first integral, using the Lipschitz bound in
[[#eq-ab-lip-bound][[eq-ab-lip-bound]]] yeilds \[\begin{aligned}
\left\|\int_{- 1}^1[ a\left(t , x , \lambda\right) - a\left(s , y , \lambda\right) ] P_{ss}(\lambda | x )\mathrm{d}\lambda\right\| &\leq \int_{- 1}^1 \| a\left(t , x , \lambda\right) - a\left(s , y , \lambda\right)\| P_{ss}\left(\lambda | x\right) \mathrm{d} \lambda \\
 & = K \| x - y\| + K_T | t - s | .
\end{aligned}\]

For the second integral, we employ the Lipschitz bound from
[[#lem-pss-lipschitz][[lem-pss-lipschitz]]] for the invariant density to
obtain

\[\begin{aligned}
\left\|\int_{- 1}^1a\left(s , y , \lambda\right) [ P_{ss}\left(\lambda | x\right) - P_{ss}\left(\lambda | y\right) ]\mathrm{d}\lambda\right\| &\leq \sup_{\lambda} \| a\left(s , y , \lambda\right)\| \operatorname{lpnorm}(P_{ss}\left(\cdot | x\right) - P_{ss}\left(\cdot | y\right), L^1, ) \\
 &\leq C\left(1 + \| y\|\right) K_P \| x - y\| .
\end{aligned}\]

Combining both terms,
\[\|\bar{a}_{\alpha , \epsilon}\left(t , x\right) - \bar{a}_{\alpha , \epsilon}\left(s , y\right)\| \leq \left[K + C\left(1 + \| y\|\right) K_P\right] \| x - y\| + K_T | t - s | .\]
For \(x , y\) in a bounded set (which holds on \(\left[0 , T\right]\) by
[[#lem-poly-mom-bound][[lem-poly-mom-bound]]]), we obtain
\[\|\bar{a}_{\alpha , \epsilon}\left(t , x\right) - \bar{a}_{\alpha , \epsilon}\left(s , y\right)\| \leq \bar{K} \| x - y\| + \bar{K}_T | t - s | ,\]

with \(\bar{K} = K + C\left(1 + R_T\right) K_P\) and
\(\bar{K}_T = K_T\), where \(R_T\) bounds \(\| x\|\) and \(\| y\|\) on
the interval. The same argument applies to \(\bar{b}\), giving the
Lipschitz bounds claimed in the lemma. ◻

#+end_proof
With the averaged coefficients satisfying the same regularity as the
original system given in [[#def-ns-gen-sde][[def-ns-gen-sde]]], we can
state the main error estimate for substituting in place of the pws
system which is implicitly multi-timescale system with its averaged
counterpart.

#+begin_theorem
Let \(\left(t , x_t, \lambda_t\right)\) evolve according to the coupled
slow-fast system of [[#cor-coupled-sde][[cor-coupled-sde]]] with
coefficients satisfying regularity conditions
[[#lem-coeff-tilde-bounds][[lem-coeff-tilde-bounds]]], and let \(y_t\)
evolve according to the reduced SDE given in
[[#def-reduced-sde][[def-reduced-sde]]], with coefficients satisfying
conditions given in [[#lem-avg-coeff-bounds][[lem-avg-coeff-bounds]]].
Let \(T > 0\), \(\gamma , \epsilon > 0\) and assume
\(x_0 = y_0 \in \mathcal{D}_{\epsilon}\) with
\(\lambda_0 \in \left[- 1 , 1\right]\). Then there exists a constant
\(C^{\text{er}}_T > 0\), depending on \(T\), Lipschitz constants and the
linear growth constants, such that
\[\PP\left[\sup_{t \in \left[0 , T\right]} \| x_t - y_t\| > \gamma\right] \leq \frac{1}{\gamma^2} C^{\text{er}}_T \sqrt{\epsilon} .\]

#+end_theorem

#+begin_proof
/Proof./ Let us define \(\xi_t \eqdef x_t - y_t\), which gives us the
initial condition \(x_0 = 0\)

then substrituting in the definition for the
\[\xi_t = \int^t_0 a_{\alpha , \epsilon}\left(s , x_s, \lambda_s\right) - \bar{a}_{\alpha , \epsilon}\left(s , y_s\right) \mathrm{d} s + \sqrt{\epsilon} \int^t_0 b\left(s , x_s, y_s\right) - \bar{b}\left(s , y_s\right) \mathrm{d} W_s,\]

Let us define the following integrands

\[\begin{aligned}
I_a \left(s\right) & \eqdef a_{\alpha , \epsilon}\left(s , x_s, \lambda_s\right) - \bar{a}_{\alpha , \epsilon}\left(s , y_s\right), \\
 I I_a \left(s\right) & \eqdef \bar{a}_{\alpha , \epsilon}\left(s , x_s\right) - \bar{a}_{\alpha , \epsilon}\left(s , y_s\right) ,
\end{aligned}\] similarly for the noise coefficient we have
\[\begin{aligned}
I_b \left(s\right) & \eqdef b\left(s , x_s, \lambda_s\right) - \bar{b}\left(s , y_s\right), \\
 I I_b \left(s\right) & \eqdef \bar{b}\left(s , x_s\right) - \bar{b}\left(s , y_s\right) ,
\end{aligned}\]

Then consider

\[\begin{aligned}
\|\xi_t\|^2 &\leq 2 \left\|\int^t_0I_a( s ) + I I_a( s )\mathrm{d} s\right\|^2 + 2 \epsilon \left\|\int^t_0I_b( s ) + I I_b( s )\mathrm{d} W_s\right\|^2, \\
 &\leq 2 t \int^t_0 \| I_a \left(s\right) + I I_a \left(s\right)\|^2 \mathrm{d} s + 2 \epsilon \left\|\int^t_0I_b( s ) + I I_b( s )\mathrm{d} W_s\right\|^2, \\
\end{aligned}\]

where in the first instance we have used the inequality
\[| a + b |^2 \leq 2 \left(| a |^2 + | b |^2\right)\] (Cauchy-Schwarz),
and in the second case we have also used Cauchy-Schwarz. Taking the
expectation allows us to use Itō isometry on teh stochastic integral,

\[\EE\left[\|\xi_t\|^2\right] \leq 2 t \EE\left[\int^t_0 \| I_a \left(s\right) + I I_a \left(s\right)\|^2 \mathrm{d} s\right] + 2 \epsilon \EE\left[\int^t_0 \| I_b \left(s\right) + I I_b \left(s\right)\|^2 \mathrm{d} s\right] ,\]
and using Cauchy-Schwarz again on the intergrand gives

\[\EE\left[\|\xi_t\|^2\right] \leq 4 t \EE\left[\int^t_0 \| I_a \left(s\right)\|^2 + \| I I_a \left(s\right)\|^2 \mathrm{d} s\right] + 4\epsilon \EE\left[\int^t_0 \| I_b \left(s\right)\|^2 + \| I I_b \left(s\right)\|^2 \mathrm{d} s\right] .\]

From [[#lem-avg-coeff-bounds][[lem-avg-coeff-bounds]]] we know that
\(I I_a \left(s\right)\) and \(I I_b \left(s\right)\) can be bounded as
it is is just an application of Lipschitz,

\[\begin{aligned}
4 t \| I I_a \left(s\right) \|^2 + 4\epsilon \| I I_b \left(s\right) \|^2 & = 4 t\|\bar{a}_{\alpha , \epsilon}\left(s , x_s\right) - \bar{a}_{\alpha , \epsilon}\left(s , y_s\right) \|^2 + 4\epsilon\|\bar{b}\left(s , x_s\right) - \bar{b}\left(s , y_s\right) \|^2 \\
 &\leq 4 \bar{K}^2\left(T + \epsilon\right) \|\xi_s\|^2.
\end{aligned}\]

For the other two integrals we consider first the parition of
\(\left[0 , t\right]\) into the windows
\(\left[k \delta , \left(k + 1\right) \delta\right]\) with
\(k = 0 , 1 , \ldots N - 1\) where \[N = t \/ \delta\] and then
recasting the integrals as, for example,

\[\int_0^t \| I_a \left(s\right)\|^2 \mathrm{d} s = \sum_{k = 0}^{N - 1} \int_0^{\delta} \| I_{a , k} \left(k \delta + s\right)\|^2 \mathrm{d} s ,\]

where \(I_{a , k}\left(s\right) \eqdef I_a\left(k \delta + s\right)\)
with \(s \in \left[0 , \delta\right)\). We then recast the integrand as

\[I_{a , k}\left(s\right) = \sum_{\ell = 1}^5 J^{\left(\ell\right)}_{a , k} \left(s\right) ,\]

where

\[\begin{aligned}
J^{\left(1\right)}_{a , k}\left(s\right) & \eqdef a\left(k \delta + s , x_{k \delta + s}, \lambda_{k \delta + s}\right) - a\left(k \delta + s , x_{k \delta}, \lambda_{k \delta + s}\right), \\
 J^{\left(2\right)}_{a , k}\left(s\right) & \eqdef a\left(k \delta + s , x_{k \delta}, \lambda_{k \delta + s}\right) - a\left(k \delta , x_{k \delta}, \lambda_{k \delta + s}\right) , \\
 J^{\left(3\right)}_{a , k}\left(s\right) & \eqdef a\left(k \delta , x_{k \delta}, \lambda_{k \delta + s}\right) - \bar{a}\left(k \delta , x_{k \delta}\right) , \\
 J^{\left(4\right)}_{a , k}\left(s\right) & \eqdef \bar{a}\left(k \delta , x_{k \delta}\right) - \bar{a}\left(k \delta + s , x_{k \delta}\right), \\
 J^{\left(5\right)}_{a , k}\left(s\right) & \eqdef \bar{a}\left(k \delta + s , x_{k \delta}\right) - \bar{a}\left(k \delta + s , x_{k \delta + s}\right) . \\
\end{aligned}\]

Each term in the sum in [[#eq-i1-5-sum][[eq-i1-5-sum]]], is associated
with a particular type of error: \(J^{\left(1\right)}_{a , k}\) and
\(J^{\left(5\right)}_{a , k}\) are the spatial error associated with
fixing \(x\) with its value at the start of the interval for the drift
and avergaed drift fields respectively; \(J^{\left(2\right)}_{a , k}\)
and \(J^{\left(4\right)}_{a , k}\) are the temporal error associated,
respectivley, with drift and avergaed drift fields by fixing the
explicit time dependence to the start of the interval;
\(J^3\left(a , k\right)\) is the mixing error as all other dependences
are fixed. Clearly,

\[\| I_{a , k}\left(s\right)\|^2 \leq 5 \sum_{\ell = 1}^5 \| J^{\left(\ell\right)}_{a , k}\left(s\right)\|^2,\]

by Cauchy-Schwarz, and it only remains to bound the various squared
error terms. Employing the Lipschitz conditions in
[[#def-ns-gen-sde][[def-ns-gen-sde]]], and
[[#lem-avg-coeff-bounds][[lem-avg-coeff-bounds]]] as well as
[[#thm-slow-var][[thm-slow-var]]] we obtain

\[\begin{aligned}
\EE\left[\| J^{\left(1\right)}_{a , k}\left(s\right)\|^2\right] &\leq K^2_x \EE\left[\| x_s - x_{k \delta}\|^2\right] & &\leq K^2_xC \left(\delta^2 + \epsilon \delta\right) , \\
 \EE\left[\| J^{\left(5\right)}_{a , k}\left(s\right)\|^2\right] &\leq \bar{K}^2_x \EE\left[\| x_s - x_{k \delta}\|^2\right] & &\leq \bar{K}^2_x C \left(\delta^2 + \epsilon \delta\right) ,
\end{aligned}\] which control the spatial error, and similarly,
\[\begin{aligned}
\EE\left[\| J^{\left(2\right)}_{a , k}\left(s\right)\|^2\right] &\leq K^2_T s^2 &\leq K^2_T \delta^2, \quad \EE\left[\| J^{\left(4\right)}_{a , k}\left(s\right)\|^2\right] &\leq \bar{K}^2_T s^2 &\leq \bar{K}^2_T \delta^2 ,
\end{aligned}\] which controls the temporal error, Using these uniform
bounds we can integrate over time to yeild \[\begin{aligned}
\sum_{k = 0}^{N - 1} \int_0^{\delta} \EE\left[\| J^{\left(1\right)}_{a , k}\left(s\right)\|^2\right] \mathrm{d} s &\leq K^2_x C \left(\delta - \epsilon \delta\right) t & &\leq K^2_x T C \left(\delta - \epsilon \delta\right) , \\
 \sum_{k = 0}^{N - 1} \int_0^{\delta} \EE\left[\| J^{\left(3\right)}_{a , k}\left(s\right)\|^2\right] \mathrm{d} s &\leq \bar{K}^2_xC \left(\delta - \epsilon \delta\right) t & &\leq \bar{K}^2_xT C \left(\delta - \epsilon \delta\right) ,
\end{aligned}\] and for the temporal errors we obtain \[\begin{aligned}
\sum_{k = 0}^{N - 1} \int_0^{\delta} \EE\left[\| J^{\left(2\right)}_{a , k}\left(s\right)\|^2\right] \mathrm{d} s &\leq K^2_T t \delta^2 & &\leq K^2_T T \delta^2 , \\
 \sum_{k = 0}^{N - 1} \int_0^{\delta} \EE\left[\| J^{\left(5\right)}_{a , k}\left(s\right)\|^2\right] \mathrm{d} s &\leq \bar{K}^2_T t \delta^2 & &\leq \bar{K}^2_T T \delta^2,
\end{aligned}\]

We now turn to the mixxing error contribution, we first rewrite
\(J^{\left(3\right)}_{a , k}\left(s\right)\) as \[\begin{aligned}
J^{\left(3\right)}_{a , k}\left(s\right) & = \int_{- 1}^1 a\left(k \delta , x_{k \delta}, \lambda\right) \left[P_s \left(\lambda | x_{k \delta}\right) - P_{ss} \left(\lambda | x_{k \delta}\right)\right] \mathrm{d} \lambda
\end{aligned}\]

where
\[P_s \left(\lambda | x_{k \delta}\right) = ee^{s \mathcal{A}^{*}_{x_{k \delta}}} P_0\left(\lambda giv x_{k \delta}\right)\]
with \(P_0\left(\lambda | x_{k \delta}\right)\) being formally, the
normalised probability density of \(\lambda\) at the start of the
interval \[\left[k \delta , \left(k + 1\right) \delta\right]\] . Recall
that for \(k = 0\) we have
\[P_0 \left(\lambda giv x_0\right) = \delta(\lambda - \lambda_0)\] but
for all \(k > 0\) the initial probability density
\(P_0 \left(\lambda giv x_{k \delta}\right)\) corresponds to some
conditional probability density at \(t = k \delta > 0\) that by
[[#lem-lam-smooth-denst][[lem-lam-smooth-denst]]], is in
\(L^2_{P_{ss}}\). With \(J^{\left(2\right)}_{a , k , i}\left(s\right)\)
denoting the \(i^{\text{th}}\) component of the vector, we have for
\(k > 0\) \[\begin{aligned}
\| J^{\left(2\right)}_{a , k}\left(s\right)\|^2 = \sum_i | J^{\left(2\right)}_{a , k , i}\left(s\right) |^2 & = \sum_i \left|\int_{- 1}^1a_i( k \delta , x_{k \delta}, \lambda ) [ P_s \left(\lambda | x_{k \delta}\right) - P_{ss} \left(\lambda | x_{k \delta}\right)]\mathrm{d}\lambda\right|^2 \\
 &\leq \left[\sum_i \operatorname{lpnorm}(a_i\left(k \delta , x_{k \delta}, \lambda\right), L^{\infty}, 2)\right] \operatorname{lpnorm}(P_s \left(\lambda | x_{k \delta}\right) - P_{ss} \left(\lambda | x_{k \delta}\right), L^1, 2) , \\
 & = \sup_{\lambda} \| a\left(k \delta , x_{k \delta}, \lambda\right)\|^2 \operatorname{lpnorm}(P_s \left(\lambda | x_{k \delta}\right) - P_{ss} \left(\lambda | x_{k \delta}\right), L^1, 2) , \\
 & = 4 \sup_{\lambda} \| a\left(k \delta , x_{k \delta}, \lambda\right)\|^2 \operatorname{lpnorm}(P_s \left(\lambda | x_{k \delta}\right) - P_{ss} \left(\lambda | x_{k \delta}\right), \text{TV}, 2) , \\
 &\leq C_0 \left(1 + \| x\|^2\right) \operatorname{lpnorm}(P_s \left(\lambda | x_{k \delta}\right) - P_{ss} \left(\lambda | x_{k \delta}\right), \text{TV}, 2) , \\
\end{aligned}\]

where we have exploited the linear growth condition in
[[#def-ns-gen-sde][[def-ns-gen-sde]]], and where
\(C_0 \eqdef 8 \left(C_{+}+ C_{-}\right)^2\). Employing
[[#thm-exp-mixing-doe][[thm-exp-mixing-doe]]] with \[\tau = \epsilon\]
on the total variation term yeilds the bound

\[\operatorname{lpnorm}(P_s \left(\lambda | x_{k \delta}\right) - P_{ss} \left(\lambda | x_{k \delta}\right), \text{TV}, 2) \leq ee ee^{- 2 \eta_{\epsilon}\left(x_{k \delta}\right) s \/ \epsilon}.\]

For the \(k = 0\) term we have a Dirac distriubtion but the total
variation is still bounded from above by one via
[[#lem-tv-upper-bound][[lem-tv-upper-bound]]]. Putting it together we
obtain

\[\begin{aligned}
\sum_{k = 0}^{N - 1} \int_{k \delta}^{\left(k + 1\right) \delta} \EE\left[\| J^{\left(2\right)}_{a , k}\left(s\right)\|^2\right] &\leq \EE\left[C_0 \left(1 + \| x\|^2\right) \left(\delta + ee \sum_{k = 1}^{N - 1} \int_0^{\delta} ee^{- 2 \eta_{\epsilon}\left(x_{k \delta}\right) s \/ \epsilon} \mathrm{d} s\right)\right] , \\
 &\leq \EE\left[C_0 \left(1 + \| x\|^2\right) \left(\delta + ee \epsilon \sum_{k = 1}^{N - 1} \frac{(1 - ee^{- 2 \eta_{\epsilon}\left(x_{k \delta}\right) \delta \/ \epsilon})}{(2 \eta_{\epsilon} \left(x_{k \delta}\right))}\right)\right] , \\
 &\leq \EE\left[C_0 \left(1 + \| x\|^2\right) \left(\delta + ee \epsilon \sum_{k = 1}^{N - 1} \frac{(1)}{(2 \eta_{\epsilon} \left(x_{k \delta}\right))}\right)\right] .
\end{aligned}\]

This estimate can be made uniform the interval
\(t = \left[0 , T\right]\) by inovking
[[#lem-poly-mom-bound][[lem-poly-mom-bound]]] and
[[#cor-lem-doeblin-min-eta-bound][[cor-lem-doeblin-min-eta-bound]]] to
yeild

\[\begin{aligned}
\sum_{k = 0}^{N - 1} \int_{k \delta}^{\left(k + 1\right) \delta} \EE\left[\| J^{\left(2\right)}_{a , k}\left(s\right)\|^2\right] &\leq C_T \left[\delta + \frac{(ee \epsilon \left(N - 1\right)) }{(2 C_{T , \eta})}\right] \\
 &\leq C_T \left[\delta + \frac{(ee \epsilon N ) }{(2 C_{T , \eta})}\right] , \\
 &\leq M_T \left[\delta + \frac{(\epsilon t ) }{(\delta)}\right] \\
 &\leq M_T \left[\delta + \frac{(\epsilon T ) }{(\delta)}\right] ,
\end{aligned}\]

where
\(M_T \eqdef \max\left\{C_T, C_T ee \/ \left(2 C_{T , \eta}\right)\right\}\).
A similar procedure can be used to obtain the same bounds for
\(\| I_b\left(s\right)\|^2\). Assembling the various inequalities
together yeilds \[\begin{aligned}
\EE\left[\|\xi_t\|^2\right] &\leq 20\left(T + \epsilon\right) \left[T C\left(\delta^2 + \epsilon \delta\right) \left(K^2_x + \bar{K}^2_x\right) + T \delta^2\left(K^2_T + \bar{K}^2_T\right) + M_T \left(\delta + \frac{(\epsilon T)}{\delta}\right)\right] \\
 & + 4\bar{K}^2\left(T + \epsilon\right) \int_0^t \EE\left[\|\xi_s\|^2\right] \mathrm{d} s .
\end{aligned}\] Notice that we can simplify the various terms before we
apply Gronwalls inequality, by taking \(\delta^2 \leq \delta\) and
\(\epsilon \delta \leq \delta\), which allows us to write
\[\begin{aligned}
\EE\left[\|\xi_t\|^2\right] &\leq D^{\text{er}}_T \left(\delta + \frac{(\epsilon T)}{\delta}\right) + K^{\text{er}}_T \int_0^t \EE\left[\|\xi_s\|^2\right] \mathrm{d} s ,
\end{aligned}\] where we define the constants
\[D^{\text{er}}_T \eqdef 20 T \left(T + 1\right)\left[C\left(K^2_x + \bar{K}^2_x\right) + K^2_T + \bar{K}^2_T\right] + M_T, \quad \text{and} \quad K^{\text{er}}_T \eqdef 4 \bar{K}^2_x\left(T + 1\right) .\]

Both \(D^{\text{er}}_T\) and \(K^{\text{er}}_T\) depends on the
Lipschitz constants and the interval size \(T\), while the former also
on depends on the linear growth constants. Applying to
[[#eq-error-bound-pre-gron][[eq-error-bound-pre-gron]]] yeilds

\[\EE\left[\|\xi_t\|^2\right] \leq D^{\text{er}}_T \left(\delta + \frac{(\epsilon T) }{\delta}\right) ee^{K^{\text{er}}_T t}.\]

To connect the error bound at \(t \in \left[0 , T\right]\) to the
supremum bound we employ Doobs Maringale inequality (see e.g.
Proposition 1.5 in Chapter II of
[[#revuzyor19993book][[revuzyor19993book]]]) to obtain

\[\begin{aligned}
\EE\left[\sup_{t \in \left[0 , T\right]} \|\xi_t\|^2\right] &\leq 4 \sup_{t \in \left[0 , T\right]}\left\{\EE\left[\|\xi_t\|^2\right]\right\} \leq D^{\text{er}}_T \left(\delta + \frac{(\epsilon T) }{\delta}\right) ee^{K^{\text{er}}_T T}.
\end{aligned}\]

From [[#eq-error-bound-no-op][[eq-error-bound-no-op]]] we can observe
that the minimal error is achieved when
\[\delta^{*} \eqdef \operatorname{argminlimits: #true}_{\delta}\left[\left(\delta + \frac{(\epsilon T) }{\delta}\right)\right] = \sqrt{T \epsilon}\]
, thus absorbing all of the constants together we can define

\[C^{\text{er}}_T \eqdef D^{\text{er}}_T \sqrt{T} ee^{K^{\text{er}}_T T},\]
which after applying the inequality yeilds
\[\PP\left[\sup_{t \in \left[0 , T\right]} \| x_s - y_s\| > \gamma\right] \leq \frac{1}{\gamma^2} \EE\left[\sup_{t \in \left[0 , T\right]} \| x_s - y_s\|^2\right] \leq \frac{1}{\gamma^2} C^{\text{er}}_T \sqrt{\epsilon} ,\]
which is the desired bound. ◻

#+end_proof
*  Typical paths and Gaussian fluctuations
:PROPERTIES:
:CUSTOM_ID: sec-typical-paths
:END:
The reduced SDE given in [[#def-reduced-sde][[def-reduced-sde]]] is a
weak-noise SDE for which we have an LDP via Freidlin-Wentzell theory
(see Chap. 5, Sec. 3 of
[[#freidlinwentzell1998book][[freidlinwentzell1998book]]], and Chap. 5,
Sec. 6 of [[#dembozeitouni2010book][[dembozeitouni2010book]]], for
proofs and discussions). We state the relevant results here.

#+begin_theorem
Let \(y_t\) solve the reduced SDE [[#eq-reduced-sde][[eq-reduced-sde]]]
with coefficients satisfying the regularity conditions of
[[#lem-avg-coeff-bounds][[lem-avg-coeff-bounds]]], and let
\(y_0 = x_0\). Then \(y_t\) satisfies a large deviation principle with
rate function \[I_T \left[\varphi\right] = \begin{cases}
 \frac{1}{2} \int_0^T \|\left[\dot{\varphi}_t - \bar{a}\left(t , \varphi_t\right)\right]^{tns}\bar{d}\left(t , \varphi_t\right)^{- 1}\left[\dot{\varphi}_t - \bar{a}\left(t , \varphi_t\right)\right]\|^2 \mathrm{d} t \quad & \varphi \in \text{a.c. on } \left[0 , T\right] \\
 +\infty \quad & \text{otherwise}
\end{cases}\] where \[\varphi_0 = y_0\] and
\[\bar{d}\left(t , x\right) \eqdef \bar{b}\left(t , x\right) \bar{b}\left(t , x\right)^{tns}.\]

Hence, for any measurable set \(A\) of paths,
\[-\inf_{\varphi \in A^{\circ}} I_T \left[\varphi\right] \leq \liminf_{\epsilon \rightarrow 0} \epsilon \log \PP\left[y \in A\right] \leq \limsup_{\epsilon \rightarrow 0} \epsilon \log \PP\left[y \in A\right] \leq -\inf_{\varphi \in \bar{A}} I_T \left[\varphi\right] ,\]
where \(A^{\circ}\) and \(\bar{A}\) denote the interior and closure of
\(A\).

#+end_theorem

In the limit \(\epsilon \rightarrow 0\), the paths of \(y_t\)
concentrate around the typical paths of \(y_t\) which correspond to the
minimisers of \(I_T\). These satisfy the Euler-Lagrange equations

\[\frac{\mathrm{d} }{(\mathrm{d} t)} \frac{(\partial \mathcal{L}) }{(\partial \dot{\varphi})} - \frac{(\partial \mathcal{L}) }{(\partial \varphi)} = 0 ,\]

where the Lagrangian is
\[\mathcal{L}\left(t , \varphi , \dot{\varphi}\right) \eqdef \|\left[\dot{\varphi}_t - \bar{a}\left(t , \varphi_t\right)\right]^{tns} \bar{d}\left(t , \varphi_t\right)^{- 1}\left[\dot{\varphi}_t - \bar{a}\left(t , \varphi_t\right)\right]\|^2\]
For a minimiser \(\varphi^{*}_t\) with \(\varphi^{*}_0 = x_0\),
Freidlin-Wentzell theory states that for any \(\gamma > 0\),

\[\PP\left[\sup_{t \in \left[0 , T\right]} \| y_t - \varphi^{*}_t\| > \gamma\right] \rightarrow 0 \quad \text{as} \epsilon \rightarrow 0 .\]

The fluctuations of \(y_t\) around a typical path \(\varphi^{*}_t\) are
Gaussian at scale \(\sqrt{\epsilon}\). Defining
\(\zeta^{\epsilon}_t \eqdef \left(y_t - \varphi^{*}_t\right) \/ \sqrt{\epsilon}\),
we have \(\zeta^{\epsilon}_t \rightarrow \zeta_t\) in distribution as
\(\epsilon \rightarrow 0\), where \(\zeta_t\) is the Ornstein-Uhlenbeck
process

\[\mathrm{d} \zeta_t = J_x\left[\bar{a}_{\alpha , 0}\left(t , \varphi^{*}_t\right)\right] \zeta_t \mathrm{d} t + \bar{b}\left(t , \varphi^{*}_t\right) \mathrm{d} W_t,\]

where
\[\bar{a}_{\alpha , 0}\left(t , x\right) = \lim_{\epsilon \rightarrow 0} \bar{a}_{\alpha , \epsilon}\left(t , x\right)\]
, \(J_x\left[\bar{a}_{\alpha , 0}\left(t , \varphi^{*}_t\right)\right]\)
is the Jacobian of the average drift evaluated on the typical path. From
[[#eq-gauss-dev-sde][[eq-gauss-dev-sde]]] one can construct a Gaussian
tube by solving the corresponding Lyapunov equation for the covariance
of \(\zeta_t\)

#+begin_proposition
Let \[\left(t , x_t, \lambda_t\right)\] evolve according to the coupled
slow-fast system of [[#cor-coupled-sde][[cor-coupled-sde]]] with
coefficients satisfying regularity conditions
[[#lem-coeff-tilde-bounds][[lem-coeff-tilde-bounds]]], and let \(y_t\)
evolve according to the reduced SDE given in
[[#def-reduced-sde][[def-reduced-sde]]], with coefficients satisfying
conditions given in [[#lem-avg-coeff-bounds][[lem-avg-coeff-bounds]]].
Let \(T > 0\), \(\gamma , \epsilon > 0\) and assume
\[x_0 = y_0 \in \mathcal{D}_{\epsilon}\] with
\(\lambda_0 \in \left[- 1 , 1\right]\). Let
\[\varphi^{*}_t \in C^2\left(\left[0 , T\right] ; \mathbb{R}^d\right)\]
be a minimiser of the Freidlin-Wentzell rate function given
[[#thm-ldp-averaged][[thm-ldp-averaged]]] with
\(\varphi^{*}_0 = x_0 = y_0\). Then for any \(\gamma > 0\),
\[\PP\left[\sup_{t \in \left[0 , T\right]} \| x_t - \varphi^{*}_t\| > \gamma\right] \rightarrow 0 \quad \text{as} \epsilon \rightarrow 0 .\]

#+end_proposition

#+begin_proof
/Proof./ By the triangle inequality,
\[\sup_{t \in \left[0 , T\right]} \| x_t - \varphi^{*}_t\| \leq \sup_{t \in \left[0 , T\right]} \| x_t - y_t\| + \sup_{t \in \left[0 , T\right]} \| y_t - \varphi^{*}_t\| ,\]
which yeilds
\[\PP\left[\sup_{t \in \left[0 , T\right]} \| x_t - \varphi^{*}_t\| > \gamma\right] \leq \PP\left[\sup_{t \in \left[0 , T\right]} \| y_t - \varphi^{*}_t\| > \frac{\gamma}{2}\right] + \PP\left[\sup_{t \in \left[0 , T\right]} \| x_t - y_t\| > \frac{\gamma}{2}\right] .\]

From [[#thm-ldp-averaged][[thm-ldp-averaged]]], we know that
\[\PP\left[\sup_{t \in \left[0 , T\right]} \| y_t - \varphi^{*}_t\| > \frac{\gamma}{2}\right] \rightarrow 0\]
as \(\epsilon \rightarrow 0\). For the second term, the
[[#thm-avg-principle][[thm-avg-principle]]] gives
\[\PP\left[\sup_{t \in \left[0 , T\right]} \| x_t - y_t\| > \frac{\gamma }{2}\right] \leq \frac{(4 C_T) }{\gamma^2} \sqrt{\epsilon} \rightarrow 0 ,\]
as \(\epsilon \rightarrow 0\). ◻

#+end_proof
[ *Remark.* body ]

*  Examples
:PROPERTIES:
:CUSTOM_ID: examples
:END:
** Toy example
:PROPERTIES:
:CUSTOM_ID: toy-example
:END:
Let us consider a 1D system with \(\sigma(x) = x\)

\[a_{+}\left(t , x\right) = - x , \quad a_{-}\left(t , x\right) = x ,\]
and

\[b_{+}\left(t , x\right) = r_{+} + x , \quad b_{-}\left(t , x\right) = r_{-} - x , \quad r_{+}, r_{-} > 0 , r_{+} \neq r_{-},\]

let \(\widehat{r}_{+} \eqdef r_{+} + r_{-}\), and
\(\widehat{r}_{-} \eqdef r_{+} + r_{-}\), when
\[a\left(t , x , \lambda\right) = -\lambda x , \quad b\left(t , x , \lambda\right) = \frac{1}{2} \left[\widehat{r}_{+} + \lambda \left(\widehat{r}_{-} + 2 x\right)\right]\]

\[\begin{aligned}
a_{\alpha , \epsilon}\left(t , x\right) & = -\lambda x + \frac{(\alpha \epsilon \lambda)}{2} b\left(t , x , \lambda\right) \\
 & = \frac{\lambda}{2} \left(\alpha \epsilon \widehat{r}_{+} - 2 x\right) + \frac{(\alpha \epsilon \lambda^2)}{2} \left(\widehat{r}_{-} + 2 x\right)
\end{aligned}\]

\[\begin{aligned}
\mathrm{d} x_t & = a_{\alpha , \epsilon} \mathrm{d} t + b\left(t , x , \lambda\right) \mathrm{d} W_t
\end{aligned}\]

\[\widetilde{a}_{\alpha , \epsilon} = a_{\alpha , \epsilon}, \quad \widetilde{d} = b^2 = \frac{1}{4}\left[\widehat{r}_{+}^2 + 2 \lambda \widehat{r}_{+}\left(\widehat{r}_{+} + 2 x\right) + \lambda^2\left(\widehat{r}_{+} + 2 x\right)^2\right]\]

*  Notes
:PROPERTIES:
:CUSTOM_ID: notes
:END:
** Tasks
:PROPERTIES:
:CUSTOM_ID: tasks
:END:
- Fix the
  \(\alpha \in \left[0 , 1\right] \rightarrow \alpha \in \left\{0 , \frac{1}{2} , 1\right\}\)
  giving Itō, strato anti-ito

- Chagne the line about Eq. 171

- Change the equation above 178

- Fix \(P_{ss} \rightarrow P^{ss}_x\) make x paramterised than using the
  given notation.

** Application Ideas
:PROPERTIES:
:CUSTOM_ID: application-ideas
:END:
- Sustained Oscillations Generated by Mutually Inhibiting Neurons with
  Adaptation Biol. Cybern. 52, 367-376 (1985)

  - feead back control neurons

    - usefull for central pattern generators

    - cost of control in weak noise environments??

- Numerical simulation of piecewise-linear models of gene regulatory
  networks using complementarity systems. Phys D 269:103--119

  - IRM

- Analysis and generic properties of gene regulatory networks with
  graded response functions Physica D 201 (2005) 150--176

  - might be the first analysis of gene regulatory netowrks with
    piecewise smooth functions

** Needs Testing
:PROPERTIES:
:CUSTOM_ID: needs-testing
:END:
- whether we obtain the limits
  \(P_{ss} \rightarrow \delta(\lambda pm 1)\) at the tangency points, in
  reverse time an forward time and backward w.r.t entry and exit points,

  - Ovs i only needs to check one of the cases, then by time reversal
    symmetry the other will also hold.
